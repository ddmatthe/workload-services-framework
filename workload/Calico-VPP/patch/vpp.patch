diff --git a/MAINTAINERS b/MAINTAINERS
index e89f1aa29..02c319860 100644
--- a/MAINTAINERS
+++ b/MAINTAINERS
@@ -687,6 +687,11 @@ I:	svs
 M:	Neale Ranns <neale@graphiant.com>
 F:	src/plugins/svs/
 
+Plugin - PBL
+I:	pbl
+M:	Nathan Skrzypczak <nathan.skrzypczak@gmail.com>
+F:	src/plugins/pbl
+
 Plugin - IPv6 Connection Tracker
 I:	ct6
 M:	Dave Barach <vpp@barachs.net>
@@ -725,6 +730,11 @@ M:	Nathan Skrzypczak <nathan.skrzypczak@gmail.com>
 M:	Neale Ranns <neale@graphiant.com>
 F:	src/plugins/cnat
 
+Plugin - Calico policies
+I:	capo
+M:	Aloys Augustin <aloaugus@cisco.com>
+F:	src/plugins/capo/
+
 Plugin - Wireguard
 I:	wireguard
 M:	Artem Glazychev <artem.glazychev@xored.com>
diff --git a/src/CMakeLists.txt b/src/CMakeLists.txt
index 4be247333..06c08fe58 100644
--- a/src/CMakeLists.txt
+++ b/src/CMakeLists.txt
@@ -11,7 +11,7 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-cmake_minimum_required(VERSION 3.13)
+cmake_minimum_required(VERSION 3.10)
 
 set(CMAKE_C_COMPILER_NAMES
   clang-13
@@ -26,6 +26,14 @@ set(CMAKE_C_COMPILER_NAMES
 
 project(vpp C)
 
+if(CMAKE_VERSION VERSION_LESS 3.12)
+  macro(add_compile_definitions defs)
+    foreach(d ${defs})
+      add_compile_options(-D${d})
+    endforeach()
+  endmacro()
+endif()
+
 if(NOT DEFINED CMAKE_INSTALL_LIBDIR AND EXISTS "/etc/debian_version")
   set(CMAKE_INSTALL_LIBDIR "lib/${CMAKE_LIBRARY_ARCHITECTURE}")
 endif()
@@ -71,10 +79,11 @@ set(VPP_LIBRARY_DIR ${CMAKE_INSTALL_LIBDIR} CACHE STRING "Relative library direc
 set(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/${VPP_RUNTIME_DIR})
 set(CMAKE_LIBRARY_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/${VPP_LIBRARY_DIR})
 set(VPP_BINARY_DIR ${CMAKE_BINARY_DIR}/CMakeFiles)
-set(PYENV PYTHONPYCACHEPREFIX=${CMAKE_BINARY_DIR}/CMakeFiles/__pycache__)
+set(PYENV PYTHONPYCACHEPREFIX=${CMAKE_BINARY_DIR}/CMakeFile/__pycache__)
 
 if (CMAKE_BUILD_TYPE)
-  add_compile_options(-g -Werror -Wall)
+#add_compile_options(-g -fPIC -Werror -Wall)
+  add_compile_options(-g -fPIC -Wall)
 endif()
 
 if (compiler_flag_no_address_of_packed_member)
@@ -90,6 +99,7 @@ set(CMAKE_C_FLAGS_DEBUG "")
 if (${CMAKE_BUILD_TYPE_LC} MATCHES "release")
   add_compile_options(-O3 -fstack-protector -fno-common)
   add_compile_definitions(_FORTIFY_SOURCE=2)
+  set(CMAKE_EXE_LINKER_FLAGS_RELEASE "-pie")
 elseif (${CMAKE_BUILD_TYPE_LC} MATCHES "debug")
   add_compile_options(-O0 -fstack-protector -fno-common)
   add_compile_definitions(CLIB_DEBUG)
@@ -116,10 +126,6 @@ if (CMAKE_BUILD_TYPE_UC STREQUAL "RELEASE")
   endif()
 endif()
 
-if(VPP_USE_LTO)
-  check_c_compiler_flag("-Wno-stringop-overflow"
-		        compiler_flag_no_stringop_overflow)
-endif()
 ##############################################################################
 # sanitizers
 ##############################################################################
@@ -134,7 +140,8 @@ set(VPP_SANITIZE_ADDR_OPTIONS
 if (VPP_ENABLE_SANITIZE_ADDR)
   add_compile_options(-fsanitize=address)
   add_compile_definitions(CLIB_SANITIZE_ADDR)
-  add_link_options(-fsanitize=address)
+  set(CMAKE_EXE_LINKER_FLAGS "-fsanitize=address ${CMAKE_EXE_LINKER_FLAGS}")
+  set(CMAKE_SHARED_LINKER_FLAGS "-fsanitize=address ${CMAKE_SHARED_LINKER_FLAGS}")
 endif (VPP_ENABLE_SANITIZE_ADDR)
 
 ##############################################################################
@@ -146,14 +153,6 @@ if(VPP_ENABLE_TRAJECTORY_TRACE)
   add_compile_definitions(VLIB_BUFFER_TRACE_TRAJECTORY=1)
 endif()
 
-##############################################################################
-# unittest with clang ode coverage
-##############################################################################
-
-if("${CMAKE_VERSION}" VERSION_GREATER_EQUAL "3.13" AND "${CMAKE_C_COMPILER_ID}" MATCHES "(Apple)?[Cc]lang")
-  option(VPP_BUILD_TESTS_WITH_COVERAGE "Build unit tests with code coverage" OFF)
-endif()
-
 ##############################################################################
 # install config
 ##############################################################################
@@ -267,7 +266,6 @@ pr("VPP version" ${VPP_VERSION})
 pr("VPP library version" ${VPP_LIB_VERSION})
 pr("GIT toplevel dir" ${VPP_GIT_TOPLEVEL_DIR})
 pr("Build type" ${CMAKE_BUILD_TYPE})
-pr("C compiler" ${CMAKE_C_COMPILER})
 pr("C flags" ${CMAKE_C_FLAGS}${CMAKE_C_FLAGS_${CMAKE_BUILD_TYPE_UC}})
 pr("Linker flags (apps)" ${CMAKE_EXE_LINKER_FLAGS} ${CMAKE_EXE_LINKER_FLAGS_${CMAKE_BUILD_TYPE_UC}})
 pr("Linker flags (libs)" ${CMAKE_SHARED_LINKER_FLAGS} ${CMAKE_SHARED_LINKER_FLAGS_${CMAKE_BUILD_TYPE_UC}})
@@ -275,4 +273,3 @@ pr("Host processor" ${CMAKE_HOST_SYSTEM_PROCESSOR})
 pr("Target processor" ${CMAKE_SYSTEM_PROCESSOR})
 pr("Prefix path" ${CMAKE_PREFIX_PATH})
 pr("Install prefix" ${CMAKE_INSTALL_PREFIX})
-pr("Library dir" ${VPP_LIBRARY_DIR})
diff --git a/src/examples/sample-plugin/sample/node.c b/src/examples/sample-plugin/sample/node.c
index a9d8b66d7..ea33d227c 100644
--- a/src/examples/sample-plugin/sample/node.c
+++ b/src/examples/sample-plugin/sample/node.c
@@ -111,6 +111,7 @@ VLIB_NODE_FN (sample_node) (vlib_main_t * vm, vlib_node_runtime_t * node,
 	  u32 sw_if_index0, sw_if_index1;
 	  u8 tmp0[6], tmp1[6];
 	  ethernet_header_t *en0, *en1;
+	  ip4_header_t *h0, *h1;
 	  u32 bi0, bi1;
 	  vlib_buffer_t *b0, *b1;
 
@@ -166,6 +167,22 @@ VLIB_NODE_FN (sample_node) (vlib_main_t * vm, vlib_node_runtime_t * node,
 	  foreach_mac_address_offset;
 #undef _
 
+	  if (clib_net_to_host_u16 (en0->type) == ETHERNET_TYPE_IP4)
+	  {
+	    ip4_header_t *h0 = vlib_buffer_get_current (b0) + sizeof(ethernet_header_t);
+	    u32 tmp = h0->src_address.data_u32;
+	    h0->src_address.data_u32 = h0->dst_address.data_u32;
+	    h0->dst_address.data_u32 = tmp;
+          }
+
+	  if (clib_net_to_host_u16 (en1->type) == ETHERNET_TYPE_IP4)
+	  {
+	    ip4_header_t *h1 = vlib_buffer_get_current (b1) + sizeof(ethernet_header_t);
+	    u32 tmp = h1->src_address.data_u32;
+	    h1->src_address.data_u32 = h1->dst_address.data_u32;
+	    h1->dst_address.data_u32 = tmp;
+          }
+
 	  sw_if_index0 = vnet_buffer (b0)->sw_if_index[VLIB_RX];
 	  sw_if_index1 = vnet_buffer (b1)->sw_if_index[VLIB_RX];
 
@@ -244,6 +261,13 @@ VLIB_NODE_FN (sample_node) (vlib_main_t * vm, vlib_node_runtime_t * node,
 #define _(a) en0->dst_address[a] = tmp0[a];
 	  foreach_mac_address_offset;
 #undef _
+	  if (clib_net_to_host_u16 (en0->type) == ETHERNET_TYPE_IP4)
+	  {
+	    ip4_header_t *h0 = vlib_buffer_get_current (b0) + sizeof(ethernet_header_t);
+	    u32 tmp = h0->src_address.data_u32;
+	    h0->src_address.data_u32 = h0->dst_address.data_u32;
+	    h0->dst_address.data_u32 = tmp;
+          }
 
 	  sw_if_index0 = vnet_buffer (b0)->sw_if_index[VLIB_RX];
 
diff --git a/src/plugins/acl/CMakeLists.txt b/src/plugins/acl/CMakeLists.txt
index c43dd23ea..44e4e6a60 100644
--- a/src/plugins/acl/CMakeLists.txt
+++ b/src/plugins/acl/CMakeLists.txt
@@ -20,6 +20,8 @@ add_vpp_plugin(acl
   dataplane_node.c
   dataplane_node_nonip.c
 
+  acl_caiop.c
+
   MULTIARCH_SOURCES
   dataplane_node.c
   dataplane_node_nonip.c
diff --git a/src/plugins/acl/acl.c b/src/plugins/acl/acl.c
index 01a1e87a2..f47234595 100644
--- a/src/plugins/acl/acl.c
+++ b/src/plugins/acl/acl.c
@@ -40,6 +40,7 @@
 
 #include "fa_node.h"
 #include "public_inlines.h"
+#include "acl_caiop.h"
 
 acl_main_t acl_main;
 
@@ -518,6 +519,11 @@ acl_clear_sessions (acl_main_t * am, u32 sw_if_index)
 			     sw_if_index);
 }
 
+void
+acl_plugin_wip_clear_sessions (u32 sw_if_index)
+{
+  acl_clear_sessions (&acl_main, sw_if_index);
+}
 
 static int
 acl_interface_in_enable_disable (acl_main_t * am, u32 sw_if_index,
@@ -602,8 +608,8 @@ acl_stats_intf_counters_enable_disable (acl_main_t * am, int enable_disable)
   return rv;
 }
 
-static int
-acl_interface_inout_enable_disable (acl_main_t * am, u32 sw_if_index,
+int
+acl_interface_inout_enable_disable (acl_main_t *am, u32 sw_if_index,
 				    int is_input, int enable_disable)
 {
   if (is_input)
@@ -612,6 +618,12 @@ acl_interface_inout_enable_disable (acl_main_t * am, u32 sw_if_index,
     return acl_interface_out_enable_disable (am, sw_if_index, enable_disable);
 }
 
+int
+is_acl_enabled_on_sw_if_index (u32 sw_if_index, int is_input)
+{
+  return 1; /* TODO */
+}
+
 static int
 acl_is_not_defined (acl_main_t * am, u32 acl_list_index)
 {
@@ -748,8 +760,11 @@ acl_interface_set_inout_acl_list (acl_main_t * am, u32 sw_if_index,
 	}
     }
   /* ensure ACL processing is enabled/disabled as needed */
+  int feature_enable =
+    is_acl_caiop_enabled_on_sw_if_index (sw_if_index, is_input) ||
+    (vec_len (vec_acl_list_index) > 0);
   acl_interface_inout_enable_disable (am, sw_if_index, is_input,
-				      vec_len (vec_acl_list_index) > 0);
+				      feature_enable);
 
 done:
   clib_bitmap_free (change_acl_bitmap);
@@ -3399,6 +3414,10 @@ acl_plugin_show_sessions (acl_main_t * am,
 		   ((f64) am->fa_current_cleaner_timer_wait_interval) *
 		   1000.0 / (f64) vm->clib_time.clocks_per_second);
   vlib_cli_output (vm, "Reclassify sessions: %d", am->reclassify_sessions);
+  vlib_cli_output (vm, "Custom access input policies: %d",
+		   am->custom_access_input_policies_count);
+  vlib_cli_output (vm, "Custom access output policies: %d",
+		   am->custom_access_output_policies_count);
 }
 
 static clib_error_t *
@@ -3714,6 +3733,8 @@ acl_init (vlib_main_t * vm)
     ACL_FA_CONN_TABLE_DEFAULT_HASH_MEMORY_SIZE;
   am->fa_conn_table_max_entries = ACL_FA_CONN_TABLE_DEFAULT_MAX_ENTRIES;
   am->reclassify_sessions = 0;
+  am->custom_access_input_policies_count = 0;
+  am->custom_access_output_policies_count = 0;
   vlib_thread_main_t *tm = vlib_get_thread_main ();
 
   am->fa_min_deleted_sessions_per_interval =
diff --git a/src/plugins/acl/acl.h b/src/plugins/acl/acl.h
index c540bf8fb..440097899 100644
--- a/src/plugins/acl/acl.h
+++ b/src/plugins/acl/acl.h
@@ -113,6 +113,11 @@ typedef struct
   u8 from_tm;
 } ace_mask_type_entry_t;
 
+/* This is a private experimental type, subject to change */
+typedef int (*acl_plugin_private_caiop_match_5tuple_func_t) (
+  void *p_acl_main, u32 sw_if_index, u32 is_inbound,
+  fa_5tuple_opaque_t *pkt_5tuple, int is_ip6, u8 *r_action, u32 *trace_bitmap);
+
 typedef struct {
   /* API message ID base */
   u16 msg_id_base;
@@ -168,7 +173,18 @@ typedef struct {
   /* whether we need to take the epoch of the session into account */
   int reclassify_sessions;
 
+  /* activation of dataplane for custom policies  when > 0 */
+  int custom_access_input_policies_count;
+  int custom_access_output_policies_count;
+  /* bitmaps when set the processing is enabled on the interface */
+  uword *caip_on_sw_if_index;
+  uword *caop_on_sw_if_index;
 
+  /* CAIOP match function vectors by sw_if_index */
+  acl_plugin_private_caiop_match_5tuple_func_t *
+    *caip_match_func_by_sw_if_index;
+  acl_plugin_private_caiop_match_5tuple_func_t *
+    *caop_match_func_by_sw_if_index;
 
   /* Total count of interface+direction pairs enabled */
   u32 fa_total_enabled_count;
@@ -376,7 +392,10 @@ typedef enum {
   ACL_FA_N_REQ,
 } acl_fa_sess_req_t;
 
+int acl_interface_inout_enable_disable (acl_main_t *am, u32 sw_if_index,
+					int is_input, int enable_disable);
+int is_acl_enabled_on_sw_if_index (u32 sw_if_index, int is_input);
 void aclp_post_session_change_request(acl_main_t *am, u32 target_thread, u32 target_session, acl_fa_sess_req_t request_type);
 void aclp_swap_wip_and_pending_session_change_requests(acl_main_t *am, u32 target_thread);
-
+void acl_plugin_wip_clear_sessions (u32 sw_if_index);
 #endif
diff --git a/src/plugins/acl/acl_caiop.c b/src/plugins/acl/acl_caiop.c
new file mode 100644
index 000000000..fa11d32a0
--- /dev/null
+++ b/src/plugins/acl/acl_caiop.c
@@ -0,0 +1,249 @@
+/*
+ * Copyright (c) 2016-2018 Cisco and/or its affiliates.
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at:
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#include <stddef.h>
+#include <netinet/in.h>
+
+#include <vlib/vlib.h>
+#include <vnet/vnet.h>
+#include <vnet/pg/pg.h>
+#include <vppinfra/error.h>
+
+#include <acl/acl.h>
+#include <vnet/ip/icmp46_packet.h>
+
+#include <plugins/acl/fa_node.h>
+#include <plugins/acl/acl.h>
+#include <plugins/acl/lookup_context.h>
+#include <plugins/acl/public_inlines.h>
+#include <plugins/acl/session_inlines.h>
+#include <plugins/acl/acl_util.h>
+#include <plugins/acl/acl_caiop.h>
+
+int
+is_acl_caiop_enabled_on_sw_if_index (u32 sw_if_index, int is_input)
+{
+  acl_main_t *am = &acl_main;
+  int ret = 0;
+  if (is_input)
+    {
+      ret = clib_bitmap_get (am->caip_on_sw_if_index, sw_if_index);
+    }
+  else
+    {
+      ret = clib_bitmap_get (am->caop_on_sw_if_index, sw_if_index);
+    }
+  return ret;
+}
+
+void
+acl_caiop_enable_disable (u32 sw_if_index, int is_input, int enable_disable)
+{
+  acl_main_t *am = &acl_main;
+
+  if (is_input)
+    {
+      ASSERT (clib_bitmap_get (am->caip_on_sw_if_index, sw_if_index) !=
+	      enable_disable);
+      am->caip_on_sw_if_index =
+	clib_bitmap_set (am->caip_on_sw_if_index, sw_if_index, enable_disable);
+    }
+  else
+    {
+      ASSERT (clib_bitmap_get (am->caop_on_sw_if_index, sw_if_index) !=
+	      enable_disable);
+      am->caop_on_sw_if_index =
+	clib_bitmap_set (am->caop_on_sw_if_index, sw_if_index, enable_disable);
+    }
+}
+
+static int
+not_found (u32 index)
+{
+  return (index == ((u32) ~0));
+}
+
+static int
+caiop_add (u32 sw_if_index, int is_input,
+	   acl_plugin_private_caiop_match_5tuple_func_t func)
+{
+  acl_main_t *am = &acl_main;
+  acl_plugin_private_caiop_match_5tuple_func_t ***pvecvec =
+    is_input ? &am->caip_match_func_by_sw_if_index :
+	       &am->caop_match_func_by_sw_if_index;
+  uword **pbitmap =
+    is_input ? &am->caip_on_sw_if_index : &am->caop_on_sw_if_index;
+  int *pcount = is_input ? &am->custom_access_input_policies_count :
+			   &am->custom_access_output_policies_count;
+
+  vec_validate (*pvecvec, sw_if_index);
+  u32 index = vec_search ((*pvecvec)[sw_if_index], func);
+  if (not_found (index))
+    {
+      vec_add1 ((*pvecvec)[sw_if_index], func);
+      *pbitmap = clib_bitmap_set (*pbitmap, sw_if_index, 1);
+      (*pcount)++;
+      return acl_interface_inout_enable_disable (am, sw_if_index, is_input, 1);
+    }
+  else
+    {
+      clib_warning ("Existing Index: %d", index);
+      return -2;
+    }
+}
+
+static int
+caiop_del (u32 sw_if_index, int is_input,
+	   acl_plugin_private_caiop_match_5tuple_func_t func)
+{
+  acl_main_t *am = &acl_main;
+  acl_plugin_private_caiop_match_5tuple_func_t ***pvecvec =
+    is_input ? &am->caip_match_func_by_sw_if_index :
+	       &am->caop_match_func_by_sw_if_index;
+  uword **pbitmap =
+    is_input ? &am->caip_on_sw_if_index : &am->caop_on_sw_if_index;
+  int *pcount = is_input ? &am->custom_access_input_policies_count :
+			   &am->custom_access_output_policies_count;
+
+  if (sw_if_index >= vec_len (*pvecvec))
+    {
+      return -2;
+    }
+  else
+    {
+      u32 index = vec_search ((*pvecvec)[sw_if_index], func);
+      if (not_found (index))
+	{
+	  return -3;
+	}
+      else
+	{
+	  vec_del1 ((*pvecvec)[sw_if_index], index);
+	  *pbitmap = clib_bitmap_set (*pbitmap, sw_if_index, 0);
+	  (*pcount)--;
+	  int enable = (*pcount > 0) ||
+		       is_acl_enabled_on_sw_if_index (sw_if_index, is_input);
+	  return acl_interface_inout_enable_disable (am, sw_if_index, is_input,
+						     enable);
+	}
+    }
+}
+
+int
+acl_caiop_add_del (int is_add, u32 sw_if_index, int is_input,
+		   acl_plugin_private_caiop_match_5tuple_func_t func)
+{
+  acl_main_t *am = &acl_main;
+  if (!vnet_sw_interface_is_api_valid (am->vnet_main, sw_if_index))
+    {
+      return -1;
+    }
+  return is_add ? caiop_add (sw_if_index, is_input, func) :
+		  caiop_del (sw_if_index, is_input, func);
+}
+
+void
+show_custom_access_policies (vlib_main_t *vm, u32 verbose)
+{
+  acl_main_t *am = &acl_main;
+  int i;
+  vlib_cli_output (vm, "\nCustom access policies:");
+  acl_cli_output_u (vm, am->custom_access_input_policies_count);
+  acl_cli_output_u (vm, am->custom_access_output_policies_count);
+  acl_cli_output_bitmap (vm, am->caip_on_sw_if_index);
+  acl_cli_output_bitmap (vm, am->caop_on_sw_if_index);
+  for (i = 0; i < vec_len (am->caip_match_func_by_sw_if_index); i++)
+    {
+      if (i == 0)
+	{
+	  vlib_cli_output (vm, "\n input function pointers:");
+	}
+      vlib_cli_output (vm, "sw_if_index: %d vector: %U", i, format_vec_uword,
+		       am->caip_match_func_by_sw_if_index[i], "%p");
+    }
+  for (i = 0; i < vec_len (am->caop_match_func_by_sw_if_index); i++)
+    {
+      if (i == 0)
+	{
+	  vlib_cli_output (vm, "\n output function pointers:");
+	}
+      vlib_cli_output (vm, "sw_if_index: %d vector: %U", i, format_vec_uword,
+		       am->caop_match_func_by_sw_if_index[i], "%p");
+    }
+}
+
+static clib_error_t *
+acl_show_custom_access_policies_fn (vlib_main_t *vm, unformat_input_t *input,
+				    vlib_cli_command_t *cmd)
+{
+  clib_error_t *error = 0;
+
+  u32 show_policies_verbose = 0;
+  (void) unformat (input, "verbose %u", &show_policies_verbose);
+
+  show_custom_access_policies (vm, show_policies_verbose);
+  return error;
+}
+
+static int
+dummy_match_5tuple_fun (void *p_acl_main, u32 sw_if_index, u32 is_inbound,
+			fa_5tuple_opaque_t *pkt_5tuple, int is_ip6,
+			u8 *r_action, u32 *trace_bitmap)
+{
+  /* permit and create connection */
+  *r_action = 2;
+  return 1;
+}
+
+static clib_error_t *
+acl_test_custom_access_policy_fn (vlib_main_t *vm, unformat_input_t *input,
+				  vlib_cli_command_t *cmd)
+{
+  clib_error_t *error = 0;
+  int is_del = unformat (input, "del");
+  int is_input = unformat (input, "input");
+  u32 sw_if_index = ~0;
+  (void) unformat (input, "sw_if_index %u", &sw_if_index);
+  vlib_cli_output (vm, "Test %s %s sw_if_index: %d", is_del ? "del" : "add",
+		   is_input ? "input" : "output", sw_if_index);
+  u32 ret =
+    acl_caiop_add_del (!is_del, sw_if_index, is_input, dummy_match_5tuple_fun);
+  if (ret != 0)
+    {
+      error = clib_error_return (0, "non-zero ret code: %d", ret);
+    }
+
+  return error;
+}
+
+VLIB_CLI_COMMAND (aclplugin_set_custom_policy_command, static) = {
+  .path = "show acl-plugin custom-access-policies",
+  .short_help = "show acl-plugin custom-access-policies [verbose]",
+  .function = acl_show_custom_access_policies_fn,
+};
+
+VLIB_CLI_COMMAND (aclplugin_test_custom_policy_command, static) = {
+  .path = "test acl-plugin custom-access-policy",
+  .short_help =
+    "test acl-plugin custom-access-policy [del] [input] [sw_if_index <N>]",
+  .function = acl_test_custom_access_policy_fn,
+};
+
+/*
+ * fd.io coding-style-patch-verification: ON
+ *
+ * Local Variables:
+ * eval: (c-set-style "gnu")
+ * End:
+ */
diff --git a/src/plugins/acl/acl_caiop.h b/src/plugins/acl/acl_caiop.h
new file mode 100644
index 000000000..d26f39d6d
--- /dev/null
+++ b/src/plugins/acl/acl_caiop.h
@@ -0,0 +1,18 @@
+#ifndef vpp_acl_caiop_h
+#define vpp_acl_caiop_h
+
+#include <plugins/acl/acl.h>
+
+int is_acl_caiop_enabled_on_sw_if_index (u32 sw_if_index, int is_input);
+int acl_caiop_add_del (int is_add, u32 sw_if_index, int is_input,
+		       acl_plugin_private_caiop_match_5tuple_func_t func);
+
+#endif
+
+/*
+ * fd.io coding-style-patch-verification: ON
+ *
+ * Local Variables:
+ * eval: (c-set-style "gnu")
+ * End:
+ */
diff --git a/src/plugins/acl/acl_util.h b/src/plugins/acl/acl_util.h
new file mode 100644
index 000000000..843a671ad
--- /dev/null
+++ b/src/plugins/acl/acl_util.h
@@ -0,0 +1,17 @@
+#ifndef vpp_acl_plugin_util_h
+#define vpp_acl_plugin_util_h
+
+#define acl_cli_output_u(vm, value)                                           \
+  vlib_cli_output (vm, "  %s: %u", #value, value)
+#define acl_cli_output_bitmap(vm, bitmap)                                     \
+  vlib_cli_output (vm, "  %s bitmap: %U", #bitmap, format_bitmap_hex, bitmap)
+
+#endif
+
+/*
+ * fd.io coding-style-patch-verification: ON
+ *
+ * Local Variables:
+ * eval: (c-set-style "gnu")
+ * End:
+ */
diff --git a/src/plugins/acl/dataplane_node.c b/src/plugins/acl/dataplane_node.c
index 4bef8f077..4ccc2a4b1 100644
--- a/src/plugins/acl/dataplane_node.c
+++ b/src/plugins/acl/dataplane_node.c
@@ -25,6 +25,7 @@
 
 #include <plugins/acl/fa_node.h>
 #include <plugins/acl/acl.h>
+#include <plugins/acl/acl_caiop.h>
 #include <plugins/acl/lookup_context.h>
 #include <plugins/acl/public_inlines.h>
 #include <plugins/acl/session_inlines.h>
@@ -318,13 +319,12 @@ acl_fa_node_common_prepare_fn (vlib_main_t * vm,
     }
 }
 
-
 always_inline uword
-acl_fa_inner_node_fn (vlib_main_t * vm,
-		      vlib_node_runtime_t * node, vlib_frame_t * frame,
-		      int is_ip6, int is_input, int is_l2_path,
-		      int with_stateful_datapath, int node_trace_on,
-		      int reclassify_sessions)
+acl_fa_inner_node_fn (vlib_main_t *vm, vlib_node_runtime_t *node,
+		      vlib_frame_t *frame, int is_ip6, int is_input,
+		      int is_l2_path, int with_stateful_datapath,
+		      int node_trace_on, int reclassify_sessions,
+		      const int do_custom_access_policies)
 {
   u32 n_left;
   u32 pkts_exist_session = 0;
@@ -465,39 +465,85 @@ acl_fa_inner_node_fn (vlib_main_t * vm,
 
 	  if (acl_check_needed)
 	    {
-	      if (is_input)
-		lc_index0 = am->input_lc_index_by_sw_if_index[sw_if_index[0]];
-	      else
-		lc_index0 =
-		  am->output_lc_index_by_sw_if_index[sw_if_index[0]];
-
-	      action = 0;	/* deny by default */
-	      int is_match = acl_plugin_match_5tuple_inline (am, lc_index0,
-							     (fa_5tuple_opaque_t *) & fa_5tuple[0], is_ip6,
-							     &action,
-							     &match_acl_pos,
-							     &match_acl_in_index,
-							     &match_rule_index,
-							     &trace_bitmap);
-	      if (PREDICT_FALSE
-		  (is_match && am->interface_acl_counters_enabled))
+	      if (do_custom_access_policies)
 		{
-		  u32 buf_len = vlib_buffer_length_in_chain (vm, b[0]);
-		  vlib_increment_combined_counter (am->combined_acl_counters +
-						   saved_matched_acl_index,
-						   thread_index,
-						   saved_matched_ace_index,
-						   saved_packet_count,
-						   saved_byte_count);
-		  saved_matched_acl_index = match_acl_in_index;
-		  saved_matched_ace_index = match_rule_index;
-		  saved_packet_count = 1;
-		  saved_byte_count = buf_len;
-		  /* prefetch the counter that we are going to increment */
-		  vlib_prefetch_combined_counter (am->combined_acl_counters +
-						  saved_matched_acl_index,
-						  thread_index,
-						  saved_matched_ace_index);
+		  if (is_acl_caiop_enabled_on_sw_if_index (sw_if_index[0],
+							   is_input))
+		    {
+		      acl_plugin_private_caiop_match_5tuple_func_t
+			*caiop_match_vec,
+			*pf;
+
+		      if (is_input)
+			{
+			  caiop_match_vec =
+			    vec_elt (am->caip_match_func_by_sw_if_index,
+				     sw_if_index[0]);
+			}
+		      else
+			{
+			  caiop_match_vec =
+			    vec_elt (am->caop_match_func_by_sw_if_index,
+				     sw_if_index[0]);
+			}
+		      vec_foreach (pf, caiop_match_vec)
+			{
+			  int is_match =
+			    (*pf) (am, sw_if_index[0], is_input,
+				   (fa_5tuple_opaque_t *) &fa_5tuple[0],
+				   is_ip6, &action, &trace_bitmap);
+			  if (is_match)
+			    {
+			      acl_check_needed = 0;
+			      break;
+			    }
+			}
+		      /* If no match in policy but no ACL configured, bypass
+		       * the ACL check, else it will crash */
+		      if (acl_check_needed)
+			{
+			  if (is_input)
+			    acl_check_needed =
+			      vec_len (am->input_lc_index_by_sw_if_index) >
+			      sw_if_index[0];
+			  else
+			    acl_check_needed =
+			      vec_len (am->output_lc_index_by_sw_if_index) >
+			      sw_if_index[0];
+			}
+		    }
+		}
+	      if (acl_check_needed)
+		{
+		  if (is_input)
+		    lc_index0 =
+		      am->input_lc_index_by_sw_if_index[sw_if_index[0]];
+		  else
+		    lc_index0 =
+		      am->output_lc_index_by_sw_if_index[sw_if_index[0]];
+
+		  action = 0; /* deny by default */
+		  int is_match = acl_plugin_match_5tuple_inline (
+		    am, lc_index0, (fa_5tuple_opaque_t *) &fa_5tuple[0],
+		    is_ip6, &action, &match_acl_pos, &match_acl_in_index,
+		    &match_rule_index, &trace_bitmap);
+		  if (PREDICT_FALSE (is_match &&
+				     am->interface_acl_counters_enabled))
+		    {
+		      u32 buf_len = vlib_buffer_length_in_chain (vm, b[0]);
+		      vlib_increment_combined_counter (
+			am->combined_acl_counters + saved_matched_acl_index,
+			thread_index, saved_matched_ace_index,
+			saved_packet_count, saved_byte_count);
+		      saved_matched_acl_index = match_acl_in_index;
+		      saved_matched_ace_index = match_rule_index;
+		      saved_packet_count = 1;
+		      saved_byte_count = buf_len;
+		      /* prefetch the counter that we are going to increment */
+		      vlib_prefetch_combined_counter (
+			am->combined_acl_counters + saved_matched_acl_index,
+			thread_index, saved_matched_ace_index);
+		    }
 		}
 
 	      b[0]->error = error_node->errors[action];
@@ -582,11 +628,10 @@ acl_fa_inner_node_fn (vlib_main_t * vm,
    * if we were had an acl match then we have a counter to increment.
    * else it is all zeroes, so this will be harmless.
    */
-  vlib_increment_combined_counter (am->combined_acl_counters +
-				   saved_matched_acl_index,
-				   thread_index,
-				   saved_matched_ace_index,
-				   saved_packet_count, saved_byte_count);
+  if (am->combined_acl_counters && saved_packet_count)
+    vlib_increment_combined_counter (
+      am->combined_acl_counters + saved_matched_acl_index, thread_index,
+      saved_matched_ace_index, saved_packet_count, saved_byte_count);
 
   vlib_node_increment_counter (vm, node->node_index,
 			       ACL_FA_ERROR_ACL_CHECK, frame->n_vectors);
@@ -602,10 +647,10 @@ acl_fa_inner_node_fn (vlib_main_t * vm,
 }
 
 always_inline uword
-acl_fa_outer_node_fn (vlib_main_t * vm,
-		      vlib_node_runtime_t * node, vlib_frame_t * frame,
-		      int is_ip6, int is_input, int is_l2_path,
-		      int do_stateful_datapath)
+acl_fa_outer_node_fn (vlib_main_t *vm, vlib_node_runtime_t *node,
+		      vlib_frame_t *frame, int is_ip6, int is_input,
+		      int is_l2_path, int do_stateful_datapath,
+		      int do_custom_access_policies)
 {
   acl_main_t *am = &acl_main;
 
@@ -615,25 +660,24 @@ acl_fa_outer_node_fn (vlib_main_t * vm,
   if (am->reclassify_sessions)
     {
       if (PREDICT_FALSE (node->flags & VLIB_NODE_FLAG_TRACE))
-	return acl_fa_inner_node_fn (vm, node, frame, is_ip6, is_input,
-				     is_l2_path, do_stateful_datapath,
-				     1 /* trace */ ,
-				     1 /* reclassify */ );
+	return acl_fa_inner_node_fn (
+	  vm, node, frame, is_ip6, is_input, is_l2_path, do_stateful_datapath,
+	  1 /* trace */, 1 /* reclassify */, do_custom_access_policies);
       else
-	return acl_fa_inner_node_fn (vm, node, frame, is_ip6, is_input,
-				     is_l2_path, do_stateful_datapath, 0,
-				     1 /* reclassify */ );
+	return acl_fa_inner_node_fn (
+	  vm, node, frame, is_ip6, is_input, is_l2_path, do_stateful_datapath,
+	  0, 1 /* reclassify */, do_custom_access_policies);
     }
   else
     {
       if (PREDICT_FALSE (node->flags & VLIB_NODE_FLAG_TRACE))
-	return acl_fa_inner_node_fn (vm, node, frame, is_ip6, is_input,
-				     is_l2_path, do_stateful_datapath,
-				     1 /* trace */ ,
-				     0);
+	return acl_fa_inner_node_fn (
+	  vm, node, frame, is_ip6, is_input, is_l2_path, do_stateful_datapath,
+	  1 /* trace */, 0, do_custom_access_policies);
       else
 	return acl_fa_inner_node_fn (vm, node, frame, is_ip6, is_input,
-				     is_l2_path, do_stateful_datapath, 0, 0);
+				     is_l2_path, do_stateful_datapath, 0, 0,
+				     do_custom_access_policies);
     }
 }
 
@@ -646,13 +690,35 @@ acl_fa_node_fn (vlib_main_t * vm,
   acl_main_t *am = &acl_main;
   acl_fa_per_worker_data_t *pw = &am->per_worker_data[vm->thread_index];
   uword rv;
+  int do_custom_access_policies = 0;
+  if (is_input)
+    {
+      do_custom_access_policies = (am->custom_access_input_policies_count > 0);
+    }
+  else
+    {
+      do_custom_access_policies =
+	(am->custom_access_output_policies_count > 0);
+    }
 
-  if (am->fa_sessions_hash_is_initialized)
-    rv = acl_fa_outer_node_fn (vm, node, frame, is_ip6, is_input,
-			       is_l2_path, 1);
+  if (do_custom_access_policies)
+    {
+      if (am->fa_sessions_hash_is_initialized)
+	rv = acl_fa_outer_node_fn (vm, node, frame, is_ip6, is_input,
+				   is_l2_path, 1, 1);
+      else
+	rv = acl_fa_outer_node_fn (vm, node, frame, is_ip6, is_input,
+				   is_l2_path, 0, 1);
+    }
   else
-    rv = acl_fa_outer_node_fn (vm, node, frame, is_ip6, is_input,
-			       is_l2_path, 0);
+    {
+      if (am->fa_sessions_hash_is_initialized)
+	rv = acl_fa_outer_node_fn (vm, node, frame, is_ip6, is_input,
+				   is_l2_path, 1, 0);
+      else
+	rv = acl_fa_outer_node_fn (vm, node, frame, is_ip6, is_input,
+				   is_l2_path, 0, 0);
+    }
 
   vlib_buffer_enqueue_to_next (vm, node, vlib_frame_vector_args (frame),
 			       pw->nexts, frame->n_vectors);
diff --git a/src/plugins/acl/exported_types.h b/src/plugins/acl/exported_types.h
index a5b1c3497..b052b818a 100644
--- a/src/plugins/acl/exported_types.h
+++ b/src/plugins/acl/exported_types.h
@@ -16,6 +16,9 @@
 #ifndef included_acl_exported_types_h
 #define included_acl_exported_types_h
 
+#include <vppinfra/types.h>
+#include <vlib/buffer.h>
+
 /* 
  * The overlay struct matching an internal type. Contents/size may change. 
  * During the compile of the ACL plugin it is checked to have the same size
@@ -74,15 +77,25 @@ typedef int (*acl_plugin_match_5tuple_fn_t) (u32 lc_index,
                                            u32 * r_rule_match_p,
                                            u32 * trace_bitmap);
 
+/*
+ * This is an experimental method, subject to change or disappear.
+ */
 
-#define foreach_acl_plugin_exported_method_name \
-_(acl_exists)                          \
-_(register_user_module)                \
-_(get_lookup_context_index)            \
-_(put_lookup_context_index)            \
-_(set_acl_vec_for_context)             \
-_(fill_5tuple)                         \
-_(match_5tuple)                        
+typedef int (*acl_plugin_wip_add_del_custom_access_io_policy_fn_t) (
+  int is_add, u32 sw_if_index, int is_input, void *func);
+
+typedef void (*acl_plugin_wip_clear_sessions_fn_t) (u32 sw_if_index);
+
+#define foreach_acl_plugin_exported_method_name                               \
+  _ (acl_exists)                                                              \
+  _ (register_user_module)                                                    \
+  _ (get_lookup_context_index)                                                \
+  _ (put_lookup_context_index)                                                \
+  _ (set_acl_vec_for_context)                                                 \
+  _ (wip_add_del_custom_access_io_policy)                                     \
+  _ (wip_clear_sessions)                                                      \
+  _ (fill_5tuple)                                                             \
+  _ (match_5tuple)
 
 #define _(name) acl_plugin_ ## name ## _fn_t name;
 typedef struct {
diff --git a/src/plugins/acl/lookup_context.c b/src/plugins/acl/lookup_context.c
index 8d1f3f20f..52641f9e7 100644
--- a/src/plugins/acl/lookup_context.c
+++ b/src/plugins/acl/lookup_context.c
@@ -14,6 +14,7 @@
  */
 
 #include <plugins/acl/acl.h>
+#include <plugins/acl/acl_caiop.h>
 #include <plugins/acl/fa_node.h>
 #include <vlib/unix/plugin.h>
 #include <plugins/acl/public_inlines.h>
@@ -282,7 +283,6 @@ void acl_plugin_lookup_context_notify_acl_change(u32 acl_num)
   }
 }
 
-
 /* Fill the 5-tuple from the packet */
 
 static void acl_plugin_fill_5tuple (u32 lc_index, vlib_buffer_t * b0, int is_ip6, int is_input,
@@ -302,6 +302,13 @@ static int acl_plugin_match_5tuple (u32 lc_index,
   return acl_plugin_match_5tuple_inline (&acl_main, lc_index, pkt_5tuple, is_ip6, r_action, r_acl_pos_p, r_acl_match_p, r_rule_match_p, trace_bitmap);
 }
 
+/* This is an experimental method, subject to change or disappear */
+static int
+acl_plugin_wip_add_del_custom_access_io_policy (int is_add, u32 sw_if_index,
+						int is_input, void *func)
+{
+  return acl_caiop_add_del (is_add, sw_if_index, is_input, func);
+}
 
 void
 acl_plugin_show_lookup_user (u32 user_index)
diff --git a/src/plugins/capo/CMakeLists.txt b/src/plugins/capo/CMakeLists.txt
new file mode 100644
index 000000000..9fa10f710
--- /dev/null
+++ b/src/plugins/capo/CMakeLists.txt
@@ -0,0 +1,28 @@
+# Copyright (c) 2020 Cisco and/or its affiliates.
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at:
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+add_vpp_plugin(capo
+  SOURCES
+  capo_api.c
+  capo_policy.c
+  capo_rule.c
+  capo_ipset.c
+  capo_match.c
+  capo_interface.c
+
+  API_TEST_SOURCES
+  capo_test.c
+
+  API_FILES
+  capo.api
+)
diff --git a/src/plugins/capo/bihash_8_24.h b/src/plugins/capo/bihash_8_24.h
new file mode 100644
index 000000000..79d1005bc
--- /dev/null
+++ b/src/plugins/capo/bihash_8_24.h
@@ -0,0 +1,107 @@
+/*
+ * Copyright (c) 2015 Cisco and/or its affiliates.
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at:
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#undef BIHASH_TYPE
+#undef BIHASH_KVP_PER_PAGE
+#undef BIHASH_32_64_SVM
+#undef BIHASH_ENABLE_STATS
+#undef BIHASH_KVP_AT_BUCKET_LEVEL
+#undef BIHASH_LAZY_INSTANTIATE
+#undef BIHASH_BUCKET_PREFETCH_CACHE_LINES
+
+#define BIHASH_TYPE			   _8_24
+#define BIHASH_KVP_PER_PAGE		   4
+#define BIHASH_KVP_AT_BUCKET_LEVEL	   1
+#define BIHASH_LAZY_INSTANTIATE		   0
+#define BIHASH_BUCKET_PREFETCH_CACHE_LINES 2
+
+#ifndef __included_bihash_8_24_h__
+#define __included_bihash_8_24_h__
+
+#include <vppinfra/heap.h>
+#include <vppinfra/format.h>
+#include <vppinfra/pool.h>
+#include <vppinfra/xxhash.h>
+#include <vppinfra/crc32.h>
+
+/** 8 octet key, 32 octet key value pair */
+typedef struct
+{
+  u64 key;	/**< the key */
+  u64 value[3]; /**< the value */
+} clib_bihash_kv_8_24_t;
+
+/** Decide if a clib_bihash_kv_8_24_t instance is free
+    @param v- pointer to the (key,value) pair
+*/
+static inline int
+clib_bihash_is_free_8_24 (clib_bihash_kv_8_24_t *v)
+{
+  if (v->key == ~0ULL && v->value[0] == ~0ULL && v->value[1] == ~0ULL &&
+      v->value[2] == ~0ULL)
+    return 1;
+  return 0;
+}
+
+/** Hash a clib_bihash_kv_8_24_t instance
+    @param v - pointer to the (key,value) pair, hash the key (only)
+*/
+static inline u64
+clib_bihash_hash_8_24 (clib_bihash_kv_8_24_t *v)
+{
+  /* Note: to torture-test linear scan, make this fn return a constant */
+#ifdef clib_crc32c_uses_intrinsics
+  return clib_crc32c ((u8 *) &v->key, 8);
+#else
+  return clib_xxhash (v->key);
+#endif
+}
+
+/** Format a clib_bihash_kv_8_24_t instance
+    @param s - u8 * vector under construction
+    @param args (vararg) - the (key,value) pair to format
+    @return s - the u8 * vector under construction
+*/
+static inline u8 *
+format_bihash_kvp_8_24 (u8 *s, va_list *args)
+{
+  clib_bihash_kv_8_24_t *v = va_arg (*args, clib_bihash_kv_8_24_t *);
+
+  s = format (s, "key %lu value %lu %lu %lu", v->key, v->value[0], v->value[1],
+	      v->value[2]);
+  return s;
+}
+
+/** Compare two clib_bihash_kv_8_24_t instances
+    @param a - first key
+    @param b - second key
+*/
+static inline int
+clib_bihash_key_compare_8_24 (u64 a, u64 b)
+{
+  return a == b;
+}
+
+#undef __included_bihash_template_h__
+#include <vppinfra/bihash_template.h>
+
+#endif /* __included_bihash_8_24_h__ */
+
+/*
+ * fd.io coding-style-patch-verification: ON
+ *
+ * Local Variables:
+ * eval: (c-set-style "gnu")
+ * End:
+ */
diff --git a/src/plugins/capo/capo.api b/src/plugins/capo/capo.api
new file mode 100644
index 000000000..48732828e
--- /dev/null
+++ b/src/plugins/capo/capo.api
@@ -0,0 +1,260 @@
+/*
+ * Copyright (c) 2020 Cisco and/or its affiliates.
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at:
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+/** \file
+    This file defines the vpp control-plane API messages
+    used to configure Calico policies
+*/
+
+option version = "0.1.0";
+import "vnet/ip/ip_types.api";
+import "vnet/fib/fib_types.api";
+
+/** \brief Get the plugin version
+    @param client_index - opaque cookie to identify the sender
+    @param context - sender context, to match reply w/ request
+*/
+
+define capo_get_version
+{
+  u32 client_index;
+  u32 context;
+};
+
+/** \brief Reply to get the plugin version
+    @param context - returned sender context, to match reply w/ request
+    @param major - Incremented every time a known breaking behavior change is introduced
+    @param minor - Incremented with small changes, may be used to avoid buggy versions
+*/
+
+define capo_get_version_reply
+{
+  u32 context;
+  u32 major;
+  u32 minor;
+};
+
+/** \brief Control ping from client to api server request
+    @param client_index - opaque cookie to identify the sender
+    @param context - sender context, to match reply w/ request
+*/
+define capo_control_ping
+{
+  u32 client_index;
+  u32 context;
+};
+
+/** \brief Control ping from the client to the server response
+    @param client_index - opaque cookie to identify the sender
+    @param context - sender context, to match reply w/ request
+    @param retval - return code for the request
+    @param vpe_pid - the pid of the vpe, returned by the server
+*/
+define capo_control_ping_reply
+{
+  u32 context;
+  i32 retval;
+  u32 client_index;
+  u32 vpe_pid;
+};
+
+
+enum capo_ipset_type : u8 {
+  CAPO_IP = 0,           /* Each member is an IP address */
+  CAPO_IP_AND_PORT = 1,  /* Each member is "<IP>,(tcp|udp):port" (3-tuple) */
+  CAPO_NET = 2,          /* Each member is a CIDR */
+};
+
+typedef capo_three_tuple {
+  vl_api_address_t address;
+  u8 l4_proto;
+  u16 port;
+};
+
+union capo_ipset_member_val {
+  vl_api_address_t address;
+  vl_api_prefix_t prefix;
+  vl_api_capo_three_tuple_t tuple;
+};
+
+typedef capo_ipset_member {
+  vl_api_capo_ipset_member_val_t val;
+};
+
+define capo_ipset_create
+{
+  u32 client_index;
+  u32 context;
+  vl_api_capo_ipset_type_t type;
+};
+
+define capo_ipset_create_reply
+{
+  u32 context;
+  i32 retval;
+  u32 set_id;
+};
+
+
+autoreply define capo_ipset_add_del_members
+{
+  u32 client_index;
+  u32 context;
+  u32 set_id;
+  bool is_add;
+  u32 len;
+  vl_api_capo_ipset_member_t members[len];
+};
+
+autoreply define capo_ipset_delete
+{
+  u32 client_index;
+  u32 context;
+  u32 set_id;
+};
+
+enum capo_rule_action : u8 {
+  CAPO_ALLOW = 0,  // Accept packet
+  CAPO_DENY,       // Drop / reject packet
+  CAPO_LOG,        // Ignored for now
+  CAPO_PASS,       // Skip following rules, resume evaluation at the policy
+                   // with the id configured in capo_configure_policies
+};
+
+enum capo_entry_type : u8 {
+  CAPO_CIDR = 0,     // simple prefix
+  CAPO_PORT_RANGE,
+  CAPO_PORT_IP_SET,  // Points to an ip + proto + port set
+  CAPO_IP_SET,       // Points to an ip only set
+};
+
+typedef capo_port_range {
+  u16 start;
+  u16 end;    // Inclusive, for a single port start==end
+};
+
+typedef capo_entry_set_id {
+  u32 set_id;
+};
+
+union capo_entry_data {
+  vl_api_prefix_t cidr;
+  vl_api_capo_port_range_t port_range;
+  vl_api_capo_entry_set_id_t set_id;
+};
+
+// A rule contains several such entries, each belong to a category
+// categories are: [not_]{src,dst}_{cidr,port_range,port_ip_set,ip_set}
+// (defined byt the 3 first fields in the rule_entry)
+// A rule matches a packet iff:
+// - for every "not" category, the source / destination do not match any entry
+// - for every positive match category, the source / destination matches at
+// least one entry in each category EXCEPT for port ranges and port+ip sets,
+// where the packet only needs to match one entry in either category
+
+typedef capo_rule_entry {
+  bool is_src;
+  bool is_not;
+  vl_api_capo_entry_type_t type;
+  vl_api_capo_entry_data_t data;
+};
+
+enum capo_rule_filter_type : u8 {
+  CAPO_RULE_FILTER_NONE_TYPE = 0,
+  CAPO_RULE_FILTER_ICMP_TYPE,
+  CAPO_RULE_FILTER_ICMP_CODE,
+  CAPO_RULE_FILTER_L4_PROTO,
+};
+
+typedef capo_rule_filter {
+  u32 value;
+  vl_api_capo_rule_filter_type_t type;
+  u8 should_match;
+};
+
+typedef capo_rule {
+  vl_api_address_family_t af;
+  vl_api_capo_rule_action_t action;
+  vl_api_capo_rule_filter_t filters[3];
+  u32 num_entries;
+  vl_api_capo_rule_entry_t matches[num_entries]; // List of other criteria
+};
+
+define capo_rule_create {
+  u32 client_index;
+  u32 context;
+  vl_api_capo_rule_t rule;
+};
+
+autoreply define capo_rule_update {
+  u32 client_index;
+  u32 context;
+  u32 rule_id;
+  vl_api_capo_rule_t rule;
+};
+
+define capo_rule_create_reply {
+  u32 context;
+  i32 retval;
+  u32 rule_id;
+};
+
+autoreply define capo_rule_delete {
+  u32 client_index;
+  u32 context;
+  u32 rule_id;
+};
+
+typedef capo_policy_item {
+  bool is_inbound; // 0 for outbound, 1 for is_inbound
+  u32 rule_id;
+};
+
+define capo_policy_create {
+  u32 client_index;
+  u32 context;
+  u32 num_items;
+  vl_api_capo_policy_item_t rules[num_items];
+};
+
+define capo_policy_create_reply {
+  u32 context;
+  i32 retval;
+  u32 policy_id;
+};
+
+autoreply define capo_policy_update {
+  u32 client_index;
+  u32 context;
+  u32 policy_id;
+  u32 num_items;
+  vl_api_capo_policy_item_t rules[num_items];
+};
+
+autoreply define capo_policy_delete {
+  u32 client_index;
+  u32 context;
+  u32 policy_id;
+};
+
+autoreply define capo_configure_policies {
+  u32 client_index;
+  u32 context;
+  u32 sw_if_index;
+  u32 num_ingress_policies;
+  u32 num_egress_policies;
+  u32 total_ids;
+  u32 policy_ids[total_ids]; // ingress, then egress, then profiles
+};
diff --git a/src/plugins/capo/capo.h b/src/plugins/capo/capo.h
new file mode 100644
index 000000000..812d14831
--- /dev/null
+++ b/src/plugins/capo/capo.h
@@ -0,0 +1,58 @@
+/*
+ * Copyright (c) 2020 Cisco and/or its affiliates.
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at:
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef included_capo_h
+#define included_capo_h
+
+#include <vnet/ip/ip.h>
+#include <vnet/ip/ip_types_api.h>
+#include <acl/public_inlines.h>
+#include <capo/bihash_8_24.h>
+
+#include <capo/capo.api_enum.h>
+#include <capo/capo.api_types.h>
+#include <capo/capo_interface.h>
+
+#define CAPO_INVALID_INDEX ((u32) ~0)
+
+typedef struct
+{
+  u16 start;
+  u16 end;
+} capo_port_range_t;
+
+typedef struct
+{
+  clib_bihash_8_24_t if_config; /* sw_if_index -> capo_interface_config */
+
+  u32 calico_acl_user_id;
+  acl_plugin_methods_t acl_plugin;
+
+  /* API message ID base */
+  u16 msg_id_base;
+
+} capo_main_t;
+
+extern capo_main_t capo_main;
+
+#endif
+
+/*
+ * fd.io coding-style-patch-verification: ON
+ *
+ * Local Variables:
+ * eval: (c-set-style "gnu")
+ * End:
+ */
diff --git a/src/plugins/capo/capo_api.c b/src/plugins/capo/capo_api.c
new file mode 100644
index 000000000..c44b77eda
--- /dev/null
+++ b/src/plugins/capo/capo_api.c
@@ -0,0 +1,444 @@
+/*
+ * Copyright (c) 2020 Cisco and/or its affiliates.
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at:
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include <vnet/vnet.h>
+#include <vnet/plugin/plugin.h>
+#include <vlibapi/api.h>
+#include <vlibmemory/api.h>
+#include <vpp/app/version.h>
+#include <stdbool.h>
+
+#include <capo/capo.h>
+#include <capo/capo_rule.h>
+#include <capo/capo_policy.h>
+#include <capo/capo_ipset.h>
+#include <capo/capo_interface.h>
+
+#define REPLY_MSG_ID_BASE cpm->msg_id_base
+#include <vlibapi/api_helper_macros.h>
+
+#define CALICO_POLICY_VERSION_MAJOR 0
+#define CALICO_POLICY_VERSION_MINOR 0
+
+capo_main_t capo_main = { 0 };
+
+void
+capo_policy_rule_decode (const vl_api_capo_policy_item_t *in,
+			 capo_policy_rule_t *out)
+{
+  out->rule_id = clib_net_to_host_u32 (in->rule_id);
+  out->direction = in->is_inbound ? VLIB_RX : VLIB_TX;
+}
+
+int
+capo_ipset_member_decode (capo_ipset_type_t type,
+			  const vl_api_capo_ipset_member_t *in,
+			  capo_ipset_member_t *out)
+{
+  switch (type)
+    {
+    case IPSET_TYPE_IP:
+      ip_address_decode2 (&in->val.address, &out->address);
+      break;
+    case IPSET_TYPE_IPPORT:
+      ip_address_decode2 (&in->val.tuple.address, &out->ipport.addr);
+      out->ipport.l4proto = in->val.tuple.l4_proto;
+      out->ipport.port = clib_net_to_host_u16 (in->val.tuple.port);
+      break;
+    case IPSET_TYPE_NET:
+      return ip_prefix_decode2 (&in->val.prefix, &out->prefix);
+    }
+  return 0;
+}
+
+void
+capo_port_range_decode (const vl_api_capo_port_range_t *in,
+			capo_port_range_t *out)
+{
+  out->start = clib_net_to_host_u16 (in->start);
+  out->end = clib_net_to_host_u16 (in->end);
+}
+
+int
+capo_rule_entry_decode (const vl_api_capo_rule_entry_t *in,
+			capo_rule_entry_t *out)
+{
+  out->flags = 0;
+  if (in->is_src)
+    out->flags |= CAPO_IS_SRC;
+  if (in->is_not)
+    out->flags |= CAPO_IS_NOT;
+  out->type = (capo_entry_type_t) in->type;
+  switch (in->type)
+    {
+    case CAPO_CIDR:
+      return ip_prefix_decode2 (&in->data.cidr, &out->data.cidr);
+    case CAPO_PORT_RANGE:
+      capo_port_range_decode (&in->data.port_range, &out->data.port_range);
+      return 0;
+    case CAPO_PORT_IP_SET:
+    case CAPO_IP_SET:
+      out->data.set_id = clib_net_to_host_u32 (in->data.set_id.set_id);
+      return 0;
+    default:
+      return -1;
+    }
+}
+
+void
+capo_rule_filter_decode (const vl_api_capo_rule_filter_t *in,
+			 capo_rule_filter_t *out)
+{
+  out->type = (capo_rule_filter_type_t) in->type;
+  out->should_match = in->should_match;
+  out->value = clib_net_to_host_u32 (in->value);
+}
+
+static void
+vl_api_capo_get_version_t_handler (vl_api_capo_get_version_t *mp)
+{
+  capo_main_t *cpm = &capo_main;
+  vl_api_capo_get_version_reply_t *rmp;
+  int msg_size = sizeof (*rmp);
+  vl_api_registration_t *reg;
+
+  reg = vl_api_client_index_to_registration (mp->client_index);
+  if (!reg)
+    return;
+
+  rmp = vl_msg_api_alloc (msg_size);
+  clib_memset (rmp, 0, msg_size);
+  rmp->_vl_msg_id = ntohs (VL_API_CAPO_GET_VERSION_REPLY + cpm->msg_id_base);
+  rmp->context = mp->context;
+  rmp->major = htonl (CALICO_POLICY_VERSION_MAJOR);
+  rmp->minor = htonl (CALICO_POLICY_VERSION_MINOR);
+
+  vl_api_send_msg (reg, (u8 *) rmp);
+}
+
+static void
+vl_api_capo_control_ping_t_handler (vl_api_capo_control_ping_t *mp)
+{
+  capo_main_t *cpm = &capo_main;
+  vl_api_capo_control_ping_reply_t *rmp;
+  int rv = 0;
+
+  REPLY_MACRO2 (VL_API_CAPO_CONTROL_PING_REPLY,
+		({ rmp->vpe_pid = ntohl (getpid ()); }));
+}
+
+/* NAME: ipset_create */
+static void
+vl_api_capo_ipset_create_t_handler (vl_api_capo_ipset_create_t *mp)
+{
+  capo_main_t *cpm = &capo_main;
+  vl_api_capo_ipset_create_reply_t *rmp;
+  int rv = 0;
+  u32 id;
+
+  id = capo_ipset_create ((capo_ipset_type_t) mp->type);
+
+  REPLY_MACRO2 (VL_API_CAPO_IPSET_CREATE_REPLY,
+		({ rmp->set_id = clib_host_to_net_u32 (id); }));
+}
+
+/* NAME: ipset_add_del_members */
+static void
+vl_api_capo_ipset_add_del_members_t_handler (
+  vl_api_capo_ipset_add_del_members_t *mp)
+{
+  capo_main_t *cpm = &capo_main;
+  vl_api_capo_ipset_add_del_members_reply_t *rmp;
+  u32 set_id, i, n_members;
+  capo_ipset_type_t type;
+  int rv = 0;
+
+  set_id = clib_net_to_host_u32 (mp->set_id);
+  n_members = clib_net_to_host_u32 (mp->len);
+
+  rv = capo_ipset_get_type (set_id, &type);
+  if (rv)
+    goto done;
+
+  for (i = 0; i < n_members; i++)
+    {
+      capo_ipset_member_t _m, *member = &_m;
+      rv = capo_ipset_member_decode (type, &mp->members[i], member);
+      if (rv)
+	break;
+      if (mp->is_add)
+	rv = capo_ipset_add_member (set_id, member);
+      else
+	rv = capo_ipset_del_member (set_id, member);
+      if (rv)
+	break;
+    }
+
+done:
+  REPLY_MACRO (VL_API_CAPO_IPSET_ADD_DEL_MEMBERS_REPLY);
+}
+
+/* NAME: ipset_delete */
+static void
+vl_api_capo_ipset_delete_t_handler (vl_api_capo_ipset_delete_t *mp)
+{
+  capo_main_t *cpm = &capo_main;
+  vl_api_capo_ipset_delete_reply_t *rmp;
+  u32 set_id;
+  int rv;
+
+  set_id = clib_net_to_host_u32 (mp->set_id);
+  rv = capo_ipset_delete (set_id);
+
+  REPLY_MACRO (VL_API_CAPO_IPSET_DELETE_REPLY);
+}
+
+static int
+vl_api_capo_rule_update_create_handler (u32 *id, vl_api_capo_rule_t *rule)
+{
+  capo_rule_filter_t *filters = 0, *filter;
+  capo_rule_entry_t *entries = 0, *entry;
+  capo_rule_action_t action;
+  ip_address_family_t af = 0;
+  int rv;
+  u32 n_matches;
+  u32 i;
+
+  action = (capo_rule_action_t) rule->action;
+
+  // if ((rv = ip_address_family_decode (rule->af, &af)))
+  //   goto done;
+
+  for (i = 0; i < ARRAY_LEN (rule->filters); i++)
+    {
+      vec_add2 (filters, filter, 1);
+      capo_rule_filter_decode (&rule->filters[i], filter);
+    }
+
+  n_matches = clib_net_to_host_u32 (rule->num_entries);
+  for (i = 0; i < n_matches; i++)
+    {
+      vec_add2 (entries, entry, 1);
+      if ((rv = capo_rule_entry_decode (&rule->matches[i], entry)))
+	goto done;
+    }
+
+  rv = capo_rule_update (id, action, af, filters, entries);
+
+done:
+  vec_free (filters);
+  vec_free (entries);
+  return rv;
+}
+
+/* NAME: rule_create */
+static void
+vl_api_capo_rule_create_t_handler (vl_api_capo_rule_create_t *mp)
+{
+  vl_api_capo_rule_create_reply_t *rmp;
+  capo_main_t *cpm = &capo_main;
+  u32 id = CAPO_INVALID_INDEX;
+  int rv;
+
+  rv = vl_api_capo_rule_update_create_handler (&id, &mp->rule);
+
+  REPLY_MACRO2 (VL_API_CAPO_RULE_CREATE_REPLY,
+		({ rmp->rule_id = clib_host_to_net_u32 (id); }));
+}
+
+/* NAME: rule_update */
+static void
+vl_api_capo_rule_update_t_handler (vl_api_capo_rule_update_t *mp)
+{
+  vl_api_capo_rule_update_reply_t *rmp;
+  capo_main_t *cpm = &capo_main;
+  u32 id;
+  int rv;
+
+  id = clib_net_to_host_u32 (mp->rule_id);
+  rv = vl_api_capo_rule_update_create_handler (&id, &mp->rule);
+
+  REPLY_MACRO (VL_API_CAPO_RULE_UPDATE_REPLY);
+}
+
+/* NAME: rule_delete */
+static void
+vl_api_capo_rule_delete_t_handler (vl_api_capo_rule_delete_t *mp)
+{
+  vl_api_capo_rule_delete_reply_t *rmp;
+  capo_main_t *cpm = &capo_main;
+  u32 id;
+  int rv;
+
+  id = clib_net_to_host_u32 (mp->rule_id);
+  rv = capo_rule_delete (id);
+
+  REPLY_MACRO (VL_API_CAPO_RULE_DELETE_REPLY);
+}
+
+static int
+vl_api_capo_policy_update_create_handler (u32 *id, u32 n_rules,
+					  vl_api_capo_policy_item_t *api_rules)
+{
+  capo_policy_rule_t *rules = 0, *rule;
+  int rv;
+
+  for (u32 i = 0; i < n_rules; i++)
+    {
+      vec_add2 (rules, rule, 1);
+      capo_policy_rule_decode (&api_rules[i], rule);
+    }
+
+  rv = capo_policy_update (id, rules);
+
+  vec_free (rules);
+  return rv;
+}
+
+/* NAME: policy_create */
+static void
+vl_api_capo_policy_create_t_handler (vl_api_capo_policy_create_t *mp)
+{
+  vl_api_capo_policy_create_reply_t *rmp;
+  capo_main_t *cpm = &capo_main;
+  u32 id = CAPO_INVALID_INDEX, n_rules;
+  int rv;
+
+  n_rules = clib_net_to_host_u32 (mp->num_items);
+  rv = vl_api_capo_policy_update_create_handler (&id, n_rules, mp->rules);
+
+  REPLY_MACRO2 (VL_API_CAPO_POLICY_CREATE_REPLY,
+		({ rmp->policy_id = clib_host_to_net_u32 (id); }));
+}
+
+/* NAME: policy_update */
+static void
+vl_api_capo_policy_update_t_handler (vl_api_capo_policy_update_t *mp)
+{
+  vl_api_capo_policy_update_reply_t *rmp;
+  capo_main_t *cpm = &capo_main;
+  u32 id, n_rules;
+  int rv;
+
+  id = clib_net_to_host_u32 (mp->policy_id);
+  n_rules = clib_net_to_host_u32 (mp->num_items);
+  rv = vl_api_capo_policy_update_create_handler (&id, n_rules, mp->rules);
+
+  REPLY_MACRO (VL_API_CAPO_POLICY_UPDATE_REPLY);
+}
+
+/* NAME: policy_delete */
+static void
+vl_api_capo_policy_delete_t_handler (vl_api_capo_policy_delete_t *mp)
+{
+  vl_api_capo_policy_delete_reply_t *rmp;
+  capo_main_t *cpm = &capo_main;
+  u32 id;
+  int rv = 0;
+
+  id = clib_net_to_host_u32 (mp->policy_id);
+  rv = capo_policy_delete (id);
+
+  REPLY_MACRO (VL_API_CAPO_POLICY_DELETE_REPLY);
+}
+
+/* NAME: configure_policies */
+static void
+vl_api_capo_configure_policies_t_handler (vl_api_capo_configure_policies_t *mp)
+{
+  vl_api_capo_configure_policies_reply_t *rmp;
+  capo_main_t *cpm = &capo_main;
+  u32 num_profiles;
+  int rv = -1;
+  int i = 0;
+
+  mp->sw_if_index = clib_net_to_host_u32 (mp->sw_if_index);
+  mp->num_ingress_policies = clib_net_to_host_u32 (mp->num_ingress_policies);
+  mp->num_egress_policies = clib_net_to_host_u32 (mp->num_egress_policies);
+  mp->total_ids = clib_net_to_host_u32 (mp->total_ids);
+  num_profiles =
+    mp->total_ids - mp->num_ingress_policies - mp->num_egress_policies;
+  for (i = 0; i < mp->total_ids; i++)
+    {
+      mp->policy_ids[i] = clib_net_to_host_u32 (mp->policy_ids[i]);
+    }
+
+  rv = capo_configure_policies (mp->sw_if_index, mp->num_ingress_policies,
+				mp->num_egress_policies, num_profiles,
+				mp->policy_ids);
+
+  REPLY_MACRO (VL_API_CAPO_CONFIGURE_POLICIES_REPLY);
+}
+
+/* Set up the API message handling tables */
+#include <vnet/format_fns.h>
+#include <capo/capo.api.c>
+
+#include <vat/vat.h>
+#include <vlibapi/vat_helper_macros.h>
+
+/* Declare message IDs */
+#include <acl/acl.api_enum.h>
+#include <acl/acl.api_types.h>
+#undef vl_print
+#define vl_print(handle, ...)
+#undef vl_print
+#define vl_endianfun /* define message structures */
+#include <acl/acl.api.h>
+#undef vl_endianfun
+
+static clib_error_t *
+calpol_init (vlib_main_t *vm)
+{
+  capo_main_t *cpm = &capo_main;
+
+  clib_error_t *acl_init_res = acl_plugin_exports_init (&cpm->acl_plugin);
+  if (acl_init_res)
+    return (acl_init_res);
+
+  cpm->calico_acl_user_id =
+    cpm->acl_plugin.register_user_module ("Calico Policy Plugin", NULL, NULL);
+
+  cpm->msg_id_base = setup_message_id_table ();
+
+  clib_bihash_init_8_24 (&cpm->if_config, "capo interfaces", 512, 1 << 20);
+
+  return (NULL);
+}
+
+static clib_error_t *
+calpol_plugin_config (vlib_main_t *vm, unformat_input_t *input)
+{
+  return NULL;
+}
+
+VLIB_PLUGIN_REGISTER () = {
+  .version = VPP_BUILD_VER,
+  .description = "Calico Policy",
+};
+
+VLIB_CONFIG_FUNCTION (calpol_plugin_config, "calico-policy-plugin");
+
+VLIB_INIT_FUNCTION (calpol_init) = {
+  .runs_after = VLIB_INITS ("acl_init"),
+};
+
+/*
+ * fd.io coding-style-patch-verification: ON
+ *
+ * Local Variables:
+ * eval: (c-set-style "gnu")
+ * End:
+ */
diff --git a/src/plugins/capo/capo_interface.c b/src/plugins/capo/capo_interface.c
new file mode 100644
index 000000000..d13d58ff4
--- /dev/null
+++ b/src/plugins/capo/capo_interface.c
@@ -0,0 +1,340 @@
+/*
+ * Copyright (c) 2020 Cisco and/or its affiliates.
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at:
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include <capo/capo.h>
+#include <capo/capo_match.h>
+#include <capo/capo_policy.h>
+
+uword unformat_sw_if_index (unformat_input_t *input, va_list *args);
+
+static int
+print_capo_interface2 (clib_bihash_kv_8_24_t *kv, void *arg)
+{
+  u8 **s = (u8 **) arg;
+  u32 sw_if_index = kv->key;
+  capo_interface_config_t *conf = (capo_interface_config_t *) kv->value;
+  *s = format (*s, "%U", format_capo_interface, sw_if_index, conf);
+  return BIHASH_WALK_CONTINUE;
+}
+
+void
+capo_interface_print_current_state ()
+{
+  u8 *s = 0;
+  clib_bihash_foreach_key_value_pair_8_24 (&capo_main.if_config,
+					   print_capo_interface2, (void *) &s);
+  clib_warning ("Current interface state:\n%s", s);
+  vec_free (s);
+}
+
+int
+capo_configure_policies (u32 sw_if_index, u32 num_ingress, u32 num_egress,
+			 u32 num_profiles, u32 *policy_ids)
+{
+  clib_bihash_kv_8_24_t kv = { sw_if_index, { 0 } };
+  capo_interface_config_t *conf = (capo_interface_config_t *) &kv.value;
+  capo_interface_config_t *old_conf;
+  u32 found = 0, i = 0;
+
+  if (pool_is_free_index (vnet_get_main ()->interface_main.sw_interfaces,
+			  sw_if_index))
+    {
+      clib_warning (
+	"configuring policies for interface %u which doesn't exist",
+	sw_if_index);
+      return VNET_API_ERROR_INVALID_SW_IF_INDEX;
+    }
+
+  if (clib_bihash_search_8_24 (&capo_main.if_config, &kv, &kv) >= 0)
+    {
+      old_conf = (capo_interface_config_t *) &kv.value;
+      vec_free (old_conf->ingress_policies);
+      vec_free (old_conf->egress_policies);
+      vec_free (old_conf->profiles);
+      found = 1;
+    }
+
+  clib_warning ("configuring policies for if %u", sw_if_index);
+
+  for (i = 0; i < num_ingress + num_egress + num_profiles; i++)
+    if (pool_is_free_index (capo_policies, policy_ids[i]))
+      goto error;
+
+  vec_resize (conf->ingress_policies, num_ingress);
+  for (i = 0; i < num_ingress; i++)
+    conf->ingress_policies[i] = policy_ids[i];
+  vec_resize (conf->egress_policies, num_egress);
+  for (i = 0; i < num_egress; i++)
+    conf->egress_policies[i] = policy_ids[num_ingress + i];
+  vec_resize (conf->profiles, num_profiles);
+  for (i = 0; i < num_profiles; i++)
+    conf->profiles[i] = policy_ids[num_ingress + num_egress + i];
+
+  clib_bihash_add_del_8_24 (&capo_main.if_config, &kv, 1 /* is_add */);
+
+  if (!found)
+    {
+      capo_main.acl_plugin.wip_add_del_custom_access_io_policy (
+	1 /* is_add */, sw_if_index, 0 /* is_input */, capo_match_func);
+      capo_main.acl_plugin.wip_add_del_custom_access_io_policy (
+	1 /* is_add */, sw_if_index, 1 /* is_input */, capo_match_func);
+    }
+
+  capo_main.acl_plugin.wip_clear_sessions (sw_if_index);
+  return 0;
+
+error:
+  clib_warning ("error configuring policies for %u", sw_if_index);
+  vec_resize (conf->ingress_policies, 0);
+  vec_resize (conf->egress_policies, 0);
+  vec_resize (conf->profiles, 0);
+  return 1;
+}
+
+static clib_error_t *
+capo_sw_interface_add_del (vnet_main_t *vnm, u32 sw_if_index, u32 is_add)
+{
+  clib_bihash_kv_8_24_t kv = { sw_if_index, { 0 } };
+  capo_interface_config_t *conf = (capo_interface_config_t *) &kv.value;
+  int rv = 0;
+
+  if (is_add)
+    return NULL;
+
+  if (clib_bihash_search_8_24 (&capo_main.if_config, &kv, &kv) >= 0)
+    {
+      conf = (capo_interface_config_t *) &kv.value;
+      vec_free (conf->ingress_policies);
+      vec_free (conf->egress_policies);
+      vec_free (conf->profiles);
+    }
+
+  clib_warning ("unconfiguring policies for if %u deleted", sw_if_index);
+  clib_bihash_add_del_8_24 (&capo_main.if_config, &kv, 0 /* is_add */);
+  rv = capo_main.acl_plugin.wip_add_del_custom_access_io_policy (
+    0 /* is_add */, sw_if_index, 0 /* is_input */
+    ,
+    capo_match_func);
+  if (rv)
+    clib_warning ("error deleting caiop (output): %d", rv);
+  rv = capo_main.acl_plugin.wip_add_del_custom_access_io_policy (
+    0 /* is_add */, sw_if_index, 1 /* is_input */
+    ,
+    capo_match_func);
+  if (rv)
+    clib_warning ("error deleting caiop (input): %d", rv);
+  return NULL;
+}
+
+VNET_SW_INTERFACE_ADD_DEL_FUNCTION (capo_sw_interface_add_del);
+
+u8 *
+format_capo_interface (u8 *s, va_list *args)
+{
+  u32 sw_if_index = va_arg (*args, u32);
+  capo_interface_config_t *conf = va_arg (*args, capo_interface_config_t *);
+  vnet_main_t *vnm = vnet_get_main ();
+  capo_policy_t *policy = NULL;
+  u32 i;
+
+  s = format (s, "[%U sw_if_index=%u addr=", format_vnet_sw_if_index_name, vnm,
+	      sw_if_index, sw_if_index);
+  ip4_address_t *ip4 = 0;
+  ip4 = ip4_interface_first_address (&ip4_main, sw_if_index, 0);
+  if (ip4)
+    s = format (s, "%U", format_ip4_address, ip4);
+  s = format (s, "]\n");
+  if (vec_len (conf->ingress_policies))
+    s = format (s, "  ingress:\n");
+  vec_foreach_index (i, conf->ingress_policies)
+    {
+      policy = capo_policy_get_if_exists (conf->ingress_policies[i]);
+      s = format (s, "    %U", format_capo_policy, policy, 4 /* indent */,
+		  CAPO_POLICY_ONLY_INGRESS);
+    }
+  if (vec_len (conf->egress_policies))
+    s = format (s, "  egress:\n");
+  vec_foreach_index (i, conf->egress_policies)
+    {
+      policy = capo_policy_get_if_exists (conf->egress_policies[i]);
+      s = format (s, "    %U", format_capo_policy, policy, 4 /* indent */,
+		  CAPO_POLICY_ONLY_EGRESS);
+    }
+  if (vec_len (conf->profiles))
+    s = format (s, "  profiles:\n");
+  vec_foreach_index (i, conf->profiles)
+    {
+      policy = capo_policy_get_if_exists (conf->profiles[i]);
+      s = format (s, "    %U", format_capo_policy, policy, 4 /* indent */,
+		  CAPO_POLICY_VERBOSE);
+    }
+  return s;
+}
+
+int
+print_capo_interface (clib_bihash_kv_8_24_t *kv, void *arg)
+{
+  vlib_main_t *vm = (vlib_main_t *) arg;
+  u32 sw_if_index = kv->key;
+  capo_interface_config_t *conf = (capo_interface_config_t *) kv->value;
+  vlib_cli_output (vm, "%U", format_capo_interface, sw_if_index, conf);
+  return BIHASH_WALK_CONTINUE;
+}
+
+static clib_error_t *
+capo_interface_show_cmd_fn (vlib_main_t *vm, unformat_input_t *input,
+			    vlib_cli_command_t *cmd)
+{
+  vlib_cli_output (vm, "Interfaces with policies configured:");
+  clib_bihash_foreach_key_value_pair_8_24 (&capo_main.if_config,
+					   print_capo_interface, vm);
+  return NULL;
+}
+
+VLIB_CLI_COMMAND (capo_policies_show_cmd, static) = {
+  .path = "show capo interfaces",
+  .function = capo_interface_show_cmd_fn,
+  .short_help = "show capo interfaces",
+};
+
+static clib_error_t *
+capo_interface_clear_cmd_fn (vlib_main_t *vm, unformat_input_t *input,
+			     vlib_cli_command_t *cmd)
+{
+  unformat_input_t _line_input, *line_input = &_line_input;
+  clib_error_t *error = 0;
+  u32 sw_if_index = CAPO_INVALID_INDEX;
+  int rv;
+
+  if (!unformat_user (input, unformat_line_input, line_input))
+    return clib_error_return (0, "missing parameters");
+
+  while (unformat_check_input (line_input) != UNFORMAT_END_OF_INPUT)
+    {
+      if (unformat (line_input, "%U", unformat_sw_if_index, NULL,
+		    &sw_if_index))
+	;
+      else if (unformat (line_input, "sw_if_index %d", &sw_if_index))
+	;
+      else
+	{
+	  error = clib_error_return (0, "unknown input '%U'",
+				     format_unformat_error, line_input);
+	  goto done;
+	}
+    }
+
+  if (sw_if_index == CAPO_INVALID_INDEX)
+    {
+      error = clib_error_return (0, "interface not specified");
+      goto done;
+    }
+
+  rv = capo_configure_policies (sw_if_index, 0, 0, 0, NULL);
+  if (rv)
+    error =
+      clib_error_return (0, "capo_configure_policies errored with %d", rv);
+  else
+    vlib_cli_output (vm, "capo interface %d cleared", sw_if_index);
+
+done:
+  unformat_free (line_input);
+  return error;
+}
+
+VLIB_CLI_COMMAND (capo_interface_clear_cmd, static) = {
+  .path = "capo interface clear",
+  .function = capo_interface_clear_cmd_fn,
+  .short_help = "capo interface clear [interface | sw_if_index N]",
+};
+
+static clib_error_t *
+capo_interface_configure_cmd_fn (vlib_main_t *vm, unformat_input_t *input,
+				 vlib_cli_command_t *cmd)
+{
+  unformat_input_t _line_input, *line_input = &_line_input;
+  clib_error_t *error = 0;
+  u32 sw_if_index = CAPO_INVALID_INDEX;
+  u32 num_ingress = 0;
+  u32 num_egress = 0;
+  u32 policy_id;
+  u32 *policy_list = NULL;
+  int rv;
+
+  if (!unformat_user (input, unformat_line_input, line_input))
+    return clib_error_return (0, "missing parameters");
+
+  while (unformat_check_input (line_input) != UNFORMAT_END_OF_INPUT)
+    {
+      if (unformat (line_input, "%U", unformat_sw_if_index, NULL,
+		    &sw_if_index))
+	;
+      else if (unformat (line_input, "sw_if_index %d", &sw_if_index))
+	;
+      else if (unformat (line_input, "in %d", &num_ingress))
+	;
+      else if (unformat (line_input, "out %d", &num_egress))
+	;
+      else if (unformat (line_input, "%d", &policy_id))
+	vec_add1 (policy_list, policy_id);
+      else
+	{
+	  error = clib_error_return (0, "unknown input '%U'",
+				     format_unformat_error, line_input);
+	  goto done;
+	}
+    }
+
+  if (sw_if_index == CAPO_INVALID_INDEX)
+    {
+      error = clib_error_return (0, "interface not specified");
+      goto done;
+    }
+  if (!vec_len (policy_list))
+    {
+      error = clib_error_return (0, "no policies specified");
+      goto done;
+    }
+
+  rv = capo_configure_policies (
+    sw_if_index, num_ingress, num_egress,
+    vec_len (policy_list) - num_ingress - num_egress, policy_list);
+
+  if (rv)
+    error =
+      clib_error_return (0, "capo_configure_policies errored with %d", rv);
+  else
+    vlib_cli_output (vm, "capo interface %d configured", sw_if_index);
+
+done:
+  unformat_free (line_input);
+  vec_free (policy_list);
+  return error;
+}
+
+VLIB_CLI_COMMAND (capo_interface_configure_cmd, static) = {
+  .path = "capo interface configure",
+  .function = capo_interface_configure_cmd_fn,
+  .short_help = "capo interface configure [interface | sw_if_index N] in "
+		"<num_ingress> out <num_egress> <policy_id> ...",
+};
+
+/*
+ * fd.io coding-style-patch-verification: ON
+ *
+ * Local Variables:
+ * eval: (c-set-style "gnu")
+ * End:
+ */
diff --git a/src/plugins/capo/capo_interface.h b/src/plugins/capo/capo_interface.h
new file mode 100644
index 000000000..f02c608a8
--- /dev/null
+++ b/src/plugins/capo/capo_interface.h
@@ -0,0 +1,40 @@
+/*
+ * Copyright (c) 2020 Cisco and/or its affiliates.
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at:
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef included_capo_interface_h
+#define included_capo_interface_h
+
+#include <vppinfra/clib.h>
+
+typedef struct
+{
+  u32 *ingress_policies;
+  u32 *egress_policies;
+  u32 *profiles;
+} capo_interface_config_t;
+
+int capo_configure_policies (u32 sw_if_index, u32 num_ingress, u32 num_egress,
+			     u32 num_profiles, u32 *policy_ids);
+u8 *format_capo_interface (u8 *s, va_list *args);
+
+#endif
+
+/*
+ * fd.io coding-style-patch-verification: ON
+ *
+ * Local Variables:
+ * eval: (c-set-style "gnu")
+ * End:
+ */
diff --git a/src/plugins/capo/capo_ipset.c b/src/plugins/capo/capo_ipset.c
new file mode 100644
index 000000000..32db3b957
--- /dev/null
+++ b/src/plugins/capo/capo_ipset.c
@@ -0,0 +1,472 @@
+/*
+ * Copyright (c) 2020 Cisco and/or its affiliates.
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at:
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include <capo/capo.h>
+#include <capo/capo_ipset.h>
+
+capo_ipset_t *capo_ipsets;
+
+u8 *
+format_capo_ipport (u8 *s, va_list *args)
+{
+  capo_ipport_t *ipport = va_arg (*args, capo_ipport_t *);
+  return format (s, "%U %U;%u", format_ip_protocol, ipport->l4proto,
+		 format_ip_address, &ipport->addr, ipport->port);
+}
+
+u8 *
+format_capo_ipset_member (u8 *s, va_list *args)
+{
+  capo_ipset_member_t *member = va_arg (*args, capo_ipset_member_t *);
+  capo_ipset_type_t type = va_arg (*args, capo_ipset_type_t);
+  switch (type)
+    {
+    case IPSET_TYPE_IP:
+      return format (s, "%U", format_ip_address, &member->address);
+    case IPSET_TYPE_IPPORT:
+      return format (s, "%U", format_capo_ipport, &member->ipport);
+    case IPSET_TYPE_NET:
+      return format (s, "%U", format_ip_prefix, &member->prefix);
+    default:
+      return format (s, "unknown type");
+    }
+}
+
+uword
+unformat_capo_ipport (unformat_input_t *input, va_list *args)
+{
+  capo_ipport_t *ipport = va_arg (*args, capo_ipport_t *);
+  u32 proto;
+  u32 port;
+  if (unformat (input, "%U %U %d", unformat_ip_protocol, &proto,
+		unformat_ip_address, &ipport->addr, &port))
+    ;
+  else
+    return 0;
+
+  ipport->port = port;
+  ipport->l4proto = (u8) proto;
+  return 1;
+}
+
+u8 *
+format_capo_ipset_type (u8 *s, va_list *args)
+{
+  capo_ipset_type_t type = va_arg (*args, capo_ipset_type_t);
+  switch (type)
+    {
+    case IPSET_TYPE_IP:
+      return format (s, "ip");
+    case IPSET_TYPE_IPPORT:
+      return format (s, "ip+port");
+    case IPSET_TYPE_NET:
+      return format (s, "prefix");
+    default:
+      return format (s, "unknownipsettype");
+    }
+}
+
+uword
+unformat_capo_ipset_member (unformat_input_t *input, va_list *args)
+{
+  capo_ipset_member_t *member = va_arg (*args, capo_ipset_member_t *);
+  capo_ipset_type_t *type = va_arg (*args, capo_ipset_type_t *);
+  if (unformat_user (input, unformat_ip_prefix, &member->prefix))
+    *type = IPSET_TYPE_NET;
+  else if (unformat_user (input, unformat_ip_address, &member->address))
+    *type = IPSET_TYPE_IP;
+  else if (unformat_user (input, unformat_capo_ipport, &member->ipport))
+    *type = IPSET_TYPE_IPPORT;
+  else
+    return 0;
+
+  return 1;
+}
+
+u8 *
+format_capo_ipset (u8 *s, va_list *args)
+{
+  capo_ipset_t *ipset = va_arg (*args, capo_ipset_t *);
+  capo_ipset_member_t *member;
+
+  if (ipset == NULL)
+    return format (s, "deleted ipset");
+
+  s = format (s, "[ipset#%d;%U;", ipset - capo_ipsets, format_capo_ipset_type,
+	      ipset->type);
+
+  pool_foreach (member, ipset->members)
+    s = format (s, "%U,", format_capo_ipset_member, member, ipset->type);
+
+  s = format (s, "]");
+
+  return (s);
+}
+
+capo_ipset_t *
+capo_ipsets_get_if_exists (u32 index)
+{
+  if (pool_is_free_index (capo_ipsets, index))
+    return (NULL);
+  return pool_elt_at_index (capo_ipsets, index);
+}
+
+u32
+capo_ipset_create (capo_ipset_type_t type)
+{
+  capo_ipset_t *ipset;
+  pool_get (capo_ipsets, ipset);
+  ipset->type = type;
+  ipset->members = NULL;
+  return ipset - capo_ipsets;
+}
+
+int
+capo_ipset_delete (u32 id)
+{
+  capo_ipset_t *ipset;
+  ipset = capo_ipsets_get_if_exists (id);
+  if (NULL == ipset)
+    return VNET_API_ERROR_NO_SUCH_ENTRY;
+
+  pool_free (ipset->members);
+  pool_put (capo_ipsets, ipset);
+  return 0;
+}
+
+int
+capo_ipset_get_type (u32 id, capo_ipset_type_t *type)
+{
+  capo_ipset_t *ipset;
+  ipset = capo_ipsets_get_if_exists (id);
+  if (NULL == ipset)
+    return VNET_API_ERROR_NO_SUCH_ENTRY;
+
+  *type = ipset->type;
+  return 0;
+}
+
+int
+capo_ipset_add_member (u32 ipset_id, capo_ipset_member_t *member)
+{
+  capo_ipset_member_t *m;
+  capo_ipset_t *ipset = &capo_ipsets[ipset_id];
+
+  if (pool_is_free (capo_ipsets, ipset))
+    {
+      return 1;
+    }
+
+  /* zero so that we can memcmp later */
+  pool_get_zero (ipset->members, m);
+  clib_memcpy (m, member, sizeof (*m));
+  return 0;
+}
+
+static size_t
+capo_ipset_member_cmp (capo_ipset_member_t *m1, capo_ipset_member_t *m2,
+		       capo_ipset_type_t type)
+{
+  switch (type)
+    {
+    case IPSET_TYPE_IP:
+      return ip_address_cmp (&m1->address, &m2->address);
+    case IPSET_TYPE_IPPORT:
+      return ((m1->ipport.port == m2->ipport.port) &&
+	      (m1->ipport.l4proto == m2->ipport.l4proto) &&
+	      ip_address_cmp (&m1->ipport.addr, &m2->ipport.addr));
+    case IPSET_TYPE_NET:
+      return ip_prefix_cmp (&m1->prefix, &m2->prefix);
+    default:
+      return 1;
+    }
+}
+
+int
+capo_ipset_del_member (u32 id, capo_ipset_member_t *member)
+{
+  index_t *index, *indexes = NULL;
+  capo_ipset_member_t *m;
+  capo_ipset_t *ipset;
+
+  ipset = capo_ipsets_get_if_exists (id);
+  if (NULL == ipset)
+    return VNET_API_ERROR_NO_SUCH_ENTRY;
+
+  pool_foreach (m, ipset->members)
+    {
+      if (!capo_ipset_member_cmp (m, member, ipset->type))
+	vec_add1 (indexes, m - ipset->members);
+    }
+
+  vec_foreach (index, indexes)
+    pool_put_index (ipset->members, *index);
+  vec_free (indexes);
+
+  return 0;
+}
+
+static clib_error_t *
+capo_ipsets_show_cmd_fn (vlib_main_t *vm, unformat_input_t *input,
+			 vlib_cli_command_t *cmd)
+{
+  capo_ipset_t *ipset;
+
+  pool_foreach (ipset, capo_ipsets)
+    vlib_cli_output (vm, "%U", format_capo_ipset, ipset);
+
+  return 0;
+}
+
+VLIB_CLI_COMMAND (capo_ipsets_show_cmd, static) = {
+  .path = "show capo ipsets",
+  .function = capo_ipsets_show_cmd_fn,
+  .short_help = "show capo ipsets",
+};
+
+static clib_error_t *
+capo_ipsets_add_cmd_fn (vlib_main_t *vm, unformat_input_t *input,
+			vlib_cli_command_t *cmd)
+{
+  unformat_input_t _line_input, *line_input = &_line_input;
+  capo_ipset_member_t tmp, *members = 0, *member;
+  clib_error_t *error = 0;
+  capo_ipset_type_t type;
+  capo_ipset_t *ipset;
+  u32 id;
+  int rv;
+
+  id = capo_ipset_create ((capo_ipset_type_t) ~0);
+  vlib_cli_output (vm, "capo ipset %d added", id);
+
+  if (!unformat_user (input, unformat_line_input, line_input))
+    return 0;
+
+  while (unformat_check_input (line_input) != UNFORMAT_END_OF_INPUT)
+    {
+      if (unformat (line_input, "%U", unformat_capo_ipset_member, &tmp, &type))
+	vec_add1 (members, tmp);
+      else
+	{
+	  error = clib_error_return (0, "unknown input '%U'",
+				     format_unformat_error, line_input);
+	  goto done;
+	}
+    }
+
+  ipset = pool_elt_at_index (capo_ipsets, id);
+  ipset->type = type;
+
+  vec_foreach (member, members)
+    {
+      rv = capo_ipset_add_member (id, member);
+      if (rv)
+	error = clib_error_return (0, "capo_ipset_add_member error %d", rv);
+    }
+
+done:
+  vec_free (members);
+  unformat_free (line_input);
+  return error;
+}
+
+VLIB_CLI_COMMAND (capo_ipsets_add_cmd, static) = {
+  .path = "capo ipset add",
+  .function = capo_ipsets_add_cmd_fn,
+  .short_help = "capo ipset add [prefix|proto ip port|ip]",
+};
+
+static clib_error_t *
+capo_ipsets_del_cmd_fn (vlib_main_t *vm, unformat_input_t *input,
+			vlib_cli_command_t *cmd)
+{
+  unformat_input_t _line_input, *line_input = &_line_input;
+  clib_error_t *error = 0;
+  u32 id = CAPO_INVALID_INDEX;
+  int rv;
+
+  if (!unformat_user (input, unformat_line_input, line_input))
+    return clib_error_return (0, "missing ipset id");
+
+  while (unformat_check_input (line_input) != UNFORMAT_END_OF_INPUT)
+    {
+      if (unformat (line_input, "%u", &id))
+	;
+      else
+	{
+	  error = clib_error_return (0, "unknown input '%U'",
+				     format_unformat_error, line_input);
+	  goto done;
+	}
+    }
+
+  if (CAPO_INVALID_INDEX == id)
+    {
+      error = clib_error_return (0, "missing ipset id");
+      goto done;
+    }
+
+  rv = capo_ipset_delete (id);
+  if (rv)
+    error = clib_error_return (0, "capo_ipset_delete errored with %d", rv);
+
+done:
+  unformat_free (line_input);
+  return error;
+}
+
+VLIB_CLI_COMMAND (capo_ipsets_del_cmd, static) = {
+  .path = "capo ipset del",
+  .function = capo_ipsets_del_cmd_fn,
+  .short_help = "capo ipset del [id]",
+};
+
+static clib_error_t *
+capo_ipsets_add_member_cmd_fn (vlib_main_t *vm, unformat_input_t *input,
+			       vlib_cli_command_t *cmd)
+{
+  unformat_input_t _line_input, *line_input = &_line_input;
+  capo_ipset_member_t tmp, *members = 0, *member;
+  u32 id = CAPO_INVALID_INDEX;
+  clib_error_t *error = 0;
+  capo_ipset_type_t type;
+  capo_ipset_t *ipset;
+  int rv;
+
+  if (!unformat_user (input, unformat_line_input, line_input))
+    return clib_error_return (0, "missing parameters");
+
+  while (unformat_check_input (line_input) != UNFORMAT_END_OF_INPUT)
+    {
+      if (unformat (line_input, "id %u", &id))
+	;
+      else if (unformat (line_input, "%U", unformat_capo_ipset_member, &tmp,
+			 &type))
+	vec_add1 (members, tmp);
+      else
+	{
+	  error = clib_error_return (0, "unknown input '%U'",
+				     format_unformat_error, line_input);
+	  goto done;
+	}
+    }
+
+  if (CAPO_INVALID_INDEX == id)
+    {
+      error = clib_error_return (0, "missing ipset id");
+      goto done;
+    }
+
+  ipset = capo_ipsets_get_if_exists (id);
+  if (NULL == ipset)
+    return clib_error_return (0, "ipset not found");
+  if (ipset->type != type && ~0 != ipset->type)
+    {
+      error = clib_error_return (0, "cannot change ipset type");
+      goto done;
+    }
+  ipset->type = type;
+
+  vec_foreach (member, members)
+    {
+      rv = capo_ipset_add_member (id, member);
+      if (rv)
+	error = clib_error_return (0, "capo_ipset_add_member error %d", rv);
+    }
+
+done:
+  vec_free (members);
+  unformat_free (line_input);
+  return error;
+}
+
+VLIB_CLI_COMMAND (capo_ipsets_add_member_cmd, static) = {
+  .path = "capo ipset add member",
+  .function = capo_ipsets_add_member_cmd_fn,
+  .short_help = "capo ipset add member [id] [prefix]",
+};
+
+static clib_error_t *
+capo_ipsets_del_member_cmd_fn (vlib_main_t *vm, unformat_input_t *input,
+			       vlib_cli_command_t *cmd)
+{
+  unformat_input_t _line_input, *line_input = &_line_input;
+  clib_error_t *error = 0;
+  u32 id = CAPO_INVALID_INDEX;
+  capo_ipset_type_t type;
+  capo_ipset_member_t tmp, *members = 0, *member;
+  capo_ipset_t *ipset;
+  int rv;
+
+  if (!unformat_user (input, unformat_line_input, line_input))
+    return clib_error_return (0, "missing parameters");
+
+  while (unformat_check_input (line_input) != UNFORMAT_END_OF_INPUT)
+    {
+      if (unformat (line_input, "id %u", &id))
+	;
+      else if (unformat (line_input, "%U", unformat_capo_ipset_member, &tmp,
+			 &type))
+	vec_add1 (members, tmp);
+      else
+	{
+	  error = clib_error_return (0, "unknown input '%U'",
+				     format_unformat_error, line_input);
+	  goto done;
+	}
+    }
+
+  if (CAPO_INVALID_INDEX == id)
+    {
+      error = clib_error_return (0, "missing ipset id");
+      goto done;
+    }
+
+  ipset = capo_ipsets_get_if_exists (id);
+  if (NULL == ipset)
+    return clib_error_return (0, "ipset not found");
+  if (ipset->type != type)
+    {
+      error = clib_error_return (0, "wrong member type");
+      goto done;
+    }
+
+  vec_foreach (member, members)
+    {
+      rv = capo_ipset_del_member (id, member);
+      if (rv)
+	error =
+	  clib_error_return (0, "capo_ipset_del_member errored with %d", rv);
+    }
+
+done:
+  vec_free (members);
+  unformat_free (line_input);
+  return error;
+}
+
+VLIB_CLI_COMMAND (capo_ipsets_del_member_cmd, static) = {
+  .path = "capo ipset del member",
+  .function = capo_ipsets_del_member_cmd_fn,
+  .short_help = "capo ipset del member [id] [prefix]",
+};
+
+/*
+ * fd.io coding-style-patch-verification: ON
+ *
+ * Local Variables:
+ * eval: (c-set-style "gnu")
+ * End:
+ */
diff --git a/src/plugins/capo/capo_ipset.h b/src/plugins/capo/capo_ipset.h
new file mode 100644
index 000000000..56bb0f466
--- /dev/null
+++ b/src/plugins/capo/capo_ipset.h
@@ -0,0 +1,68 @@
+/*
+ * Copyright (c) 2020 Cisco and/or its affiliates.
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at:
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef included_capo_ipset_h
+#define included_capo_ipset_h
+
+#include <capo/capo.h>
+
+typedef enum
+{
+  IPSET_TYPE_IP = 0,
+  IPSET_TYPE_IPPORT = 1,
+  IPSET_TYPE_NET = 2
+} capo_ipset_type_t;
+
+typedef struct
+{
+  ip_address_t addr;
+  u16 port;
+  u8 l4proto;
+} capo_ipport_t;
+
+typedef union
+{
+  ip_address_t address;
+  capo_ipport_t ipport;
+  ip_prefix_t prefix;
+} capo_ipset_member_t;
+
+typedef struct
+{
+  capo_ipset_type_t type;
+  capo_ipset_member_t *members;
+} capo_ipset_t;
+
+u32 capo_ipset_create (capo_ipset_type_t type);
+int capo_ipset_delete (u32 id);
+
+int capo_ipset_add_member (u32 ipset_id, capo_ipset_member_t *member);
+int capo_ipset_del_member (u32 ipset_id, capo_ipset_member_t *member);
+
+int capo_ipset_get_type (u32 id, capo_ipset_type_t *type);
+u8 *format_capo_ipset (u8 *s, va_list *args);
+capo_ipset_t *capo_ipsets_get_if_exists (u32 index);
+
+extern capo_ipset_t *capo_ipsets;
+
+#endif
+
+/*
+ * fd.io coding-style-patch-verification: ON
+ *
+ * Local Variables:
+ * eval: (c-set-style "gnu")
+ * End:
+ */
diff --git a/src/plugins/capo/capo_match.c b/src/plugins/capo/capo_match.c
new file mode 100644
index 000000000..eed0cb233
--- /dev/null
+++ b/src/plugins/capo/capo_match.c
@@ -0,0 +1,736 @@
+/*
+ * Copyright (c) 2020 Cisco and/or its affiliates.
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at:
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include <vnet/ip/ip.h>
+
+#include <capo/capo.h>
+#include <capo/capo_match.h>
+
+/* for our bihash 8_24 */
+#include <vppinfra/bihash_template.c>
+
+int
+capo_match_func (void *p_acl_main, u32 sw_if_index, u32 is_inbound,
+		 fa_5tuple_opaque_t *opaque_5tuple, int is_ip6, u8 *r_action,
+		 u32 *trace_bitmap)
+{
+  fa_5tuple_t *pkt_5tuple = (fa_5tuple_t *) opaque_5tuple;
+  clib_bihash_kv_8_24_t conf_kv;
+  capo_interface_config_t *if_config;
+  capo_policy_t *policy;
+  u32 *policies;
+  int r;
+  u32 i;
+
+  conf_kv.key = sw_if_index;
+  if (clib_bihash_search_8_24 (&capo_main.if_config, &conf_kv, &conf_kv) != 0)
+    {
+      /* no config for this interface found, allow */
+      *r_action = 2;
+      return 0;
+    }
+  if_config = (capo_interface_config_t *) conf_kv.value;
+  policies =
+    is_inbound ? if_config->egress_policies : if_config->ingress_policies;
+
+  if (vec_len (policies) == 0)
+    goto profiles; /* no policies, jump to profiles */
+
+  *r_action = 0; /* drop by default */
+
+  vec_foreach_index (i, policies)
+    {
+      policy = &capo_policies[policies[i]];
+      r = capo_match_policy (policy, is_inbound, is_ip6, pkt_5tuple);
+      switch (r)
+	{
+	case CAPO_ALLOW:
+	  *r_action = 2; /* allow */
+	  return 1;
+	case CAPO_DENY:
+	  return 1;
+	case CAPO_PASS:
+	  goto profiles;
+	case CAPO_LOG:
+	  /* TODO: support LOG action */
+	  break;
+	default:
+	  break;
+	}
+    };
+  /* nothing matched, deny */
+  return 1;
+
+profiles:
+  if (vec_len (if_config->profiles) == 0)
+    {
+      *r_action = 2; /* no profiles, allow */
+      return 1;
+    }
+
+  vec_foreach_index (i, if_config->profiles)
+    {
+      policy = &capo_policies[if_config->profiles[i]];
+      r = capo_match_policy (policy, is_inbound, is_ip6, pkt_5tuple);
+      switch (r)
+	{
+	case CAPO_ALLOW:
+	  *r_action = 2; /* allow */
+	  return 1;
+	case CAPO_DENY:
+	  return 1;
+	case CAPO_PASS:
+	  clib_warning ("error: pass in profile %u", if_config->profiles[i]);
+	  return 1;
+	case CAPO_LOG:
+	  /* TODO: support LOG action */
+	  break;
+	default:
+	  break;
+	}
+    };
+  /* nothing matched, deny */
+  return 1;
+}
+
+int
+capo_match_policy (capo_policy_t *policy, u32 is_inbound, u32 is_ip6,
+		   fa_5tuple_t *pkt_5tuple)
+{
+  /* inbound packet from VPP pov is outbound from container pov - need to match
+     it against TX policies */
+  u32 *rules =
+    is_inbound ? policy->rule_ids[VLIB_TX] : policy->rule_ids[VLIB_RX];
+  u32 *rule_id;
+  capo_rule_t *rule;
+  int r;
+
+  vec_foreach (rule_id, rules)
+    {
+      rule = &capo_rules[*rule_id];
+      r = capo_match_rule (rule, is_ip6, pkt_5tuple);
+      if (r >= 0)
+	{
+	  return r;
+	}
+    }
+  return -1;
+}
+
+#define SRC 0
+#define DST 1
+
+int
+capo_match_rule (capo_rule_t *rule, u32 is_ip6, fa_5tuple_t *pkt_5tuple)
+{
+  //   if (is_ip6 != (rule->af == AF_IP6)) {
+  //       return -1;
+  //   }
+
+  ip4_address_t *src_ip4 = &pkt_5tuple->ip4_addr[SRC];
+  ip4_address_t *dst_ip4 = &pkt_5tuple->ip4_addr[DST];
+  ip6_address_t *src_ip6 = &pkt_5tuple->ip6_addr[SRC];
+  ip6_address_t *dst_ip6 = &pkt_5tuple->ip6_addr[DST];
+  u8 l4proto = pkt_5tuple->l4.proto;
+  u16 src_port = pkt_5tuple->l4.port[SRC];
+  u16 dst_port = pkt_5tuple->l4.port[DST];
+  u16 type = pkt_5tuple->l4.port[0];
+  u16 code = pkt_5tuple->l4.port[1];
+
+  capo_rule_filter_t *filter;
+  vec_foreach (filter, rule->filters)
+    {
+      switch (filter->type)
+	{
+	case CAPO_RULE_FILTER_NONE_TYPE:
+	  break;
+	case CAPO_RULE_FILTER_L4_PROTO:
+	  if (filter->should_match && filter->value != l4proto)
+	    return -1;
+	  if (!filter->should_match && filter->value == l4proto)
+	    return -2;
+	  break;
+	case CAPO_RULE_FILTER_ICMP_TYPE:
+	  if (l4proto == IP_PROTOCOL_ICMP || l4proto == IP_PROTOCOL_ICMP6)
+	    {
+	      if (filter->should_match && filter->value != type)
+		return -3;
+	      if (!filter->should_match && filter->value == type)
+		return -4;
+	    }
+	  else
+	    // A rule with an ICMP type / code specified doesn't match a
+	    // non-icmp packet
+	    return -5;
+	  break;
+	case CAPO_RULE_FILTER_ICMP_CODE:
+	  if (l4proto == IP_PROTOCOL_ICMP || l4proto == IP_PROTOCOL_ICMP6)
+	    {
+	      if (filter->should_match && filter->value != code)
+		return -6;
+	      if (!filter->should_match && filter->value == code)
+		return -7;
+	    }
+	  else
+	    // A rule with an ICMP type / code specified doesn't match a
+	    // non-icmp packet
+	    return -8;
+	  break;
+	default:
+	  // clib_warning ("unimplemented capo filter!");
+	  break;
+	}
+    }
+
+  /* prefixes */
+  if (rule->prefixes[CAPO_SRC])
+    {
+      ip_prefix_t *prefix;
+      u8 found = 0;
+      vec_foreach (prefix, rule->prefixes[CAPO_SRC])
+	{
+	  u8 pfx_af = ip_prefix_version (prefix);
+	  if (is_ip6 && pfx_af == AF_IP6)
+	    {
+	      if (ip6_destination_matches_route (&ip6_main, src_ip6,
+						 &ip_addr_v6 (&prefix->addr),
+						 prefix->len))
+		{
+		  found = 1;
+		  break;
+		}
+	    }
+	  else if (!is_ip6 && pfx_af == AF_IP4)
+	    {
+	      if (ip4_destination_matches_route (&ip4_main, src_ip4,
+						 &ip_addr_v4 (&prefix->addr),
+						 prefix->len))
+		{
+		  found = 1;
+		  break;
+		}
+	    }
+	}
+      if (!found)
+	{
+	  return -9;
+	}
+    }
+
+  if (rule->prefixes[CAPO_NOT_SRC])
+    {
+      ip_prefix_t *prefix;
+      vec_foreach (prefix, rule->prefixes[CAPO_NOT_SRC])
+	{
+	  u8 pfx_af = ip_prefix_version (prefix);
+	  if (is_ip6 && pfx_af == AF_IP6)
+	    {
+	      if (ip6_destination_matches_route (&ip6_main, src_ip6,
+						 &ip_addr_v6 (&prefix->addr),
+						 prefix->len))
+		{
+		  return -10;
+		}
+	    }
+	  else if (!is_ip6 && pfx_af == AF_IP4)
+	    {
+	      if (ip4_destination_matches_route (&ip4_main, src_ip4,
+						 &ip_addr_v4 (&prefix->addr),
+						 prefix->len))
+		{
+		  return -11;
+		}
+	    }
+	}
+    }
+
+  if (rule->prefixes[CAPO_DST])
+    {
+      ip_prefix_t *prefix;
+      u8 found = 0;
+      vec_foreach (prefix, rule->prefixes[CAPO_DST])
+	{
+	  u8 pfx_af = ip_prefix_version (prefix);
+	  if (is_ip6 && pfx_af == AF_IP6)
+	    {
+	      if (ip6_destination_matches_route (&ip6_main, dst_ip6,
+						 &ip_addr_v6 (&prefix->addr),
+						 prefix->len))
+		{
+		  found = 1;
+		  break;
+		}
+	    }
+	  else if (!is_ip6 && pfx_af == AF_IP4)
+	    {
+	      if (ip4_destination_matches_route (&ip4_main, dst_ip4,
+						 &ip_addr_v4 (&prefix->addr),
+						 prefix->len))
+		{
+		  found = 1;
+		  break;
+		}
+	    }
+	}
+      if (!found)
+	{
+	  return -12;
+	}
+    }
+
+  if (rule->prefixes[CAPO_NOT_DST])
+    {
+      ip_prefix_t *prefix;
+      vec_foreach (prefix, rule->prefixes[CAPO_NOT_DST])
+	{
+	  u8 pfx_af = ip_prefix_version (prefix);
+	  if (is_ip6 && pfx_af == AF_IP6)
+	    {
+	      if (ip6_destination_matches_route (&ip6_main, dst_ip6,
+						 &ip_addr_v6 (&prefix->addr),
+						 prefix->len))
+		{
+		  return -13;
+		}
+	    }
+	  else if (!is_ip6 && pfx_af == AF_IP4)
+	    {
+	      if (ip4_destination_matches_route (&ip4_main, dst_ip4,
+						 &ip_addr_v4 (&prefix->addr),
+						 prefix->len))
+		{
+		  return -14;
+		}
+	    }
+	}
+    }
+
+  /* IP ipsets */
+  if (rule->ip_ipsets[CAPO_SRC])
+    {
+      u32 *ipset;
+      u8 found = 0;
+      vec_foreach (ipset, rule->ip_ipsets[CAPO_SRC])
+	{
+	  if (is_ip6)
+	    {
+	      if (ipset_contains_ip6 (&capo_ipsets[*ipset], src_ip6))
+		{
+		  found = 1;
+		  break;
+		}
+	    }
+	  else
+	    {
+	      if (ipset_contains_ip4 (&capo_ipsets[*ipset], src_ip4))
+		{
+		  found = 1;
+		  break;
+		}
+	    }
+	}
+      if (!found)
+	{
+	  return -15;
+	}
+    }
+
+  if (rule->ip_ipsets[CAPO_NOT_SRC])
+    {
+      u32 *ipset;
+      vec_foreach (ipset, rule->ip_ipsets[CAPO_NOT_SRC])
+	{
+	  if (is_ip6)
+	    {
+	      if (ipset_contains_ip6 (&capo_ipsets[*ipset], src_ip6))
+		{
+		  return -16;
+		}
+	    }
+	  else
+	    {
+	      if (ipset_contains_ip4 (&capo_ipsets[*ipset], src_ip4))
+		{
+		  return -17;
+		}
+	    }
+	}
+    }
+
+  if (rule->ip_ipsets[CAPO_DST])
+    {
+      u32 *ipset;
+      u8 found = 0;
+      vec_foreach (ipset, rule->ip_ipsets[CAPO_DST])
+	{
+	  if (is_ip6)
+	    {
+	      if (ipset_contains_ip6 (&capo_ipsets[*ipset], dst_ip6))
+		{
+		  found = 1;
+		  break;
+		}
+	    }
+	  else
+	    {
+	      if (ipset_contains_ip4 (&capo_ipsets[*ipset], dst_ip4))
+		{
+		  found = 1;
+		  break;
+		}
+	    }
+	}
+      if (!found)
+	{
+	  return -18;
+	}
+    }
+
+  if (rule->ip_ipsets[CAPO_NOT_DST])
+    {
+      u32 *ipset;
+      vec_foreach (ipset, rule->ip_ipsets[CAPO_NOT_DST])
+	{
+	  if (is_ip6)
+	    {
+	      if (ipset_contains_ip6 (&capo_ipsets[*ipset], dst_ip6))
+		{
+		  return -19;
+		}
+	    }
+	  else
+	    {
+	      if (ipset_contains_ip4 (&capo_ipsets[*ipset], dst_ip4))
+		{
+		  return -20;
+		}
+	    }
+	}
+    }
+
+  /* Special treatment for src / dst ports: they need to be in either the port
+     ranges or the port + ip ipsets / */
+  u8 src_port_found = 0;
+  u8 dst_port_found = 0;
+
+  /* port ranges */
+  if (rule->port_ranges[CAPO_SRC])
+    {
+      capo_port_range_t *range;
+      vec_foreach (range, rule->port_ranges[CAPO_SRC])
+	{
+	  if (range->start <= src_port && src_port <= range->end)
+	    {
+	      src_port_found = 1;
+	      break;
+	    }
+	}
+    }
+
+  if (rule->port_ranges[CAPO_NOT_SRC])
+    {
+      capo_port_range_t *range;
+      vec_foreach (range, rule->port_ranges[CAPO_NOT_SRC])
+	{
+	  if (range->start <= src_port && src_port <= range->end)
+	    {
+	      return -21;
+	    }
+	}
+    }
+
+  if (rule->port_ranges[CAPO_DST])
+    {
+      capo_port_range_t *range;
+      vec_foreach (range, rule->port_ranges[CAPO_DST])
+	{
+	  if (range->start <= dst_port && dst_port <= range->end)
+	    {
+	      dst_port_found = 1;
+	      break;
+	    }
+	}
+    }
+
+  if (rule->port_ranges[CAPO_NOT_DST])
+    {
+      capo_port_range_t *range;
+      vec_foreach (range, rule->port_ranges[CAPO_NOT_DST])
+	{
+	  if (range->start <= dst_port && dst_port <= range->end)
+	    {
+	      return -22;
+	    }
+	}
+    }
+
+  /* ipport ipsets */
+  if (rule->ipport_ipsets[CAPO_SRC])
+    {
+      u32 *ipset;
+      vec_foreach (ipset, rule->ipport_ipsets[CAPO_SRC])
+	{
+	  if (is_ip6)
+	    {
+	      if (ipport_ipset_contains_ip6 (&capo_ipsets[*ipset], src_ip6,
+					     l4proto, src_port))
+		{
+		  src_port_found = 1;
+		  break;
+		}
+	    }
+	  else
+	    {
+	      if (ipport_ipset_contains_ip4 (&capo_ipsets[*ipset], src_ip4,
+					     l4proto, src_port))
+		{
+		  src_port_found = 1;
+		  break;
+		}
+	    }
+	}
+    }
+
+  if (rule->ipport_ipsets[CAPO_NOT_SRC])
+    {
+      u32 *ipset;
+      vec_foreach (ipset, rule->ipport_ipsets[CAPO_NOT_SRC])
+	{
+	  if (is_ip6)
+	    {
+	      if (ipport_ipset_contains_ip6 (&capo_ipsets[*ipset], src_ip6,
+					     l4proto, src_port))
+		{
+		  return -23;
+		}
+	    }
+	  else
+	    {
+	      if (ipport_ipset_contains_ip4 (&capo_ipsets[*ipset], src_ip4,
+					     l4proto, src_port))
+		{
+		  return -24;
+		}
+	    }
+	}
+    }
+
+  if (rule->ipport_ipsets[CAPO_DST])
+    {
+      u32 *ipset;
+      vec_foreach (ipset, rule->ipport_ipsets[CAPO_DST])
+	{
+	  if (is_ip6)
+	    {
+	      if (ipport_ipset_contains_ip6 (&capo_ipsets[*ipset], dst_ip6,
+					     l4proto, dst_port))
+		{
+		  dst_port_found = 1;
+		  break;
+		}
+	    }
+	  else
+	    {
+	      if (ipport_ipset_contains_ip4 (&capo_ipsets[*ipset], dst_ip4,
+					     l4proto, dst_port))
+		{
+		  dst_port_found = 1;
+		  break;
+		}
+	    }
+	}
+    }
+
+  if (rule->ipport_ipsets[CAPO_NOT_DST])
+    {
+      u32 *ipset;
+      vec_foreach (ipset, rule->ipport_ipsets[CAPO_NOT_DST])
+	{
+	  if (is_ip6)
+	    {
+	      if (ipport_ipset_contains_ip6 (&capo_ipsets[*ipset], dst_ip6,
+					     l4proto, dst_port))
+		{
+		  return -25;
+		}
+	    }
+	  else
+	    {
+	      if (ipport_ipset_contains_ip4 (&capo_ipsets[*ipset], dst_ip4,
+					     l4proto, dst_port))
+		{
+		  return -26;
+		}
+	    }
+	}
+    }
+
+  if ((rule->port_ranges[CAPO_SRC] || rule->ipport_ipsets[CAPO_SRC]) &&
+      (!src_port_found))
+    {
+      return -27;
+    }
+  if ((rule->port_ranges[CAPO_DST] || rule->ipport_ipsets[CAPO_DST]) &&
+      (!dst_port_found))
+    {
+      return -28;
+    }
+
+  return rule->action;
+}
+
+u8
+ip_ipset_contains_ip4 (capo_ipset_t *ipset, ip4_address_t *addr)
+{
+  ASSERT (ipset->type == IPSET_TYPE_IP);
+  capo_ipset_member_t *member;
+  pool_foreach (member, ipset->members)
+    {
+      if (member->address.version != AF_IP4)
+	continue;
+      if (!ip4_address_compare (addr, &ip_addr_v4 (&member->address)))
+	return 1;
+    }
+  return 0;
+}
+
+u8
+ip_ipset_contains_ip6 (capo_ipset_t *ipset, ip6_address_t *addr)
+{
+  ASSERT (ipset->type == IPSET_TYPE_IP);
+  capo_ipset_member_t *member;
+  pool_foreach (member, ipset->members)
+    {
+      if (member->address.version != AF_IP6)
+	continue;
+      if (!ip6_address_compare (addr, &ip_addr_v6 (&member->address)))
+	return 1;
+    }
+  return 0;
+}
+
+u8
+net_ipset_contains_ip4 (capo_ipset_t *ipset, ip4_address_t *addr)
+{
+  ASSERT (ipset->type == IPSET_TYPE_NET);
+  capo_ipset_member_t *member;
+  pool_foreach (member, ipset->members)
+    {
+      if (member->prefix.addr.version != AF_IP4)
+	continue;
+      if (ip4_destination_matches_route (&ip4_main, addr,
+					 &ip_addr_v4 (&member->prefix.addr),
+					 member->prefix.len))
+	{
+	  return 1;
+	}
+    }
+  return 0;
+}
+
+u8
+net_ipset_contains_ip6 (capo_ipset_t *ipset, ip6_address_t *addr)
+{
+  ASSERT (ipset->type == IPSET_TYPE_NET);
+  capo_ipset_member_t *member;
+  pool_foreach (member, ipset->members)
+    {
+      if (member->prefix.addr.version != AF_IP6)
+	continue;
+      if (ip6_destination_matches_route (&ip6_main, addr,
+					 &ip_addr_v6 (&member->prefix.addr),
+					 member->prefix.len))
+	{
+	  return 1;
+	}
+    }
+  return 0;
+}
+
+u8
+ipset_contains_ip4 (capo_ipset_t *ipset, ip4_address_t *addr)
+{
+  switch (ipset->type)
+    {
+    case IPSET_TYPE_IP:
+      return ip_ipset_contains_ip4 (ipset, addr);
+    case IPSET_TYPE_NET:
+      return net_ipset_contains_ip4 (ipset, addr);
+    default:
+      clib_warning ("Wrong ipset type");
+    }
+  return 0;
+}
+
+u8
+ipset_contains_ip6 (capo_ipset_t *ipset, ip6_address_t *addr)
+{
+  switch (ipset->type)
+    {
+    case IPSET_TYPE_IP:
+      return ip_ipset_contains_ip6 (ipset, addr);
+    case IPSET_TYPE_NET:
+      return net_ipset_contains_ip6 (ipset, addr);
+    default:
+      clib_warning ("Wrong ipset type");
+    }
+  return 0;
+}
+
+u8
+ipport_ipset_contains_ip4 (capo_ipset_t *ipset, ip4_address_t *addr,
+			   u8 l4proto, u16 port)
+{
+  ASSERT (ipset->type == IPSET_TYPE_IPPORT);
+  capo_ipset_member_t *member;
+  pool_foreach (member, ipset->members)
+    {
+      if (member->ipport.addr.version != AF_IP4)
+	continue;
+      if (l4proto == member->ipport.l4proto && port == member->ipport.port &&
+	  !ip4_address_compare (addr, &ip_addr_v4 (&member->ipport.addr)))
+	{
+	  return 1;
+	}
+    }
+  return 0;
+}
+
+u8
+ipport_ipset_contains_ip6 (capo_ipset_t *ipset, ip6_address_t *addr,
+			   u8 l4proto, u16 port)
+{
+  ASSERT (ipset->type == IPSET_TYPE_IPPORT);
+  capo_ipset_member_t *member;
+  pool_foreach (member, ipset->members)
+    {
+      if (member->ipport.addr.version != AF_IP6)
+	continue;
+      if (l4proto == member->ipport.l4proto && port == member->ipport.port &&
+	  !ip6_address_compare (addr, &ip_addr_v6 (&member->ipport.addr)))
+	{
+	  return 1;
+	}
+    }
+  return 0;
+}
+
+/*
+ * fd.io coding-style-patch-verification: ON
+ *
+ * Local Variables:
+ * eval: (c-set-style "gnu")
+ * End:
+ */
diff --git a/src/plugins/capo/capo_match.h b/src/plugins/capo/capo_match.h
new file mode 100644
index 000000000..fe1907485
--- /dev/null
+++ b/src/plugins/capo/capo_match.h
@@ -0,0 +1,49 @@
+/*
+ * Copyright (c) 2020 Cisco and/or its affiliates.
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at:
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef included_capo_match_h
+#define included_capo_match_h
+
+#include <acl/acl.h>
+#include <acl/fa_node.h>
+
+#include <capo/capo_ipset.h>
+#include <capo/capo_policy.h>
+#include <capo/capo_rule.h>
+
+int capo_match_func (void *p_acl_main, u32 sw_if_index, u32 is_inbound,
+		     fa_5tuple_opaque_t *opaque_5tuple, int is_ip6,
+		     u8 *r_action, u32 *trace_bitmap);
+
+int capo_match_policy (capo_policy_t *policy, u32 is_inbound, u32 is_ip6,
+		       fa_5tuple_t *pkt_5tuple);
+int capo_match_rule (capo_rule_t *rule, u32 is_ip6, fa_5tuple_t *pkt_5tuple);
+
+u8 ipset_contains_ip4 (capo_ipset_t *ipset, ip4_address_t *addr);
+u8 ipset_contains_ip6 (capo_ipset_t *ipset, ip6_address_t *addr);
+u8 ipport_ipset_contains_ip4 (capo_ipset_t *ipset, ip4_address_t *addr,
+			      u8 l4proto, u16 port);
+u8 ipport_ipset_contains_ip6 (capo_ipset_t *ipset, ip6_address_t *addr,
+			      u8 l4proto, u16 port);
+
+#endif
+
+/*
+ * fd.io coding-style-patch-verification: ON
+ *
+ * Local Variables:
+ * eval: (c-set-style "gnu")
+ * End:
+ */
diff --git a/src/plugins/capo/capo_policy.c b/src/plugins/capo/capo_policy.c
new file mode 100644
index 000000000..86c61b8cc
--- /dev/null
+++ b/src/plugins/capo/capo_policy.c
@@ -0,0 +1,263 @@
+/*
+ * Copyright (c) 2020 Cisco and/or its affiliates.
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at:
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include <capo/capo.h>
+#include <capo/capo_policy.h>
+#include <capo/capo_rule.h>
+
+capo_policy_t *capo_policies;
+
+static capo_policy_t *
+capo_policy_alloc ()
+{
+  capo_policy_t *policy;
+  pool_get_zero (capo_policies, policy);
+  return policy;
+}
+
+capo_policy_t *
+capo_policy_get_if_exists (u32 index)
+{
+  if (pool_is_free_index (capo_policies, index))
+    return (NULL);
+  return pool_elt_at_index (capo_policies, index);
+}
+
+static void
+capo_policy_cleanup (capo_policy_t *policy)
+{
+  for (int i = 0; i < VLIB_N_RX_TX; i++)
+    vec_free (policy->rule_ids[i]);
+}
+
+int
+capo_policy_update (u32 *id, capo_policy_rule_t *rules)
+{
+  capo_policy_t *policy;
+  capo_policy_rule_t *rule;
+
+  policy = capo_policy_get_if_exists (*id);
+  if (policy)
+    capo_policy_cleanup (policy);
+  else
+    policy = capo_policy_alloc ();
+
+  vec_foreach (rule, rules)
+    vec_add1 (policy->rule_ids[rule->direction], rule->rule_id);
+
+  *id = policy - capo_policies;
+  return 0;
+}
+
+int
+capo_policy_delete (u32 id)
+{
+  capo_policy_t *policy;
+  policy = capo_policy_get_if_exists (id);
+  if (NULL == policy)
+    return VNET_API_ERROR_NO_SUCH_ENTRY;
+
+  capo_policy_cleanup (policy);
+  pool_put (capo_policies, policy);
+
+  return 0;
+}
+
+u8 *
+format_capo_policy (u8 *s, va_list *args)
+{
+  capo_policy_t *policy = va_arg (*args, capo_policy_t *);
+  int indent = va_arg (*args, int);
+  int verbose = va_arg (*args, int);
+  u32 *rule_id;
+
+  if (policy == NULL)
+    return format (s, "deleted policy");
+
+  if (verbose)
+    {
+      s = format (s, "[policy#%u]\n", policy - capo_policies);
+      capo_rule_t *rule;
+      if (verbose != CAPO_POLICY_ONLY_INGRESS)
+	vec_foreach (rule_id, policy->rule_ids[VLIB_TX])
+	  {
+	    rule = capo_rule_get_if_exists (*rule_id);
+	    s = format (s, "%Uegress :%U\n", format_white_space, indent + 2,
+			format_capo_rule, rule);
+	  }
+      if (verbose != CAPO_POLICY_ONLY_EGRESS)
+	vec_foreach (rule_id, policy->rule_ids[VLIB_RX])
+	  {
+	    rule = capo_rule_get_if_exists (*rule_id);
+	    s = format (s, "%Uingress:%U\n", format_white_space, indent + 2,
+			format_capo_rule, rule);
+	  }
+    }
+  else
+    {
+      s = format (s, "[policy#%u] rx-rules:%d tx-rules:%d\n",
+		  policy - capo_policies, vec_len (policy->rule_ids[VLIB_RX]),
+		  vec_len (policy->rule_ids[VLIB_TX]));
+    }
+
+  return (s);
+}
+
+static clib_error_t *
+capo_policies_show_cmd_fn (vlib_main_t *vm, unformat_input_t *input,
+			   vlib_cli_command_t *cmd)
+{
+  unformat_input_t _line_input, *line_input = &_line_input;
+  clib_error_t *error = 0;
+  capo_policy_t *policy;
+  u8 verbose = 0, has_input = 0;
+
+  if (unformat_user (input, unformat_line_input, line_input))
+    {
+      has_input = 1;
+      while (unformat_check_input (line_input) != UNFORMAT_END_OF_INPUT)
+	{
+	  if (unformat (line_input, "verbose"))
+	    verbose = 1;
+	  else
+	    {
+	      error = clib_error_return (0, "unknown input '%U'",
+					 format_unformat_error, line_input);
+	      goto done;
+	    }
+	}
+    }
+
+  pool_foreach (policy, capo_policies)
+    vlib_cli_output (vm, "%U", format_capo_policy, policy, 0 /* indent */,
+		     verbose);
+
+done:
+  if (has_input)
+    unformat_free (line_input);
+  return error;
+}
+
+VLIB_CLI_COMMAND (capo_policies_show_cmd, static) = {
+  .path = "show capo policies",
+  .function = capo_policies_show_cmd_fn,
+  .short_help = "show capo policies [verbose]",
+};
+
+static clib_error_t *
+capo_policies_add_cmd_fn (vlib_main_t *vm, unformat_input_t *input,
+			  vlib_cli_command_t *cmd)
+{
+  unformat_input_t _line_input, *line_input = &_line_input;
+  clib_error_t *error = 0;
+  u32 id = CAPO_INVALID_INDEX, rule_id;
+  capo_policy_rule_t *policy_rules = 0, *policy_rule;
+  int direction = VLIB_RX;
+  int rv;
+
+  if (!unformat_user (input, unformat_line_input, line_input))
+    return clib_error_return (0, "missing parameters");
+
+  while (unformat_check_input (line_input) != UNFORMAT_END_OF_INPUT)
+    {
+      if (unformat (line_input, "update %u", &id))
+	;
+      else if (unformat (line_input, "%U", unformat_vlib_rx_tx, &direction))
+	;
+      else if (unformat (line_input, "%u", &rule_id))
+	{
+	  vec_add2 (policy_rules, policy_rule, 1);
+	  policy_rule->rule_id = rule_id;
+	  policy_rule->direction = direction;
+	}
+      else
+	{
+	  error = clib_error_return (0, "unknown input '%U'",
+				     format_unformat_error, line_input);
+	  goto done;
+	}
+    }
+
+  rv = capo_policy_update (&id, policy_rules);
+  if (rv)
+    error = clib_error_return (0, "capo_policy_delete errored with %d", rv);
+  else
+    vlib_cli_output (vm, "capo policy %d added", id);
+
+done:
+  vec_free (policy_rules);
+  unformat_free (line_input);
+  return error;
+}
+
+VLIB_CLI_COMMAND (capo_policies_add_cmd, static) = {
+  .path = "capo policy add",
+  .function = capo_policies_add_cmd_fn,
+  .short_help = "capo policy add [rx rule_id rule_id ...] [tx rule_id rule_id "
+		"...] [update [id]]",
+};
+
+static clib_error_t *
+capo_policies_del_cmd_fn (vlib_main_t *vm, unformat_input_t *input,
+			  vlib_cli_command_t *cmd)
+{
+  unformat_input_t _line_input, *line_input = &_line_input;
+  clib_error_t *error = 0;
+  u32 id = CAPO_INVALID_INDEX;
+  int rv;
+
+  if (!unformat_user (input, unformat_line_input, line_input))
+    return clib_error_return (0, "missing policy id");
+
+  while (unformat_check_input (line_input) != UNFORMAT_END_OF_INPUT)
+    {
+      if (unformat (line_input, "%u", &id))
+	;
+      else
+	{
+	  error = clib_error_return (0, "unknown input '%U'",
+				     format_unformat_error, line_input);
+	  goto done;
+	}
+    }
+
+  if (CAPO_INVALID_INDEX == id)
+    {
+      error = clib_error_return (0, "missing policy id");
+      goto done;
+    }
+
+  rv = capo_policy_delete (id);
+  if (rv)
+    error = clib_error_return (0, "capo_policy_delete errored with %d", rv);
+
+done:
+  unformat_free (line_input);
+  return error;
+}
+
+VLIB_CLI_COMMAND (capo_policies_del_cmd, static) = {
+  .path = "capo policy del",
+  .function = capo_policies_del_cmd_fn,
+  .short_help = "capo policy del [id]",
+};
+
+/*
+ * fd.io coding-style-patch-verification: ON
+ *
+ * Local Variables:
+ * eval: (c-set-style "gnu")
+ * End:
+ */
diff --git a/src/plugins/capo/capo_policy.h b/src/plugins/capo/capo_policy.h
new file mode 100644
index 000000000..a98799929
--- /dev/null
+++ b/src/plugins/capo/capo_policy.h
@@ -0,0 +1,58 @@
+/*
+ * Copyright (c) 2020 Cisco and/or its affiliates.
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at:
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef included_capo_policy_h
+#define included_capo_policy_h
+
+#include <capo/capo.h>
+
+typedef struct
+{
+  /* VLIB_RX for inbound
+     VLIB_TX for outbound */
+  u32 *rule_ids[VLIB_N_RX_TX];
+} capo_policy_t;
+
+typedef struct
+{
+  u32 rule_id;
+  /* VLIB_RX or VLIB_TX */
+  u8 direction;
+} capo_policy_rule_t;
+
+typedef enum
+{
+  CAPO_POLICY_QUIET,
+  CAPO_POLICY_VERBOSE,
+  CAPO_POLICY_ONLY_INGRESS,
+  CAPO_POLICY_ONLY_EGRESS,
+} capo_policy_format_type_t;
+
+extern capo_policy_t *capo_policies;
+
+int capo_policy_update (u32 *id, capo_policy_rule_t *rules);
+int capo_policy_delete (u32 id);
+u8 *format_capo_policy (u8 *s, va_list *args);
+capo_policy_t *capo_policy_get_if_exists (u32 index);
+
+#endif
+
+/*
+ * fd.io coding-style-patch-verification: ON
+ *
+ * Local Variables:
+ * eval: (c-set-style "gnu")
+ * End:
+ */
diff --git a/src/plugins/capo/capo_rule.c b/src/plugins/capo/capo_rule.c
new file mode 100644
index 000000000..c672f29bd
--- /dev/null
+++ b/src/plugins/capo/capo_rule.c
@@ -0,0 +1,509 @@
+/*
+ * Copyright (c) 2020 Cisco and/or its affiliates.
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at:
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include <capo/capo.h>
+#include <capo/capo_rule.h>
+#include <capo/capo_ipset.h>
+
+capo_rule_t *capo_rules;
+
+u8 *
+format_capo_rule_action (u8 *s, va_list *args)
+{
+  capo_rule_action_t action = va_arg (*args, int);
+  switch (action)
+    {
+    case CAPO_ALLOW:
+      return format (s, "allow");
+    case CAPO_DENY:
+      return format (s, "deny");
+    case CAPO_LOG:
+      return format (s, "log");
+    case CAPO_PASS:
+      return format (s, "pass");
+    default:
+      return format (s, "unknownaction");
+    }
+}
+
+uword
+unformat_capo_rule_action (unformat_input_t *input, va_list *args)
+{
+  capo_rule_action_t *action = va_arg (*args, capo_rule_action_t *);
+  if (unformat (input, "allow"))
+    *action = CAPO_ALLOW;
+  else if (unformat (input, "deny"))
+    *action = CAPO_DENY;
+  else if (unformat (input, "log"))
+    *action = CAPO_LOG;
+  else if (unformat (input, "pass"))
+    *action = CAPO_PASS;
+  else
+    return 0;
+  return 1;
+}
+
+u8 *
+format_capo_rule_port_range (u8 *s, va_list *args)
+{
+  capo_port_range_t *port_range = va_arg (*args, capo_port_range_t *);
+
+  if (port_range->start != port_range->end)
+    s = format (s, "[%u-%u]", port_range->start, port_range->end);
+  else
+    s = format (s, "%u", port_range->start);
+
+  return (s);
+}
+
+u8 *
+format_capo_rule_entry (u8 *s, va_list *args)
+{
+  capo_rule_entry_t *entry = va_arg (*args, capo_rule_entry_t *);
+  capo_ipset_t *ipset;
+
+  s = format (s, "%s", entry->flags & CAPO_IS_SRC ? "src" : "dst");
+  s = format (s, "%s", entry->flags & CAPO_IS_NOT ? "!=" : "==");
+  switch (entry->type)
+    {
+    case CAPO_CIDR:
+      s = format (s, "%U", format_ip_prefix, &entry->data.cidr);
+      break;
+    case CAPO_PORT_RANGE:
+      s =
+	format (s, "%U", format_capo_rule_port_range, &entry->data.port_range);
+      break;
+    case CAPO_IP_SET:
+      ipset = capo_ipsets_get_if_exists (entry->data.set_id);
+      s = format (s, "%U", format_capo_ipset, ipset);
+      break;
+    case CAPO_PORT_IP_SET:
+      ipset = capo_ipsets_get_if_exists (entry->data.set_id);
+      s = format (s, "%U", format_capo_ipset, ipset);
+      break;
+    default:
+      s = format (s, "unknown");
+      break;
+    }
+  return (s);
+}
+
+uword
+unformat_rule_key_flag (unformat_input_t *input, va_list *args)
+{
+  capo_rule_key_flag_t *flags = va_arg (*args, capo_rule_key_flag_t *);
+  if (unformat (input, "src=="))
+    *flags = CAPO_IS_SRC;
+  else if (unformat (input, "src!="))
+    *flags = CAPO_IS_SRC | CAPO_IS_NOT;
+  else if (unformat (input, "dst!="))
+    *flags = CAPO_IS_NOT;
+  else if (unformat (input, "dst=="))
+    *flags = 0;
+  else
+    return 0;
+  return 1;
+}
+
+uword
+unformat_capo_port_range (unformat_input_t *input, va_list *args)
+{
+  capo_port_range_t *port_range = va_arg (*args, capo_port_range_t *);
+  u32 start, end;
+  if (unformat (input, "[%d-%d]", &start, &end))
+    {
+      port_range->start = (u16) start;
+      port_range->end = (u16) end;
+    }
+  else
+    return 0;
+  return 1;
+}
+
+uword
+unformat_capo_rule_entry (unformat_input_t *input, va_list *args)
+{
+  capo_rule_entry_t *entry = va_arg (*args, capo_rule_entry_t *);
+  if (unformat (input, "%U %U", unformat_rule_key_flag, &entry->flags,
+		unformat_ip_prefix, &entry->data.cidr))
+    entry->type = CAPO_CIDR;
+  else if (unformat (input, "%U %U", unformat_rule_key_flag, &entry->flags,
+		     unformat_capo_port_range, &entry->data.port_range))
+    entry->type = CAPO_PORT_RANGE;
+  else if (unformat (input, "%Uset %u", unformat_rule_key_flag, &entry->flags,
+		     &entry->data.set_id))
+    entry->type = CAPO_PORT_IP_SET;
+  else
+    return 0;
+  return 1;
+}
+
+u8 *
+format_capo_rule_filter (u8 *s, va_list *args)
+{
+  capo_rule_filter_t *filter = va_arg (*args, capo_rule_filter_t *);
+  switch (filter->type)
+    {
+    case CAPO_RULE_FILTER_NONE_TYPE:
+      return format (s, "<no filter>");
+    case CAPO_RULE_FILTER_ICMP_TYPE:
+      return format (s, "icmp-type%s=%d", filter->should_match ? "=" : "!",
+		     filter->value);
+    case CAPO_RULE_FILTER_ICMP_CODE:
+      return format (s, "icmp-code%s=%d", filter->should_match ? "=" : "!",
+		     filter->value);
+    case CAPO_RULE_FILTER_L4_PROTO:
+      return format (s, "proto%s=%U", filter->should_match ? "=" : "!",
+		     format_ip_protocol, filter->value);
+    default:
+      return format (s, "unknown");
+    }
+}
+
+uword
+unformat_capo_should_match (unformat_input_t *input, va_list *args)
+{
+  u8 *should_match = va_arg (*args, u8 *);
+  if (unformat (input, "=="))
+    *should_match = 1;
+  else if (unformat (input, "!="))
+    *should_match = 0;
+  else
+    return 0;
+  return 1;
+}
+
+uword
+unformat_capo_rule_filter (unformat_input_t *input, va_list *args)
+{
+  u8 tmp_value;
+  capo_rule_filter_t *filter = va_arg (*args, capo_rule_filter_t *);
+  if (unformat (input, "icmp-type%U%d", unformat_capo_should_match,
+		&filter->should_match, &filter->value))
+    filter->type = CAPO_RULE_FILTER_ICMP_TYPE;
+  else if (unformat (input, "icmp-code%U%d", unformat_capo_should_match,
+		     &filter->should_match, &filter->value))
+    filter->type = CAPO_RULE_FILTER_ICMP_CODE;
+  else if (unformat (input, "proto%U%U", unformat_capo_should_match,
+		     &filter->should_match, unformat_ip_protocol, &tmp_value))
+    {
+      filter->value = tmp_value;
+      filter->type = CAPO_RULE_FILTER_L4_PROTO;
+    }
+  else
+    return 0;
+  return 1;
+}
+
+static capo_rule_entry_t *
+capo_rule_get_entries (capo_rule_t *rule)
+{
+  capo_rule_entry_t *entries = NULL, *entry;
+  capo_port_range_t *pr;
+  ip_prefix_t *pfx;
+  u32 *set_id;
+  for (int i = 0; i < CAPO_RULE_MAX_FLAGS; i++)
+    {
+      vec_foreach (pfx, rule->prefixes[i])
+	{
+	  vec_add2 (entries, entry, 1);
+	  entry->type = CAPO_CIDR;
+	  entry->flags = i;
+	  clib_memcpy (&entry->data.cidr, pfx, sizeof (*pfx));
+	}
+      vec_foreach (pr, rule->port_ranges[i])
+	{
+	  vec_add2 (entries, entry, 1);
+	  entry->type = CAPO_PORT_RANGE;
+	  entry->flags = i;
+	  clib_memcpy (&entry->data.port_range, pr, sizeof (*pr));
+	}
+      vec_foreach (set_id, rule->ip_ipsets[i])
+	{
+	  vec_add2 (entries, entry, 1);
+	  entry->type = CAPO_IP_SET;
+	  entry->flags = i;
+	  entry->data.set_id = *set_id;
+	}
+      vec_foreach (set_id, rule->ipport_ipsets[i])
+	{
+	  vec_add2 (entries, entry, 1);
+	  entry->type = CAPO_PORT_IP_SET;
+	  entry->flags = i;
+	  entry->data.set_id = *set_id;
+	}
+    }
+  return entries;
+}
+
+u8 *
+format_capo_rule (u8 *s, va_list *args)
+{
+  capo_rule_t *rule = va_arg (*args, capo_rule_t *);
+  capo_rule_filter_t *filter;
+  capo_rule_entry_t *entry, *entries;
+
+  if (rule == NULL)
+    return format (s, "deleted rule");
+
+  s = format (s, "[rule#%d;%U][", rule - capo_rules, format_capo_rule_action,
+	      rule->action);
+
+  /* filters */
+  vec_foreach (filter, rule->filters)
+    {
+      if (filter->type != CAPO_RULE_FILTER_NONE_TYPE)
+	s = format (s, "%U,", format_capo_rule_filter, filter);
+    }
+
+  entries = capo_rule_get_entries (rule);
+  vec_foreach (entry, entries)
+    s = format (s, "%U,", format_capo_rule_entry, entry);
+  vec_free (entries);
+  s = format (s, "]");
+
+  return (s);
+}
+
+capo_rule_t *
+capo_rule_alloc ()
+{
+  capo_rule_t *rule;
+  pool_get_zero (capo_rules, rule);
+  return rule;
+}
+
+capo_rule_t *
+capo_rule_get_if_exists (u32 index)
+{
+  if (pool_is_free_index (capo_rules, index))
+    return (NULL);
+  return pool_elt_at_index (capo_rules, index);
+}
+
+static void
+capo_rule_cleanup (capo_rule_t *rule)
+{
+  int i;
+  vec_free (rule->filters);
+  for (i = 0; i < CAPO_RULE_MAX_FLAGS; i++)
+    {
+      vec_free (rule->prefixes[i]);
+      vec_free (rule->port_ranges[i]);
+      vec_free (rule->ip_ipsets[i]);
+      vec_free (rule->ipport_ipsets[i]);
+    }
+}
+
+int
+capo_rule_update (u32 *id, capo_rule_action_t action, ip_address_family_t af,
+		  capo_rule_filter_t *filters, capo_rule_entry_t *entries)
+{
+  capo_rule_filter_t *filter;
+  capo_rule_entry_t *entry;
+  capo_rule_t *rule;
+  int rv;
+
+  rule = capo_rule_get_if_exists (*id);
+  if (rule)
+    capo_rule_cleanup (rule);
+  else
+    rule = capo_rule_alloc ();
+
+  rule->af = -1;
+  rule->action = action;
+  vec_foreach (filter, filters)
+    vec_add1 (rule->filters, *filter);
+
+  vec_foreach (entry, entries)
+    {
+      u8 flags = entry->flags;
+      switch (entry->type)
+	{
+	case CAPO_CIDR:
+	  vec_add1 (rule->prefixes[flags], entry->data.cidr);
+	  break;
+	case CAPO_PORT_RANGE:
+	  vec_add1 (rule->port_ranges[flags], entry->data.port_range);
+	  break;
+	case CAPO_PORT_IP_SET:
+	  vec_add1 (rule->ipport_ipsets[flags], entry->data.set_id);
+	  break;
+	case CAPO_IP_SET:
+	  vec_add1 (rule->ip_ipsets[flags], entry->data.set_id);
+	  break;
+	default:
+	  rv = 1;
+	  goto error;
+	}
+    }
+  *id = rule - capo_rules;
+  return 0;
+error:
+  capo_rule_cleanup (rule);
+  pool_put (capo_rules, rule);
+  return rv;
+}
+
+int
+capo_rule_delete (u32 id)
+{
+  capo_rule_t *rule;
+  rule = capo_rule_get_if_exists (id);
+  if (NULL == rule)
+    return VNET_API_ERROR_NO_SUCH_ENTRY;
+
+  capo_rule_cleanup (rule);
+  pool_put (capo_rules, rule);
+
+  return 0;
+}
+
+static clib_error_t *
+capo_rules_show_cmd_fn (vlib_main_t *vm, unformat_input_t *input,
+			vlib_cli_command_t *cmd)
+{
+  capo_rule_t *rule;
+
+  pool_foreach (rule, capo_rules)
+    {
+      vlib_cli_output (vm, "%U", format_capo_rule, rule);
+    }
+
+  return 0;
+}
+
+VLIB_CLI_COMMAND (capo_rules_show_cmd, static) = {
+  .path = "show capo rules",
+  .function = capo_rules_show_cmd_fn,
+  .short_help = "show capo rules",
+};
+
+static clib_error_t *
+capo_rules_add_cmd_fn (vlib_main_t *vm, unformat_input_t *input,
+		       vlib_cli_command_t *cmd)
+{
+  unformat_input_t _line_input, *line_input = &_line_input;
+  capo_rule_filter_t tmp_filter, *filters = 0;
+  capo_rule_entry_t tmp_entry, *entries = 0;
+  clib_error_t *error = 0;
+  capo_rule_action_t action;
+  ip_address_family_t af = AF_IP4;
+  u32 id = CAPO_INVALID_INDEX;
+  int rv;
+
+  if (!unformat_user (input, unformat_line_input, line_input))
+    return 0;
+
+  while (unformat_check_input (line_input) != UNFORMAT_END_OF_INPUT)
+    {
+      if (unformat (line_input, "update %u", &id))
+	;
+      else if (unformat_user (line_input, unformat_ip_address_family, &af))
+	;
+      else if (unformat_user (line_input, unformat_capo_rule_action, &action))
+	;
+      else if (unformat_user (line_input, unformat_capo_rule_entry,
+			      &tmp_entry))
+	vec_add1 (entries, tmp_entry);
+      else if (unformat_user (line_input, unformat_capo_rule_filter,
+			      &tmp_filter))
+	{
+	  vec_add1 (filters, tmp_filter);
+	  vlib_cli_output (vm, "%U", format_capo_rule_filter, &tmp_filter);
+	}
+      else
+	{
+	  error = clib_error_return (0, "unknown input '%U'",
+				     format_unformat_error, line_input);
+	  goto done;
+	}
+    }
+
+  rv = capo_rule_update (&id, action, af, filters, entries);
+  if (rv)
+    error = clib_error_return (0, "capo_rule_update error %d", rv);
+  else
+    vlib_cli_output (vm, "capo rule %d added", id);
+
+done:
+  vec_free (filters);
+  vec_free (entries);
+  unformat_free (line_input);
+  return error;
+}
+
+VLIB_CLI_COMMAND (capo_rules_add_cmd, static) = {
+  .path = "capo rule add",
+  .function = capo_rules_add_cmd_fn,
+  .short_help = "capo rule add [ip4|ip6] [allow|deny|log|pass]"
+		"[filter[==|!=]value]"
+		"[[src|dst][==|!=][prefix|set ID|[port-port]]]",
+  .long_help = "Add a rule, with given filters and entries\n"
+	       "filters can be `icmp-type`, `icmp-code` and `proto`",
+};
+
+static clib_error_t *
+capo_rules_del_cmd_fn (vlib_main_t *vm, unformat_input_t *input,
+		       vlib_cli_command_t *cmd)
+{
+  unformat_input_t _line_input, *line_input = &_line_input;
+  clib_error_t *error = 0;
+  u32 id = CAPO_INVALID_INDEX;
+  int rv;
+
+  if (!unformat_user (input, unformat_line_input, line_input))
+    return clib_error_return (0, "missing rule id");
+
+  while (unformat_check_input (line_input) != UNFORMAT_END_OF_INPUT)
+    {
+      if (unformat (line_input, "%u", &id))
+	;
+      else
+	{
+	  error = clib_error_return (0, "unknown input '%U'",
+				     format_unformat_error, line_input);
+	  goto done;
+	}
+    }
+
+  if (CAPO_INVALID_INDEX == id)
+    {
+      error = clib_error_return (0, "missing rule id");
+      goto done;
+    }
+
+  rv = capo_rule_delete (id);
+  if (rv)
+    error = clib_error_return (0, "capo_rule_delete errored with %d", rv);
+
+done:
+  unformat_free (line_input);
+  return error;
+}
+
+VLIB_CLI_COMMAND (capo_rules_del_cmd, static) = {
+  .path = "capo rule del",
+  .function = capo_rules_del_cmd_fn,
+  .short_help = "capo rule del [id]",
+};
+
+/*
+ * fd.io coding-style-patch-verification: ON
+ *
+ * Local Variables:
+ * eval: (c-set-style "gnu")
+ * End:
+ */
diff --git a/src/plugins/capo/capo_rule.h b/src/plugins/capo/capo_rule.h
new file mode 100644
index 000000000..0875a45c5
--- /dev/null
+++ b/src/plugins/capo/capo_rule.h
@@ -0,0 +1,91 @@
+/*
+ * Copyright (c) 2020 Cisco and/or its affiliates.
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at:
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef included_capo_rule_h
+#define included_capo_rule_h
+
+#include <capo/capo.h>
+
+typedef vl_api_capo_rule_action_t capo_rule_action_t;
+typedef vl_api_capo_entry_type_t capo_entry_type_t;
+typedef vl_api_capo_rule_filter_type_t capo_rule_filter_type_t;
+
+typedef struct capo_rule_filter_
+{
+  capo_rule_filter_type_t type;
+  /* Content to filter against */
+  u32 value;
+  /* If true match packet.property == opaque, else packet.property != opaque */
+  u8 should_match;
+} capo_rule_filter_t;
+
+typedef union capo_entry_data_t_
+{
+  ip_prefix_t cidr;
+  capo_port_range_t port_range;
+  u32 set_id;
+} capo_entry_data_t;
+
+typedef enum capo_rule_key_flag_
+{
+  CAPO_IS_SRC = 1 << 0,
+  CAPO_IS_NOT = 1 << 1,
+  CAPO_RULE_MAX_FLAGS = 1 << 2,
+} capo_rule_key_flag_t;
+
+#define CAPO_SRC     CAPO_IS_SRC
+#define CAPO_NOT_SRC (CAPO_IS_SRC | CAPO_IS_NOT)
+#define CAPO_DST     0
+#define CAPO_NOT_DST CAPO_IS_NOT
+
+typedef struct capo_rule_entry_t_
+{
+  capo_entry_type_t type;
+  capo_entry_data_t data;
+  capo_rule_key_flag_t flags;
+} capo_rule_entry_t;
+
+typedef struct capo_rule_
+{
+  ip_address_family_t af;
+  capo_rule_action_t action;
+
+  capo_rule_filter_t *filters;
+
+  /* Indexed by capo_rule_key_flag_t */
+  ip_prefix_t *prefixes[CAPO_RULE_MAX_FLAGS];
+  u32 *ip_ipsets[CAPO_RULE_MAX_FLAGS];
+  capo_port_range_t *port_ranges[CAPO_RULE_MAX_FLAGS];
+  u32 *ipport_ipsets[CAPO_RULE_MAX_FLAGS];
+} capo_rule_t;
+
+extern capo_rule_t *capo_rules;
+
+int capo_rule_delete (u32 id);
+int capo_rule_update (u32 *id, capo_rule_action_t action,
+		      ip_address_family_t af, capo_rule_filter_t *filters,
+		      capo_rule_entry_t *entries);
+u8 *format_capo_rule (u8 *s, va_list *args);
+capo_rule_t *capo_rule_get_if_exists (u32 index);
+
+#endif
+
+/*
+ * fd.io coding-style-patch-verification: ON
+ *
+ * Local Variables:
+ * eval: (c-set-style "gnu")
+ * End:
+ */
diff --git a/src/plugins/capo/capo_test.c b/src/plugins/capo/capo_test.c
new file mode 100644
index 000000000..8bfa4ae29
--- /dev/null
+++ b/src/plugins/capo/capo_test.c
@@ -0,0 +1,490 @@
+/*
+ * Copyright (c) 2015 Cisco and/or its affiliates.
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at:
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+/*
+ *------------------------------------------------------------------
+ * acl_test.c - test harness plugin
+ *------------------------------------------------------------------
+ */
+
+#include <vat/vat.h>
+#include <vlibapi/api.h>
+#include <vlibmemory/api.h>
+#include <vppinfra/error.h>
+#include <vnet/ip/ip.h>
+#include <arpa/inet.h>
+
+#include <vnet/ip/ip_format_fns.h>
+#include <vnet/ethernet/ethernet_format_fns.h>
+
+#define __plugin_msg_base capo_test_main.msg_id_base
+#include <vlibapi/vat_helper_macros.h>
+
+uword unformat_sw_if_index (unformat_input_t *input, va_list *args);
+
+/* Declare message IDs */
+#include <capo/capo.api_enum.h>
+#include <capo/capo.api_types.h>
+#define vl_endianfun /* define message structures */
+#include <capo/capo.api.h>
+#undef vl_endianfun
+
+typedef struct
+{
+  /* API message ID base */
+  u16 msg_id_base;
+  vat_main_t *vat_main;
+} capo_test_main_t;
+
+capo_test_main_t capo_test_main;
+
+/* NAME: capo_get_version_reply */
+static void
+vl_api_capo_get_version_reply_t_handler (vl_api_capo_get_version_reply_t *mp)
+{
+  vat_main_t *vam = capo_test_main.vat_main;
+  clib_warning ("Calico Policy plugin version: %d.%d", ntohl (mp->major),
+		ntohl (mp->minor));
+  vam->result_ready = 1;
+}
+
+/* NAME: capo_control_ping_reply */
+static void
+vl_api_capo_control_ping_reply_t_handler (vl_api_capo_control_ping_reply_t *mp)
+{
+  vat_main_t *vam = capo_test_main.vat_main;
+  i32 retval = ntohl (mp->retval);
+  if (vam->async_mode)
+    {
+      vam->async_errors += (retval < 0);
+    }
+  else
+    {
+      vam->retval = retval;
+      vam->result_ready = 1;
+    }
+}
+
+/* NAME: ipset_create_reply */
+static void
+vl_api_capo_ipset_create_reply_t_handler (vl_api_capo_ipset_create_reply_t *mp)
+{
+  vat_main_t *vam = capo_test_main.vat_main;
+  clib_warning ("Got ipset_create_reply...");
+  vam->result_ready = 1;
+}
+
+/* NAME: rule_create_reply */
+static void
+vl_api_capo_rule_create_reply_t_handler (vl_api_capo_rule_create_reply_t *mp)
+{
+  vat_main_t *vam = capo_test_main.vat_main;
+  clib_warning ("Got rule_create_reply...");
+  vam->result_ready = 1;
+}
+
+/* NAME: policy_create_reply */
+static void
+vl_api_capo_policy_create_reply_t_handler (
+  vl_api_capo_policy_create_reply_t *mp)
+{
+  vat_main_t *vam = capo_test_main.vat_main;
+  clib_warning ("Got policy_create_reply...");
+  vam->result_ready = 1;
+}
+
+/* NAME: capo_get_version */
+
+static int
+api_capo_get_version (vat_main_t *vam)
+{
+  capo_test_main_t *cptm = &capo_test_main;
+  unformat_input_t *i = vam->input;
+  vl_api_capo_get_version_t *mp;
+  u32 msg_size = sizeof (*mp);
+  int ret;
+
+  vam->result_ready = 0;
+  mp = vl_msg_api_alloc_as_if_client (msg_size);
+  memset (mp, 0, msg_size);
+  mp->_vl_msg_id = ntohs (VL_API_CAPO_GET_VERSION + cptm->msg_id_base);
+  mp->client_index = vam->my_client_index;
+
+  /* FIXME: do something here */
+
+  while (unformat_check_input (i) != UNFORMAT_END_OF_INPUT)
+    {
+    }
+
+  /* send it... */
+  S (mp);
+
+  /* Wait for a reply... */
+  W (ret);
+  return ret;
+}
+
+/* NAME: capo_control_ping */
+
+static int
+api_capo_control_ping (vat_main_t *vam)
+{
+  capo_test_main_t *cptm = &capo_test_main;
+  unformat_input_t *i = vam->input;
+  vl_api_capo_control_ping_t *mp;
+  u32 msg_size = sizeof (*mp);
+  int ret;
+
+  vam->result_ready = 0;
+  mp = vl_msg_api_alloc_as_if_client (msg_size);
+  memset (mp, 0, msg_size);
+  mp->_vl_msg_id = ntohs (VL_API_CAPO_CONTROL_PING + cptm->msg_id_base);
+  mp->client_index = vam->my_client_index;
+
+  /* FIXME: do something here */
+
+  while (unformat_check_input (i) != UNFORMAT_END_OF_INPUT)
+    {
+    }
+
+  /* send it... */
+  S (mp);
+
+  /* Wait for a reply... */
+  W (ret);
+  return ret;
+}
+
+/* NAME: ipset_create */
+
+static int
+api_capo_ipset_create (vat_main_t *vam)
+{
+  capo_test_main_t *cptm = &capo_test_main;
+  unformat_input_t *i = vam->input;
+  vl_api_capo_ipset_create_t *mp;
+  u32 msg_size = sizeof (*mp);
+  int ret;
+
+  vam->result_ready = 0;
+  mp = vl_msg_api_alloc_as_if_client (msg_size);
+  memset (mp, 0, msg_size);
+  mp->_vl_msg_id = ntohs (VL_API_CAPO_IPSET_CREATE + cptm->msg_id_base);
+  mp->client_index = vam->my_client_index;
+
+  /* FIXME: do something here */
+
+  while (unformat_check_input (i) != UNFORMAT_END_OF_INPUT)
+    {
+    }
+
+  /* send it... */
+  S (mp);
+
+  /* Wait for a reply... */
+  W (ret);
+  return ret;
+}
+
+/* NAME: ipset_add_del_members */
+
+static int
+api_capo_ipset_add_del_members (vat_main_t *vam)
+{
+  capo_test_main_t *cptm = &capo_test_main;
+  unformat_input_t *i = vam->input;
+  vl_api_capo_ipset_add_del_members_t *mp;
+  u32 msg_size = sizeof (*mp);
+  int ret;
+
+  vam->result_ready = 0;
+  mp = vl_msg_api_alloc_as_if_client (msg_size);
+  memset (mp, 0, msg_size);
+  mp->_vl_msg_id =
+    ntohs (VL_API_CAPO_IPSET_ADD_DEL_MEMBERS + cptm->msg_id_base);
+  mp->client_index = vam->my_client_index;
+
+  /* FIXME: do something here */
+
+  while (unformat_check_input (i) != UNFORMAT_END_OF_INPUT)
+    {
+    }
+
+  /* send it... */
+  S (mp);
+
+  /* Wait for a reply... */
+  W (ret);
+  return ret;
+}
+
+/* NAME: ipset_delete */
+
+static int
+api_capo_ipset_delete (vat_main_t *vam)
+{
+  capo_test_main_t *cptm = &capo_test_main;
+  unformat_input_t *i = vam->input;
+  vl_api_capo_ipset_delete_t *mp;
+  u32 msg_size = sizeof (*mp);
+  int ret;
+
+  vam->result_ready = 0;
+  mp = vl_msg_api_alloc_as_if_client (msg_size);
+  memset (mp, 0, msg_size);
+  mp->_vl_msg_id = ntohs (VL_API_CAPO_IPSET_DELETE + cptm->msg_id_base);
+  mp->client_index = vam->my_client_index;
+
+  /* FIXME: do something here */
+
+  while (unformat_check_input (i) != UNFORMAT_END_OF_INPUT)
+    {
+    }
+
+  /* send it... */
+  S (mp);
+
+  /* Wait for a reply... */
+  W (ret);
+  return ret;
+}
+
+/* NAME: rule_create */
+
+static int
+api_capo_rule_create (vat_main_t *vam)
+{
+  capo_test_main_t *cptm = &capo_test_main;
+  unformat_input_t *i = vam->input;
+  vl_api_capo_rule_create_t *mp;
+  u32 msg_size = sizeof (*mp);
+  int ret;
+
+  vam->result_ready = 0;
+  mp = vl_msg_api_alloc_as_if_client (msg_size);
+  memset (mp, 0, msg_size);
+  mp->_vl_msg_id = ntohs (VL_API_CAPO_RULE_CREATE + cptm->msg_id_base);
+  mp->client_index = vam->my_client_index;
+
+  /* FIXME: do something here */
+
+  while (unformat_check_input (i) != UNFORMAT_END_OF_INPUT)
+    {
+    }
+
+  /* send it... */
+  S (mp);
+
+  /* Wait for a reply... */
+  W (ret);
+  return ret;
+}
+
+/* NAME: rule_update */
+
+static int
+api_capo_rule_update (vat_main_t *vam)
+{
+  capo_test_main_t *cptm = &capo_test_main;
+  unformat_input_t *i = vam->input;
+  vl_api_capo_rule_update_t *mp;
+  u32 msg_size = sizeof (*mp);
+  int ret;
+
+  vam->result_ready = 0;
+  mp = vl_msg_api_alloc_as_if_client (msg_size);
+  memset (mp, 0, msg_size);
+  mp->_vl_msg_id = ntohs (VL_API_CAPO_RULE_UPDATE + cptm->msg_id_base);
+  mp->client_index = vam->my_client_index;
+
+  /* FIXME: do something here */
+
+  while (unformat_check_input (i) != UNFORMAT_END_OF_INPUT)
+    {
+    }
+
+  /* send it... */
+  S (mp);
+
+  /* Wait for a reply... */
+  W (ret);
+  return ret;
+}
+
+/* NAME: rule_delete */
+
+static int
+api_capo_rule_delete (vat_main_t *vam)
+{
+  capo_test_main_t *cptm = &capo_test_main;
+  unformat_input_t *i = vam->input;
+  vl_api_capo_rule_delete_t *mp;
+  u32 msg_size = sizeof (*mp);
+  int ret;
+
+  vam->result_ready = 0;
+  mp = vl_msg_api_alloc_as_if_client (msg_size);
+  memset (mp, 0, msg_size);
+  mp->_vl_msg_id = ntohs (VL_API_CAPO_RULE_DELETE + cptm->msg_id_base);
+  mp->client_index = vam->my_client_index;
+
+  /* FIXME: do something here */
+
+  while (unformat_check_input (i) != UNFORMAT_END_OF_INPUT)
+    {
+    }
+
+  /* send it... */
+  S (mp);
+
+  /* Wait for a reply... */
+  W (ret);
+  return ret;
+}
+
+/* NAME: policy_create */
+
+static int
+api_capo_policy_create (vat_main_t *vam)
+{
+  capo_test_main_t *cptm = &capo_test_main;
+  unformat_input_t *i = vam->input;
+  vl_api_capo_policy_create_t *mp;
+  u32 msg_size = sizeof (*mp);
+  int ret;
+
+  vam->result_ready = 0;
+  mp = vl_msg_api_alloc_as_if_client (msg_size);
+  memset (mp, 0, msg_size);
+  mp->_vl_msg_id = ntohs (VL_API_CAPO_POLICY_CREATE + cptm->msg_id_base);
+  mp->client_index = vam->my_client_index;
+
+  /* FIXME: do something here */
+
+  while (unformat_check_input (i) != UNFORMAT_END_OF_INPUT)
+    {
+    }
+
+  /* send it... */
+  S (mp);
+
+  /* Wait for a reply... */
+  W (ret);
+  return ret;
+}
+
+/* NAME: policy_update */
+
+static int
+api_capo_policy_update (vat_main_t *vam)
+{
+  capo_test_main_t *cptm = &capo_test_main;
+  unformat_input_t *i = vam->input;
+  vl_api_capo_policy_update_t *mp;
+  u32 msg_size = sizeof (*mp);
+  int ret;
+
+  vam->result_ready = 0;
+  mp = vl_msg_api_alloc_as_if_client (msg_size);
+  memset (mp, 0, msg_size);
+  mp->_vl_msg_id = ntohs (VL_API_CAPO_POLICY_UPDATE + cptm->msg_id_base);
+  mp->client_index = vam->my_client_index;
+
+  /* FIXME: do something here */
+
+  while (unformat_check_input (i) != UNFORMAT_END_OF_INPUT)
+    {
+    }
+
+  /* send it... */
+  S (mp);
+
+  /* Wait for a reply... */
+  W (ret);
+  return ret;
+}
+
+/* NAME: policy_delete */
+
+static int
+api_capo_policy_delete (vat_main_t *vam)
+{
+  capo_test_main_t *cptm = &capo_test_main;
+  unformat_input_t *i = vam->input;
+  vl_api_capo_policy_delete_t *mp;
+  u32 msg_size = sizeof (*mp);
+  int ret;
+
+  vam->result_ready = 0;
+  mp = vl_msg_api_alloc_as_if_client (msg_size);
+  memset (mp, 0, msg_size);
+  mp->_vl_msg_id = ntohs (VL_API_CAPO_POLICY_DELETE + cptm->msg_id_base);
+  mp->client_index = vam->my_client_index;
+
+  /* FIXME: do something here */
+
+  while (unformat_check_input (i) != UNFORMAT_END_OF_INPUT)
+    {
+    }
+
+  /* send it... */
+  S (mp);
+
+  /* Wait for a reply... */
+  W (ret);
+  return ret;
+}
+
+/* NAME: configure_policies */
+
+static int
+api_capo_configure_policies (vat_main_t *vam)
+{
+  capo_test_main_t *cptm = &capo_test_main;
+  unformat_input_t *i = vam->input;
+  vl_api_capo_configure_policies_t *mp;
+  u32 msg_size = sizeof (*mp);
+  int ret;
+
+  vam->result_ready = 0;
+  mp = vl_msg_api_alloc_as_if_client (msg_size);
+  memset (mp, 0, msg_size);
+  mp->_vl_msg_id = ntohs (VL_API_CAPO_CONFIGURE_POLICIES + cptm->msg_id_base);
+  mp->client_index = vam->my_client_index;
+
+  /* FIXME: do something here */
+
+  while (unformat_check_input (i) != UNFORMAT_END_OF_INPUT)
+    {
+    }
+
+  /* send it... */
+  S (mp);
+
+  /* Wait for a reply... */
+  W (ret);
+  return ret;
+}
+
+#define VL_API_LOCAL_SETUP_MESSAGE_ID_TABLE local_setup_message_id_table
+static void
+local_setup_message_id_table (vat_main_t *vam)
+{
+  // hash_set_mem (vam->function_by_name, "acl_add_replace_from_file",
+  // api_capo_acl_add_replace_from_file); hash_set_mem (vam->help_by_name,
+  // "acl_add_replace_from_file", "filename <file> [permit]
+  // [append-default-permit]");
+}
+
+#include <capo/capo.api_test.c>
diff --git a/src/plugins/capo/test/test_capo.py b/src/plugins/capo/test/test_capo.py
new file mode 100644
index 000000000..dec9c56f7
--- /dev/null
+++ b/src/plugins/capo/test/test_capo.py
@@ -0,0 +1,806 @@
+#!/usr/bin/env python3
+
+import random
+import unittest
+from ipaddress import (IPv4Address, IPv4Network, IPv6Address, IPv6Network,
+                       ip_address, ip_network)
+from itertools import product
+
+from framework import VppTestCase, VppTestRunner
+from scapy.layers.inet import (ICMP, IP, TCP, UDP, ICMPerror, IPerror,
+                               TCPerror, UDPerror)
+from scapy.layers.inet6 import (ICMPv6DestUnreach, ICMPv6EchoReply,
+                                ICMPv6EchoRequest, IPerror6, IPv6)
+from scapy.layers.l2 import Ether
+from scapy.packet import Raw
+from vpp_ip import INVALID_INDEX, DpoProto
+from vpp_object import VppObject
+from vpp_papi import VppEnum
+
+icmp4_type = 8  # echo request
+icmp4_code = 3
+icmp6_type = 128  # echo request
+icmp6_code = 3
+tcp_protocol = 6
+icmp_protocol = 1
+icmp6_protocol = 58
+udp_protocol = 17
+src_l4 = 1234
+dst_l4 = 4321
+
+
+def random_payload():
+    return Raw(load=bytearray(random.getrandbits(8) for _ in range(20)))
+
+
+class VppCapoPolicyItem():
+    def __init__(self, is_inbound, rule_id):
+        self._is_inbound = is_inbound
+        self._rule_id = rule_id
+
+    def encode(self):
+        return {'rule_id': self._rule_id, 'is_inbound': self._is_inbound}
+
+
+class VppCapoPolicy(VppObject):
+    def __init__(self, test, rules):
+        self._test = test
+        self._rules = rules
+        self.encoded_rules = []
+        self.init_rules()
+
+    def init_rules(self):
+        self.encoded_rules = []
+        for rule in self._rules:
+            self.encoded_rules.append(rule.encode())
+
+    def add_vpp_config(self):
+        r = self._test.vapi.capo_policy_create(
+            len(self.encoded_rules),
+            self.encoded_rules)
+        self._test.assertEqual(0, r.retval)
+        self._test.registry.register(self, self._test.logger)
+        self._test.logger.info("capo_policy_create retval=" + str(r.retval))
+        self._policy_id = r.policy_id
+        self._test.logger.info(self._test.vapi.cli("show capo policies verbose"))
+
+    def capo_policy_update(self, rules):
+        self._rules = rules
+        self.init_rules()
+        r = self._test.vapi.capo_policy_update(
+            self._policy_id,
+            len(self.encoded_rules),
+            self.encoded_rules)
+        self._test.assertEqual(0, r.retval)
+
+    def capo_policy_delete(self):
+        r = self._test.vapi.capo_policy_delete(self._policy_id)
+        self._test.assertEqual(0, r.retval)
+        self._test.logger.info(self._test.vapi.cli("show capo policies"))
+
+    def remove_vpp_config(self):
+        self.capo_policy_delete()
+
+    def query_vpp_config(self):
+        self._test.logger.info("query vpp config")
+        self._test.logger.info(self._test.vapi.cli("show capo policies verbose"))
+
+
+class VppCapoFilter:
+    def __init__(self, type=None, value=0, should_match=0):
+        self._filter_type = type if type != None else FILTER_TYPE_NONE
+        self._filter_value = value
+        self._should_match = should_match
+
+    def encode(self):
+        return {'type': self._filter_type,
+            'value': self._filter_value,
+            'should_match': self._should_match}
+
+
+class VppCapoRule(VppObject):
+    def __init__(self, test, is_v6, action, filters=[], matches=[]):
+        self._test = test
+        # This is actually unused
+        self._af = 255
+        self.init_rule(action, filters, matches)
+
+    def vpp_id(self):
+        return self._rule_id
+
+    def init_rule(self, action, filters=[], matches=[]):
+        self._action = action
+        self._filters = filters
+        self._matches = matches
+        self.encoded_filters = []
+        for filter in self._filters:
+            self.encoded_filters.append(filter.encode())
+        while len(self.encoded_filters) < 3:
+            self.encoded_filters.append(VppCapoFilter().encode())
+        self._test.assertEqual(len(self.encoded_filters), 3)
+
+    def add_vpp_config(self):
+        r = self._test.vapi.capo_rule_create(
+            {'af': self._af,
+             'action': self._action,
+             'filters': self.encoded_filters,
+             'num_entries': len(self._matches),
+             'matches': self._matches
+            })
+        self._test.assertEqual(0, r.retval)
+        self._test.registry.register(self, self._test.logger)
+        self._test.logger.info("capo_rule_create retval=" + str(r.retval))
+        self._rule_id = r.rule_id
+        self._test.logger.info("rules id : " + str(self._rule_id))
+        self._test.logger.info(self._test.vapi.cli("show capo rules"))
+
+    def capo_rule_update(self, filters, matches):
+        self.init_rule(self._action, filters, matches)
+        r = self._test.vapi.capo_rule_update(
+            self._rule_id,
+            {'af': self._af,
+             'action': self._action,
+             'filters': self.encoded_filters,
+             'num_entries': len(self._matches),
+             'matches': self._matches
+            })
+        self._test.assertEqual(0, r.retval)
+        self._test.registry.register(self, self._test.logger)
+        self._test.logger.info("capo rule update")
+        self._test.logger.info(self._test.vapi.cli("show capo rules"))
+
+    def capo_rule_delete(self):
+        r = self._test.vapi.capo_rule_delete(self._rule_id)
+        self._test.assertEqual(0, r.retval)
+        self._test.logger.info(self._test.vapi.cli("show capo rules"))
+
+    def remove_vpp_config(self):
+        self.capo_rule_delete()
+
+    def query_vpp_config(self):
+        self._test.logger.info("query vpp config")
+        self._test.logger.info(self._test.vapi.cli("show capo rules"))
+
+
+class VppCapoIpset(VppObject):
+    def __init__(self, test, type, members):
+        self.test = test
+        self.type = type
+        self.members = members
+
+    def add_vpp_config(self):
+        r = self.test.vapi.capo_ipset_create(self.type)
+        self.test.assertEqual(0, r.retval)
+        self.vpp_id = r.set_id
+        encoded_members = []
+        for m in self.members:
+            if self.type == IPSET_TYPE_IP:
+                encoded_members.append({"val":{"address": m}})
+            elif self.type == IPSET_TYPE_IP_PORT:
+                encoded_members.append({"val":{"tuple": m}})
+            elif self.type == IPSET_TYPE_NET:
+                encoded_members.append({"val":{"prefix": m}})
+        r = self.test.vapi.capo_ipset_add_del_members(
+            set_id=self.vpp_id,
+            is_add=True,
+            len=len(encoded_members),
+            members=encoded_members,
+        )
+        self.test.assertEqual(0, r.retval)
+
+    def query_vpp_config(self):
+        pass
+
+    def remove_vpp_config(self):
+        r = self.test.vapi.capo_ipset_delete(set_id=self.vpp_id)
+        self.test.assertEqual(0, r.retval)
+
+
+
+class BaseCapoTest(VppTestCase):
+    @classmethod
+    def setUpClass(self):
+        super(BaseCapoTest, self).setUpClass()
+        # We can't define these before the API is loaded, so here they are...
+        global ACTION_ALLOW, ACTION_DENY, ACTION_PASS, ACTION_LOG
+        ACTION_ALLOW = VppEnum.vl_api_capo_rule_action_t.CAPO_ALLOW
+        ACTION_DENY = VppEnum.vl_api_capo_rule_action_t.CAPO_DENY
+        ACTION_PASS = VppEnum.vl_api_capo_rule_action_t.CAPO_PASS
+        ACTION_LOG = VppEnum.vl_api_capo_rule_action_t.CAPO_LOG
+        global FILTER_TYPE_NONE, FILTER_TYPE_L4_PROTO, FILTER_TYPE_ICMP_CODE, FILTER_TYPE_ICMP_TYPE
+        FILTER_TYPE_NONE = VppEnum.vl_api_capo_rule_filter_type_t.CAPO_RULE_FILTER_NONE_TYPE
+        FILTER_TYPE_L4_PROTO = VppEnum.vl_api_capo_rule_filter_type_t.CAPO_RULE_FILTER_L4_PROTO
+        FILTER_TYPE_ICMP_CODE = VppEnum.vl_api_capo_rule_filter_type_t.CAPO_RULE_FILTER_ICMP_CODE
+        FILTER_TYPE_ICMP_TYPE = VppEnum.vl_api_capo_rule_filter_type_t.CAPO_RULE_FILTER_ICMP_TYPE
+        global ENTRY_CIDR, ENTRY_PORT_RANGE, ENTRY_PORT_IP_SET, ENTRY_IP_SET
+        ENTRY_CIDR = VppEnum.vl_api_capo_entry_type_t.CAPO_CIDR
+        ENTRY_PORT_RANGE = VppEnum.vl_api_capo_entry_type_t.CAPO_PORT_RANGE
+        ENTRY_PORT_IP_SET = VppEnum.vl_api_capo_entry_type_t.CAPO_PORT_IP_SET
+        ENTRY_IP_SET = VppEnum.vl_api_capo_entry_type_t.CAPO_IP_SET
+        global IPSET_TYPE_IP, IPSET_TYPE_IP_PORT, IPSET_TYPE_NET
+        IPSET_TYPE_IP = VppEnum.vl_api_capo_ipset_type_t.CAPO_IP
+        IPSET_TYPE_IP_PORT = VppEnum.vl_api_capo_ipset_type_t.CAPO_IP_AND_PORT
+        IPSET_TYPE_NET = VppEnum.vl_api_capo_ipset_type_t.CAPO_NET
+
+        self.create_pg_interfaces(range(2))
+        for i in self.pg_interfaces:
+            i.admin_up()
+            # Add one additional neighbor on each side for tests with different addresses
+            i.generate_remote_hosts(2)
+            i.config_ip4()
+            i.configure_ipv4_neighbors()
+            i.config_ip6()
+            i.configure_ipv6_neighbors()
+
+    @classmethod
+    def tearDownClass(self):
+        for i in self.pg_interfaces:
+            i.unconfig_ip4()
+            i.unconfig_ip6()
+            i.admin_down()
+        super(BaseCapoTest, self).tearDownClass()
+
+
+    def setUp(self):
+        super(BaseCapoTest, self).setUp()
+
+    def tearDown(self):
+        super(BaseCapoTest, self).tearDown()
+
+    def configure_policies(self, interface, ingress, egress, profiles):
+        id_list = []
+        for policy in ingress + egress + profiles:
+            id_list.append(policy._policy_id)
+
+        r = self.vapi.capo_configure_policies(
+             interface.sw_if_index,
+             len(ingress),
+             len(egress),
+             len(ingress) + len(egress) + len(profiles),
+             id_list)
+        self.assertEqual(0, r.retval)
+
+    def base_ip_packet(self, is_v6=False, second_src_ip=False, second_dst_ip=False):
+        IP46 = IPv6 if is_v6 else IP
+        src_host = self.pg0.remote_hosts[1 if second_src_ip else 0]
+        dst_host = self.pg1.remote_hosts[1 if second_dst_ip else 0]
+        src_addr = src_host.ip6 if is_v6 else src_host.ip4
+        dst_addr = dst_host.ip6 if is_v6 else dst_host.ip4
+        return Ether(src=src_host.mac, dst=self.pg0.local_mac) / IP46(src=src_addr,
+                dst=dst_addr)
+
+    def do_test_one_rule(self, filters, matches, matching_packets, not_matching_packets):
+        # Caution: because of how vpp works, packets may be reordered (v4 first, v6 next)
+        # which may break the check on received packets
+        # Therefore, in matching packets, all v4 packets must be before all v6 packets
+        self.rule.capo_rule_update(filters, matches)
+        self.send_test_packets(self.pg0, self.pg1, matching_packets, not_matching_packets)
+
+    def send_test_packets(self, from_if, to_if, passing_packets, dropped_packets):
+        if len(passing_packets) > 0:
+            rxl = self.send_and_expect(from_if, passing_packets, to_if)
+            self.assertEqual(len(rxl), len(passing_packets))
+            for i in range(len(passing_packets)):
+                rx = rxl[i].payload
+                tx = passing_packets[i].payload
+                tx = tx.__class__(bytes(tx)) # Compute all fields
+                # Remove IP[v6] TTL / checksum that are changed on forwarding
+                if IP in tx:
+                    del tx.chksum, tx.ttl, rx.chksum, rx.ttl
+                elif IPv6 in tx:
+                    del tx.hlim, rx.hlim
+                self.assertEqual(rx, tx)
+        if len(dropped_packets) > 0:
+            self.send_and_assert_no_replies(from_if, dropped_packets, to_if, timeout=0.1)
+        self.vapi.cli("clear acl-plugin sessions")
+
+
+class TestCapoMatches(BaseCapoTest):
+    """ Calico Policies rule matching tests  """
+    @classmethod
+    def setUpClass(self):
+        super(TestCapoMatches, self).setUpClass()
+
+    @classmethod
+    def tearDownClass(self):
+        super(TestCapoMatches, self).tearDownClass()
+
+    def setUp(self):
+        super(TestCapoMatches, self).setUp()
+        self.rule = VppCapoRule(self, is_v6=False, action=ACTION_ALLOW)
+        self.rule.add_vpp_config()
+        self.policy = VppCapoPolicy(self, [VppCapoPolicyItem(is_inbound=1, rule_id=self.rule.vpp_id())])
+        self.policy.add_vpp_config()
+        self.configure_policies(self.pg1, [self.policy], [], [])
+        self.src_ip_ipset = VppCapoIpset(self, IPSET_TYPE_IP, [self.pg0.remote_ip4, self.pg0.remote_ip6])
+        self.src_ip_ipset.add_vpp_config()
+        self.dst_ip_ipset = VppCapoIpset(self, IPSET_TYPE_IP, [self.pg1.remote_ip4, self.pg1.remote_ip6])
+        self.dst_ip_ipset.add_vpp_config()
+        self.src_net_ipset = VppCapoIpset(self, IPSET_TYPE_NET, [self.pg0.remote_ip4+"/32", self.pg0.remote_ip6+"/128"])
+        self.src_net_ipset.add_vpp_config()
+        self.dst_net_ipset = VppCapoIpset(self, IPSET_TYPE_NET, [self.pg1.remote_ip4+"/32", self.pg1.remote_ip6+"/128"])
+        self.dst_net_ipset.add_vpp_config()
+        self.src_ipport_ipset = VppCapoIpset(self, IPSET_TYPE_IP_PORT, [
+            {"address":self.pg0.remote_ip4, "l4_proto": tcp_protocol, "port": src_l4},
+            {"address":self.pg0.remote_ip6, "l4_proto": tcp_protocol, "port": src_l4}
+        ])
+        self.src_ipport_ipset.add_vpp_config()
+        self.dst_ipport_ipset = VppCapoIpset(self, IPSET_TYPE_IP_PORT, [
+            {"address":self.pg1.remote_ip4, "l4_proto": tcp_protocol, "port": dst_l4},
+            {"address":self.pg1.remote_ip6, "l4_proto": tcp_protocol, "port": dst_l4}
+        ])
+        self.dst_ipport_ipset.add_vpp_config()
+
+    def tearDown(self):
+        self.vapi.cli("clear acl-plugin sessions")
+        self.configure_policies(self.pg1, [], [], [])
+        self.policy.capo_policy_delete()
+        self.rule.capo_rule_delete()
+        super(TestCapoMatches, self).tearDown()
+
+    def test_empty_rule(self):
+        # Empty rule matches everything
+        valid = [
+            self.base_ip_packet(False) / TCP(sport=src_l4, dport=dst_l4) / random_payload(),
+            self.base_ip_packet(False) / UDP(sport=src_l4, dport=dst_l4) / random_payload(),
+            self.base_ip_packet(False) / ICMP(type=icmp4_type, code=icmp4_code) / random_payload(),
+            self.base_ip_packet(True) / TCP(sport=src_l4, dport=dst_l4) / random_payload(),
+            self.base_ip_packet(True) / UDP(sport=src_l4, dport=dst_l4) / random_payload(),
+            self.base_ip_packet(True) / ICMPv6EchoRequest(type=icmp6_type, code=icmp6_code) / random_payload(),
+        ]
+        self.do_test_one_rule([], [], valid, [])
+
+    def capo_test_icmp(self, is_v6):
+        ICMP46 = ICMPv6EchoRequest if is_v6 else ICMP
+        icmp_type = icmp6_type if is_v6 else icmp4_type
+        icmp_code = icmp6_code if is_v6 else icmp4_code
+
+        # Define filter on ICMP type
+        filters = [VppCapoFilter(FILTER_TYPE_ICMP_TYPE, value=icmp_type, should_match=1)]
+        valid = self.base_ip_packet(is_v6) / ICMP46(type=icmp_type, code=icmp_code) / random_payload()
+        invalid = self.base_ip_packet(is_v6) / ICMP46(type=11, code=22) / random_payload()
+        self.do_test_one_rule(filters, [], [valid], [invalid])
+
+        # Define filter on ICMP type  / should match = 0
+        filters = [VppCapoFilter(FILTER_TYPE_ICMP_TYPE, value=11, should_match=0)]
+        invalid = self.base_ip_packet(is_v6) / ICMP46(type=11, code=icmp_code) / random_payload()
+        valid = self.base_ip_packet(is_v6) / ICMP46(type=icmp_type, code=icmp_code) / random_payload()
+        self.do_test_one_rule(filters, [], [valid], [invalid])
+
+    def test_icmp4_type(self):
+        self.capo_test_icmp(is_v6=False)
+
+    def test_icmp6_type(self):
+        self.capo_test_icmp(is_v6=True)
+
+    def capo_test_icmp_code(self, is_v6):
+        ICMP46 = ICMPv6EchoRequest if is_v6 else ICMP
+        icmp_type = 1 if is_v6 else 3   # Destination unreachable
+        icmp_code = 9 # admin prohibited
+
+        # Define filter on ICMP type
+        filters = [VppCapoFilter(FILTER_TYPE_ICMP_CODE, value=icmp_code, should_match=1)]
+        valid = self.base_ip_packet(is_v6) / ICMP46(type=icmp_type, code=icmp_code) / random_payload()
+        invalid = self.base_ip_packet(is_v6) / ICMP46(type=icmp_type, code=icmp_code-1) / random_payload()
+        self.do_test_one_rule(filters, [], [valid], [invalid])
+
+        # Define filter on ICMP type  / should match = 0
+        filters = [VppCapoFilter(FILTER_TYPE_ICMP_CODE, value=icmp_code, should_match=0)]
+        valid = self.base_ip_packet(is_v6) / ICMP46(type=icmp_type, code=icmp_code+1) / random_payload()
+        invalid = self.base_ip_packet(is_v6) / ICMP46(type=icmp_type, code=icmp_code) / random_payload()
+        self.do_test_one_rule(filters, [], [valid], [invalid])
+
+    def test_icmp4_code(self):
+        self.capo_test_icmp(is_v6=False)
+
+    def test_icmp6_code(self):
+        self.capo_test_icmp(is_v6=True)
+
+    def capo_test_l4proto(self, is_v6, l4proto):
+        filter_value = 0
+        if l4proto == TCP:
+            filter_value = tcp_protocol
+        elif l4proto == UDP:
+            filter_value = udp_protocol
+
+        # Define filter on l4proto type
+        filters = [VppCapoFilter(FILTER_TYPE_L4_PROTO, value=filter_value, should_match=1)]
+
+        # Send tcp pg0 -> pg1
+        valid = self.base_ip_packet(is_v6) / l4proto(sport=src_l4, dport=dst_l4) / random_payload()
+        # send icmp packet (different l4proto) and expect packet is filtered
+        invalid = self.base_ip_packet(is_v6) / ICMP(type=8, code=3) / random_payload()
+        self.do_test_one_rule(filters, [], [valid], [invalid])
+
+        # Define filter on l4proto / should match = 0
+        filters = [VppCapoFilter(FILTER_TYPE_L4_PROTO, value=filter_value, should_match=0)]
+        # send l4proto packet and expect it is filtered
+        invalid = self.base_ip_packet(is_v6) / l4proto(sport=src_l4, dport=dst_l4) / random_payload()
+        # send icmp packet (different l4proto) and expect it is not filtered
+        valid = self.base_ip_packet(is_v6) / ICMP(type=8, code=3) / random_payload()
+        self.do_test_one_rule(filters, [], [valid], [invalid])
+
+    def test_l4proto_tcp4(self):
+        self.capo_test_l4proto(False, TCP)
+
+    def test_l4proto_tcp6(self):
+        self.capo_test_l4proto(True, TCP)
+
+    def test_l4proto_udp4(self):
+        self.capo_test_l4proto(False, UDP)
+
+    def test_l4proto_udp6(self):
+        self.capo_test_l4proto(True, UDP)
+
+    def test_prefixes_ip6(self):
+        self.test_prefixes(True)
+
+    def test_prefixes(self, is_ip6=False):
+        pload = lambda : TCP(sport=src_l4, dport=dst_l4) / random_payload()
+        dst_ip_match = self.pg1.remote_ip6 + "/128" if is_ip6 else self.pg1.remote_ip4 + "/32"
+        match = {"is_src": False, "is_not": False, "type": ENTRY_CIDR, "data": {"cidr": dst_ip_match}}
+        valid = self.base_ip_packet(is_ip6) / pload()
+        invalid = self.base_ip_packet(is_ip6, second_dst_ip=True) / pload()
+        self.do_test_one_rule([], [match], [valid], [invalid])
+
+        match['is_not'] = True
+        self.do_test_one_rule([], [match], [invalid], [valid])
+
+        src_ip_match = self.pg0.remote_ip6 + "/128" if is_ip6 else self.pg0.remote_ip4 + "/32"
+        match = {"is_src": True, "is_not": False, "type": ENTRY_CIDR, "data": {"cidr": src_ip_match}}
+        valid = self.base_ip_packet(is_ip6) / pload()
+        invalid = self.base_ip_packet(is_ip6, second_src_ip=True) / pload()
+        self.do_test_one_rule([], [match], [valid], [invalid])
+
+        match['is_not'] = True
+        self.do_test_one_rule([], [match], [invalid], [valid])
+
+    def test_port_ranges_ip6(self):
+        self.test_prefixes(True)
+
+    def test_port_ranges(self, is_ip6=False):
+        base = self.base_ip_packet(is_ip6)
+        test_port = 5123
+        # Test all match kinds
+        match = {"is_src": False, "is_not": False, "type": ENTRY_PORT_RANGE,
+                 "data": {"port_range": {"start": test_port, "end": test_port}}}
+        valid = base / TCP(sport=test_port, dport=test_port) / random_payload()
+        invalid = [
+            base / TCP(sport=test_port, dport=test_port+1) / random_payload(),
+            base / TCP(sport=test_port, dport=test_port-1) / random_payload(),
+        ]
+        self.do_test_one_rule([], [match], [valid], invalid)
+
+        match['is_not'] = True
+        self.do_test_one_rule([], [match], invalid, [valid])
+
+        match = {"is_src": True, "is_not": False, "type": ENTRY_PORT_RANGE,
+                 "data": {"port_range": {"start": test_port, "end": test_port}}}
+        valid = base / TCP(sport=test_port, dport=test_port) / random_payload()
+        invalid = [
+            base / TCP(sport=test_port+1, dport=test_port) / random_payload(),
+            base / TCP(sport=test_port-1, dport=test_port) / random_payload(),
+        ]
+        self.do_test_one_rule([], [match], [valid], invalid)
+
+        match['is_not'] = True
+        self.do_test_one_rule([], [match], invalid, [valid])
+
+        # Test port ranges with several ports & UDP
+        match = {"is_src": False, "is_not": False, "type": ENTRY_PORT_RANGE,
+                 "data": {"port_range": {"start": test_port, "end": test_port+10}}}
+        valid = [
+            base / TCP(sport=test_port, dport=test_port) / random_payload(),
+            base / TCP(sport=test_port, dport=test_port+5) / random_payload(),
+            base / TCP(sport=test_port, dport=test_port+10) / random_payload(),
+            base / UDP(sport=test_port, dport=test_port) / random_payload(),
+            base / UDP(sport=test_port, dport=test_port+5) / random_payload(),
+            base / UDP(sport=test_port, dport=test_port+10) / random_payload(),
+        ]
+        invalid = [
+            base / TCP(sport=test_port, dport=test_port-1) / random_payload(),
+            base / TCP(sport=test_port, dport=test_port+11) / random_payload(),
+        ]
+        self.do_test_one_rule([], [match], valid, invalid)
+
+
+    def test_ip_ipset_ip6(self):
+        self.test_ip_ipset(True)
+
+    def test_ip_ipset(self, is_ip6=False):
+        pload = lambda : TCP(sport=src_l4, dport=dst_l4) / random_payload()
+        dst_ip_match = self.pg1.remote_ip6 + "/128" if is_ip6 else self.pg1.remote_ip4 + "/32"
+        match = {"is_src": False, "is_not": False, "type": ENTRY_IP_SET,
+                 "data": {"set_id": {"set_id": self.dst_ip_ipset.vpp_id}}}
+        valid = self.base_ip_packet(is_ip6) / pload()
+        invalid = self.base_ip_packet(is_ip6, second_dst_ip=True) / pload()
+        self.do_test_one_rule([], [match], [valid], [invalid])
+
+        match['is_not'] = True
+        self.do_test_one_rule([], [match], [invalid], [valid])
+
+        src_ip_match = self.pg0.remote_ip6 + "/128" if is_ip6 else self.pg0.remote_ip4 + "/32"
+        match = {"is_src": True, "is_not": False, "type": ENTRY_IP_SET,
+                 "data": {"set_id": {"set_id": self.src_ip_ipset.vpp_id}}}
+        valid = self.base_ip_packet(is_ip6) / pload()
+        invalid = self.base_ip_packet(is_ip6, second_src_ip=True) / pload()
+        self.do_test_one_rule([], [match], [valid], [invalid])
+
+        match['is_not'] = True
+        self.do_test_one_rule([], [match], [invalid], [valid])
+
+    def test_net_ipset_ip6(self):
+        self.test_net_ipset(True)
+
+    def test_net_ipset(self, is_ip6=False):
+        pload = lambda : TCP(sport=src_l4, dport=dst_l4) / random_payload()
+        dst_ip_match = self.pg1.remote_ip6 + "/128" if is_ip6 else self.pg1.remote_ip4 + "/32"
+        match = {"is_src": False, "is_not": False, "type": ENTRY_IP_SET,
+                 "data": {"set_id": {"set_id": self.dst_net_ipset.vpp_id}}}
+        valid = self.base_ip_packet(is_ip6) / pload()
+        invalid = self.base_ip_packet(is_ip6, second_dst_ip=True) / pload()
+        self.do_test_one_rule([], [match], [valid], [invalid])
+
+        match['is_not'] = True
+        self.do_test_one_rule([], [match], [invalid], [valid])
+
+        src_ip_match = self.pg0.remote_ip6 + "/128" if is_ip6 else self.pg0.remote_ip4 + "/32"
+        match = {"is_src": True, "is_not": False, "type": ENTRY_IP_SET,
+                 "data": {"set_id": {"set_id": self.src_net_ipset.vpp_id}}}
+        valid = self.base_ip_packet(is_ip6) / pload()
+        invalid = self.base_ip_packet(is_ip6, second_src_ip=True) / pload()
+        self.do_test_one_rule([], [match], [valid], [invalid])
+
+        match['is_not'] = True
+        self.do_test_one_rule([], [match], [invalid], [valid])
+
+    def test_ipport_ipset_ip6(self):
+        self.test_ipport_ipset(True)
+
+    def test_ipport_ipset(self, is_ip6=False):
+        match = {"is_src": False, "is_not": False, "type": ENTRY_PORT_IP_SET,
+                 "data": {"set_id": {"set_id": self.dst_ipport_ipset.vpp_id}}}
+        valid = self.base_ip_packet(is_ip6) / TCP(sport=src_l4, dport=dst_l4) / random_payload()
+        invalid = [ # Change all criteria: address, proto, port
+            self.base_ip_packet(is_ip6, second_dst_ip=True) / TCP(sport=src_l4, dport=dst_l4) / random_payload(),
+            self.base_ip_packet(is_ip6) / UDP(sport=src_l4, dport=dst_l4) / random_payload(),
+            self.base_ip_packet(is_ip6) / TCP(sport=src_l4, dport=dst_l4+1) / random_payload(),
+        ]
+        self.do_test_one_rule([], [match], [valid], invalid)
+
+        match['is_not'] = True
+        self.do_test_one_rule([], [match], invalid, [valid])
+
+        match = {"is_src": True, "is_not": False, "type": ENTRY_PORT_IP_SET,
+                 "data": {"set_id": {"set_id": self.src_ipport_ipset.vpp_id}}}
+        valid = self.base_ip_packet(is_ip6) / TCP(sport=src_l4, dport=dst_l4) / random_payload()
+        invalid = [ # Change all criteria: address, proto, port
+            self.base_ip_packet(is_ip6, second_src_ip=True) / TCP(sport=src_l4, dport=dst_l4) / random_payload(),
+            self.base_ip_packet(is_ip6) / UDP(sport=src_l4, dport=dst_l4) / random_payload(),
+            self.base_ip_packet(is_ip6) / TCP(sport=src_l4+1, dport=dst_l4) / random_payload(),
+        ]
+        self.do_test_one_rule([], [match], [valid], invalid)
+
+        match['is_not'] = True
+        self.do_test_one_rule([], [match], invalid, [valid])
+
+    # Calico specificity: if a rule has port ranges and ipport ipsets, a packet matches
+    # the rule if it matches either category
+    def test_port_range_and_ipport_ipset_ip6(self):
+            self.test_port_range_and_ipport_ipset(True)
+
+    def test_port_range_and_ipport_ipset(self, is_ip6=False):
+        # Test all match types to exercies all code (but not all combinations)
+        test_port=4569
+        matches = [
+            {"is_src": False, "is_not": False, "type": ENTRY_PORT_IP_SET,
+                "data": {"set_id": {"set_id": self.dst_ipport_ipset.vpp_id}}},
+            {"is_src": False, "is_not": False, "type": ENTRY_PORT_RANGE,
+                "data": {"port_range": {"start": test_port, "end": test_port}}},
+        ]
+        valid = [
+            self.base_ip_packet(is_ip6) / TCP(sport=src_l4, dport=dst_l4) / random_payload(),
+            self.base_ip_packet(is_ip6) / TCP(sport=src_l4, dport=test_port) / random_payload(),
+            self.base_ip_packet(is_ip6) / UDP(sport=src_l4, dport=test_port) / random_payload(),
+            self.base_ip_packet(is_ip6, second_src_ip=True) / TCP(sport=src_l4, dport=test_port) / random_payload(),
+            self.base_ip_packet(is_ip6, second_dst_ip=True) / TCP(sport=src_l4, dport=test_port) / random_payload(),
+        ]
+        invalid = [
+            self.base_ip_packet(is_ip6, second_dst_ip=True) / TCP(sport=src_l4, dport=dst_l4) / random_payload(),
+            self.base_ip_packet(is_ip6) / UDP(sport=src_l4, dport=dst_l4) / random_payload(),
+            self.base_ip_packet(is_ip6) / TCP(sport=src_l4, dport=(dst_l4+test_port)//2) / random_payload(),
+        ]
+        self.do_test_one_rule([], matches, valid, invalid)
+
+        for match in matches:
+            match['is_not'] = True
+        self.do_test_one_rule([], matches, invalid, valid)
+
+        matches = [
+            {"is_src": True, "is_not": False, "type": ENTRY_PORT_IP_SET,
+                "data": {"set_id": {"set_id": self.src_ipport_ipset.vpp_id}}},
+            {"is_src": True, "is_not": False, "type": ENTRY_PORT_RANGE,
+                "data": {"port_range": {"start": test_port, "end": test_port}}},
+        ]
+        valid = [
+            self.base_ip_packet(is_ip6) / TCP(sport=src_l4, dport=dst_l4) / random_payload(),
+            self.base_ip_packet(is_ip6) / TCP(sport=test_port, dport=dst_l4) / random_payload(),
+            self.base_ip_packet(is_ip6) / UDP(sport=test_port, dport=dst_l4) / random_payload(),
+            self.base_ip_packet(is_ip6, second_src_ip=True) / TCP(sport=test_port, dport=dst_l4) / random_payload(),
+            self.base_ip_packet(is_ip6, second_dst_ip=True) / TCP(sport=test_port, dport=dst_l4) / random_payload(),
+        ]
+        invalid = [
+            self.base_ip_packet(is_ip6, second_src_ip=True) / TCP(sport=src_l4, dport=dst_l4) / random_payload(),
+            self.base_ip_packet(is_ip6) / UDP(sport=src_l4, dport=dst_l4) / random_payload(),
+            self.base_ip_packet(is_ip6) / TCP(sport=(src_l4+test_port)//2, dport=dst_l4) / random_payload(),
+        ]
+        self.do_test_one_rule([], matches, valid, invalid)
+
+        for match in matches:
+            match['is_not'] = True
+        self.do_test_one_rule([], matches, invalid, valid)
+
+
+class TestCapoPolicies(BaseCapoTest):
+    """ Calico Policies tests """
+    @classmethod
+    def setUpClass(self):
+        super(TestCapoPolicies, self).setUpClass()
+
+    @classmethod
+    def tearDownClass(self):
+        super(TestCapoPolicies, self).tearDownClass()
+
+    def setUp(self):
+        super(TestCapoPolicies, self).setUp()
+
+    def tearDown(self):
+        super(TestCapoPolicies, self).tearDown()
+
+    def tcp_dport_rule(self, port, action):
+        return VppCapoRule(self, is_v6=False, action=action,
+            filters=[VppCapoFilter(FILTER_TYPE_L4_PROTO, tcp_protocol, True)],
+            matches=[{"is_src": False, "is_not": False, "type": ENTRY_PORT_RANGE,
+                        "data": {"port_range": {"start": port, "end": port}}}]
+        )
+
+    def test_inbound_outbound(self):
+        r = self.tcp_dport_rule(1000, ACTION_ALLOW)
+        r.add_vpp_config()
+        pin = VppCapoPolicy(self, [VppCapoPolicyItem(is_inbound=1, rule_id=r.vpp_id())])
+        pout = VppCapoPolicy(self, [VppCapoPolicyItem(is_inbound=0, rule_id=r.vpp_id())])
+        pin.add_vpp_config()
+        pout.add_vpp_config()
+
+        matching = self.base_ip_packet() / TCP(sport=1, dport=1000) / random_payload()
+        not_matching = self.base_ip_packet() / TCP(sport=1, dport=2000) / random_payload()
+
+        # out policy at src
+        self.configure_policies(self.pg0, [], [pout], [])
+        self.send_test_packets(self.pg0, self.pg1, [matching], [not_matching])
+
+        # policies configured at src + dst
+        self.configure_policies(self.pg1, [pin], [], [])
+        self.send_test_packets(self.pg0, self.pg1, [matching], [not_matching])
+
+        # policies configured at dst
+        self.configure_policies(self.pg0, [], [], [])
+        self.send_test_packets(self.pg0, self.pg1, [matching], [not_matching])
+
+        # no policies
+        self.configure_policies(self.pg1, [], [], [])
+        self.send_test_packets(self.pg0, self.pg1, [matching, not_matching], [])
+
+    def test_default_verdict(self):
+        # If profiles only are configured (pass_id = 0), default is deny
+        # If there are policies + profiles (pass_id > 0), then default is to deny before
+        # evaluating profiles, unless a rule with a PASS target matches
+        rule1 = self.tcp_dport_rule(1000, ACTION_ALLOW)
+        rule2 = self.tcp_dport_rule(2000, ACTION_ALLOW)
+        rule3 = self.tcp_dport_rule(1000, ACTION_DENY)
+        rule4 = self.tcp_dport_rule(1000, ACTION_PASS)
+        rule1.add_vpp_config()
+        rule2.add_vpp_config()
+        rule3.add_vpp_config()
+        rule4.add_vpp_config()
+        policy1 = VppCapoPolicy(self, [VppCapoPolicyItem(is_inbound=1, rule_id=rule1.vpp_id())])
+        policy2 = VppCapoPolicy(self, [VppCapoPolicyItem(is_inbound=1, rule_id=rule2.vpp_id())])
+        policy3 = VppCapoPolicy(self, [VppCapoPolicyItem(is_inbound=1, rule_id=rule3.vpp_id())])
+        policy4 = VppCapoPolicy(self, [VppCapoPolicyItem(is_inbound=1, rule_id=rule4.vpp_id())])
+        policy5 = VppCapoPolicy(self, [
+            VppCapoPolicyItem(is_inbound=1, rule_id=rule4.vpp_id()),
+            VppCapoPolicyItem(is_inbound=1, rule_id=rule3.vpp_id()),
+        ])
+        policy1.add_vpp_config()
+        policy2.add_vpp_config()
+        policy3.add_vpp_config()
+        policy4.add_vpp_config()
+        policy5.add_vpp_config()
+
+        # Test profile default deny: 1 allow rule, pass_id=0
+        self.configure_policies(self.pg1, [], [], [policy1])
+        passing = [self.base_ip_packet() / TCP(sport=1, dport=1000) / random_payload()]
+        dropped = [self.base_ip_packet() / TCP(sport=1, dport=2000) / random_payload()]
+        self.send_test_packets(self.pg0, self.pg1, passing, dropped)
+
+        # Test policy default deny: 1 allow rule, pass_id=1
+        self.configure_policies(self.pg1, [policy1], [], [])
+        self.send_test_packets(self.pg0, self.pg1, passing, dropped)
+
+        # Test that profiles are not executed when policies are configured
+        # 1 allow policy, 1 allow profile, pass_id=1
+        self.configure_policies(self.pg1, [policy1], [], [policy2])
+        self.send_test_packets(self.pg0, self.pg1, passing, dropped)
+
+        # Test that pass target does not evaluate further policies and jumps to profiles
+        # 1 pass policy, 1 deny policy, 1 allow profile, pass_id=2
+        self.configure_policies(self.pg1, [policy4, policy3], [], [policy1])
+        self.send_test_packets(self.pg0, self.pg1, passing, dropped)
+
+        # Test that pass target does not evaluate further rules in the policy and jumps to profiles
+        # 1 policy w/ 1 pass rule & 1 deny rule, 1 deny profile, pass_id=1
+        self.configure_policies(self.pg1, [policy5], [], [policy1])
+        self.send_test_packets(self.pg0, self.pg1, passing, dropped)
+
+        policy1.remove_vpp_config()
+        policy2.remove_vpp_config()
+        policy3.remove_vpp_config()
+        policy4.remove_vpp_config()
+        policy5.remove_vpp_config()
+        rule1.remove_vpp_config()
+        rule2.remove_vpp_config()
+        rule3.remove_vpp_config()
+        rule4.remove_vpp_config()
+
+    def test_realistic_policy(self):
+        # Rule 1 allows ping from everywhere
+        rule1 = VppCapoRule(self, is_v6=False, action=ACTION_ALLOW,
+            filters = [
+                VppCapoFilter(FILTER_TYPE_L4_PROTO, icmp_protocol, True),
+                VppCapoFilter(FILTER_TYPE_ICMP_TYPE, 8, True),
+                VppCapoFilter(FILTER_TYPE_ICMP_CODE, 0, True),
+            ],
+            matches = [],
+        )
+        rule1.add_vpp_config()
+        # Rule 2 allows tcp dport 8080 from a single container
+        src_ipset = VppCapoIpset(self, IPSET_TYPE_NET,
+                [self.pg0.remote_ip4 + "/32", self.pg0.remote_ip6 + "/128"])
+        src_ipset.add_vpp_config()
+        rule2 = VppCapoRule(self, is_v6=False, action=ACTION_ALLOW,
+            filters=[
+                VppCapoFilter(FILTER_TYPE_L4_PROTO, tcp_protocol, True),
+            ],
+            matches = [
+                {"is_src": True, "is_not": False, "type": ENTRY_IP_SET,
+                        "data": {"set_id": {"set_id": src_ipset.vpp_id}}},
+                {"is_src": False, "is_not": False, "type": ENTRY_PORT_RANGE,
+                        "data": {"port_range": {"start": 8080, "end": 8080}}},
+            ],
+        )
+        rule2.add_vpp_config()
+        policy = VppCapoPolicy(self, [
+            VppCapoPolicyItem(is_inbound=1, rule_id=rule1.vpp_id()),
+            VppCapoPolicyItem(is_inbound=1, rule_id=rule2.vpp_id()),
+        ])
+        policy.add_vpp_config()
+        self.configure_policies(self.pg1, [policy], [], [])
+
+        passing = [
+            self.base_ip_packet() / ICMP(type=8),
+            self.base_ip_packet(second_src_ip=True) / ICMP(type=8),
+            self.base_ip_packet() / TCP(sport=1, dport=8080) / random_payload(),
+        ]
+        dropped = [
+            self.base_ip_packet() / ICMP(type=3),
+            self.base_ip_packet(second_src_ip=True) / TCP(sport=1, dport=8080) / random_payload(),
+            self.base_ip_packet() / UDP(sport=1, dport=8080) / random_payload(),
+            self.base_ip_packet() / TCP(sport=1, dport=8081) / random_payload(),
+        ]
+        self.send_test_packets(self.pg0, self.pg1, passing, dropped)
+        # Cleanup
+        self.configure_policies(self.pg1, [], [], [])
+        policy.remove_vpp_config()
+        rule1.remove_vpp_config()
+        rule2.remove_vpp_config()
+        src_ipset.remove_vpp_config()
diff --git a/src/plugins/cnat/cnat_node_feature.c b/src/plugins/cnat/cnat_node_feature.c
index aced4cd0a..0f40b40d3 100644
--- a/src/plugins/cnat/cnat_node_feature.c
+++ b/src/plugins/cnat/cnat_node_feature.c
@@ -43,6 +43,7 @@ cnat_input_feature_fn (vlib_main_t *vm, vlib_node_runtime_t *node,
 		       int session_not_found, cnat_session_t *session)
 {
   vlib_combined_counter_main_t *cntm = &cnat_translation_counters;
+  cnat_snat_policy_main_t *cpm = &cnat_snat_policy_main;
   const cnat_translation_t *ct = NULL;
   ip4_header_t *ip4 = NULL;
   ip_protocol_t iproto;
@@ -95,6 +96,8 @@ cnat_input_feature_fn (vlib_main_t *vm, vlib_node_runtime_t *node,
       cnat_ep_trk_t *trk0;
       u32 rsession_flags = CNAT_SESSION_FLAG_NO_CLIENT;
       u32 dpoi_index = -1;
+      u32 in_if = vnet_buffer (b)->sw_if_index[VLIB_RX];
+      int ispod;
 
       lb0 = load_balance_get (ct->ct_lb.dpoi_index);
       if (!lb0->lb_n_buckets)
@@ -127,7 +130,10 @@ cnat_input_feature_fn (vlib_main_t *vm, vlib_node_runtime_t *node,
       session->value.cs_port[VLIB_RX] = udp0->src_port;
       session->value.flags = 0;
 
-      if (trk0->ct_flags & CNAT_TRK_FLAG_NO_NAT)
+      ispod = clib_bitmap_get (
+	cpm->interface_maps[CNAT_SNAT_IF_MAP_INCLUDE_POD], in_if);
+
+      if (trk0->ct_flags & CNAT_TRK_FLAG_NO_NAT && !ispod)
 	{
 	  const dpo_id_t *dpo0;
 	  const load_balance_t *lb1;
diff --git a/src/plugins/dpdk/device/dpdk.h b/src/plugins/dpdk/device/dpdk.h
index 196f68f97..c64abc895 100644
--- a/src/plugins/dpdk/device/dpdk.h
+++ b/src/plugins/dpdk/device/dpdk.h
@@ -242,6 +242,7 @@ typedef struct
   };
   dpdk_device_addr_type_t dev_addr_type;
   u8 *name;
+  u8 *tag;
   u8 is_blacklisted;
 
 #define _(x) uword x;
diff --git a/src/plugins/dpdk/device/init.c b/src/plugins/dpdk/device/init.c
index 6c34981b2..bcf5a26e3 100644
--- a/src/plugins/dpdk/device/init.c
+++ b/src/plugins/dpdk/device/init.c
@@ -439,6 +439,9 @@ dpdk_lib_init (dpdk_main_t * dm)
       xd->sw_if_index = sw->sw_if_index;
       dpdk_log_debug ("[%u] interface %s created", port_id, hi->name);
 
+      if (devconf->tag)
+	vnet_set_sw_interface_tag (vnm, devconf->tag, sw->sw_if_index);
+
       ethernet_set_flags (vnm, xd->hw_if_index,
 			  ETHERNET_INTERFACE_FLAG_DEFAULT_L3);
 
@@ -850,6 +853,8 @@ dpdk_device_config (dpdk_config_main_t *conf, void *addr,
 	;
       else if (unformat (input, "name %v", &devconf->name))
 	;
+      else if (unformat (input, "tag %s", &devconf->tag))
+	;
       else if (unformat (input, "workers %U", unformat_bitmap_list,
 			 &devconf->workers))
 	;
@@ -966,6 +971,7 @@ dpdk_config (vlib_main_t * vm, unformat_input_t * input)
   u8 *socket_mem = 0;
   u8 *huge_dir_path = 0;
   u32 vendor, device, domain, bus, func;
+  bool ioat = true;
 
   huge_dir_path =
     format (0, "%s/hugepages%c", vlib_unix_get_runtime_dir (), 0);
@@ -1136,7 +1142,7 @@ dpdk_config (vlib_main_t * vm, unformat_input_t * input)
 #undef _
 	else if (unformat (input, "default"))
 	;
-
+      else if (unformat (input, "no-ioat")) { ioat = false; }
       else if (unformat_skip_white_space (input))
 	;
       else
@@ -1275,6 +1281,14 @@ dpdk_config (vlib_main_t * vm, unformat_input_t * input)
 
   vm = vlib_get_main ();
 
+  if (!ioat)
+    {
+      struct rte_bus *bus;
+      bus = rte_bus_find_by_name ("dsa");
+      if (bus)
+	rte_bus_unregister (bus);
+    }
+
   /* make copy of args as rte_eal_init tends to mess up with arg array */
   for (i = 1; i < vec_len (conf->eal_init_args); i++)
     conf->eal_init_args_str = format (conf->eal_init_args_str, "%s ",
diff --git a/src/plugins/dsa_intel/CMakeLists.txt b/src/plugins/dsa_intel/CMakeLists.txt
new file mode 100644
index 000000000..26c1e3efd
--- /dev/null
+++ b/src/plugins/dsa_intel/CMakeLists.txt
@@ -0,0 +1,10 @@
+# SPDX-License-Identifier: Apache-2.0
+# Copyright(c) 2022 Cisco Systems, Inc.
+
+add_vpp_plugin(dsa_intel
+  SOURCES
+  dsa.c
+  dsa_pci.c
+  format.c
+  main.c
+)
diff --git a/src/plugins/dsa_intel/dsa.c b/src/plugins/dsa_intel/dsa.c
new file mode 100644
index 000000000..5dead3f92
--- /dev/null
+++ b/src/plugins/dsa_intel/dsa.c
@@ -0,0 +1,410 @@
+/* SPDX-License-Identifier: Apache-2.0
+ * Copyright(c) 2022 Cisco Systems, Inc.
+ * Copyright (c) 2022 Intel and/or its affiliates.
+ */
+
+#include <vlib/vlib.h>
+#include <vlib/pci/pci.h>
+#include <vlib/dma/dma.h>
+#include <vppinfra/heap.h>
+#include <vppinfra/atomics.h>
+#include <vnet/plugin/plugin.h>
+#include <vpp/app/version.h>
+#include <dsa_intel/dsa_intel.h>
+
+extern vlib_node_registration_t intel_dsa_node;
+
+VLIB_REGISTER_LOG_CLASS (intel_dsa_log, static) = {
+  .class_name = "intel_dsa",
+  .subclass_name = "dsa",
+};
+
+static void
+intel_dsa_channel_lock (intel_dsa_channel_t *ch)
+{
+  u8 expected = 0;
+  if (ch->n_threads < 2)
+    return;
+
+  /* channel is used by multiple threads so we need to lock it */
+  while (!__atomic_compare_exchange_n (&ch->lock, &expected,
+				       /* desired */ 1, /* weak */ 0,
+				       __ATOMIC_ACQUIRE, __ATOMIC_RELAXED))
+    {
+      while (__atomic_load_n (&ch->lock, __ATOMIC_RELAXED))
+	CLIB_PAUSE ();
+      expected = 0;
+    }
+}
+
+static void
+intel_dsa_channel_unlock (intel_dsa_channel_t *ch)
+{
+  if (ch->n_threads < 2)
+    return;
+
+  __atomic_store_n (&ch->lock, 0, __ATOMIC_RELEASE);
+}
+
+static vlib_dma_batch_t *
+intel_dsa_batch_new (vlib_main_t *vm, struct vlib_dma_config_data *cd)
+{
+  intel_dsa_main_t *idm = &intel_dsa_main;
+  intel_dsa_config_t *idc;
+  intel_dsa_batch_t *b;
+
+  idc = vec_elt_at_index (idm->dsa_config_heap,
+			  cd->private_data + vm->thread_index);
+
+  if (vec_len (idc->freelist) > 0)
+      b = vec_pop (idc->freelist);
+  else
+    {
+      clib_spinlock_lock (&idm->lock);
+      b = vlib_physmem_alloc (vm, idc->alloc_size);
+      /* if no free space in physmem, force quit */
+      ASSERT(b != NULL);
+      *b = idc->batch_template;
+      vlib_pci_map_dma (vm, b->ch->pci_handle, b);
+      clib_spinlock_unlock (&idm->lock);
+      b->max_transfers = idc->max_transfers;
+
+      u32 def_flags = (INTEL_DSA_OP_MEMMOVE << INTEL_DSA_OP_SHIFT) |
+			       INTEL_DSA_FLAG_CACHE_CONTROL;
+      if (b->ch->block_on_fault)
+        def_flags |= INTEL_DSA_FLAG_BLOCK_ON_FAULT;
+      for (int i = 0; i < idc->max_transfers; i++)
+	{
+	  intel_dsa_desc_t *dsa_desc = b->descs + i;
+	  dsa_desc->op_flags = def_flags;
+	}
+    }
+
+  return &b->batch;
+}
+
+static_always_inline void
+__movdir64b (volatile void *dst, const void *src)
+{
+  asm volatile(".byte 0x66, 0x0f, 0x38, 0xf8, 0x02"
+	       :
+	       : "a"(dst), "d"(src)
+	       : "memory");
+}
+
+static_always_inline void
+intel_dsa_batch_fallback (vlib_main_t *vm, intel_dsa_batch_t *b, intel_dsa_channel_t *ch)
+{
+  for (u16 i = 0; i < b->batch.n_enq; i++)
+    {
+      intel_dsa_desc_t *desc =  &b->descs[i];
+      clib_memcpy_fast(desc->dst, desc->src, desc->size);
+    }
+  b->status = INTEL_DSA_STATUS_CPU_SUCCESS;
+  ch->submitted ++;
+  return;
+}
+
+int
+intel_dsa_batch_submit (vlib_main_t *vm, struct vlib_dma_batch *vb)
+{
+  intel_dsa_main_t *idm = &intel_dsa_main;
+  intel_dsa_batch_t *b = (intel_dsa_batch_t *) vb;
+  intel_dsa_channel_t *ch = b->ch;
+  if (PREDICT_FALSE (vb->n_enq == 0))
+  {
+    vec_add1 (idm->dsa_config_heap[b->config_heap_index].freelist, b);
+    return 0;
+  }
+
+  intel_dsa_channel_lock (ch);
+  if (ch->n_enq >= ch->size)
+   {
+     if (!b->sw_fallback)
+     {
+	intel_dsa_channel_unlock (ch);
+	return 0;
+     }
+     /* skip channel limitation if first pending finished */
+    intel_dsa_batch_t *lb = NULL;
+    u32 n_pendings = vec_len (idm->dsa_threads[vm->thread_index].pending_batches);
+    if (n_pendings)
+      lb = idm->dsa_threads[vm->thread_index].pending_batches[n_pendings - 1];
+
+    if (lb && lb->status != INTEL_DSA_STATUS_SUCCESS)
+      {
+	intel_dsa_batch_fallback (vm, b, ch);
+	goto done;
+      }
+   }
+
+  b->status = INTEL_DSA_STATUS_BUSY;
+  if (PREDICT_FALSE (vb->n_enq == 1))
+    {
+      intel_dsa_desc_t *desc = &b->descs[0];
+      desc->completion = (u64) &b->completion_cl;
+      desc->op_flags |= INTEL_DSA_FLAG_COMPLETION_ADDR_VALID |
+			INTEL_DSA_FLAG_REQUEST_COMPLETION;
+      _mm_sfence (); /* fence before writing desc to device */
+      __movdir64b (ch->portal, (void *) desc);
+    }
+  else
+    {
+      intel_dsa_desc_t *batch_desc = &b->descs[b->max_transfers];
+      batch_desc->op_flags = (INTEL_DSA_OP_BATCH << INTEL_DSA_OP_SHIFT) |
+			     INTEL_DSA_FLAG_COMPLETION_ADDR_VALID |
+			     INTEL_DSA_FLAG_REQUEST_COMPLETION;
+      batch_desc->desc_addr = (void *) (b->descs);
+      batch_desc->size = vb->n_enq;
+      batch_desc->completion = (u64) &b->completion_cl;
+      _mm_sfence (); /* fence before writing desc to device */
+      __movdir64b (ch->portal, (void *) batch_desc);
+    }
+
+  ch->submitted ++;
+  ch->n_enq ++;
+
+done:
+  intel_dsa_channel_unlock (ch);
+  vec_add1 (idm->dsa_threads[vm->thread_index].pending_batches, b);
+  vlib_node_set_interrupt_pending (vm, intel_dsa_node.index);
+  return 1;
+}
+
+static int
+intel_dsa_check_channel (intel_dsa_channel_t *ch, vlib_dma_config_data_t *cd)
+{
+  if (!ch)
+    {
+      dsa_log_error ("no available dsa channel");
+      return 1;
+    }
+  vlib_dma_config_t supported_cfg = {
+    .barrier_before_last = 1,
+    .sw_fallback = 1,
+  };
+
+  fprintf(stderr, "cd->cfg.features %x supported_cfg.features %x\n", cd->cfg.features,
+		  supported_cfg.features);
+//  if (cd->cfg.features & ~supported_cfg.features)
+//    {
+//      dsa_log_error ("unsupported feature requested");
+//      return 1;
+//    }
+
+  if (cd->cfg.max_transfers > ch->max_transfers)
+    {
+      dsa_log_error ("transfer number (%u) too big", cd->cfg.max_transfers);
+      return 1;
+    }
+
+  if (cd->cfg.max_transfer_size > ch->max_transfer_size)
+    {
+      dsa_log_error ("transfer size (%u) too big", cd->cfg.max_transfer_size);
+      return 1;
+    }
+  return 0;
+}
+
+static int
+intel_dsa_config_add_fn (vlib_main_t *vm, vlib_dma_config_data_t *cd)
+{
+  intel_dsa_main_t *idm = &intel_dsa_main;
+  intel_dsa_config_t *idc;
+  u32 index, n_threads = vlib_get_n_threads ();
+
+  vec_validate (idm->dsa_config_heap_handle_by_config_index,
+		cd->config_index);
+  index = heap_alloc_aligned (
+    idm->dsa_config_heap, n_threads, CLIB_CACHE_LINE_BYTES,
+    idm->dsa_config_heap_handle_by_config_index[cd->config_index]);
+
+  cd->batch_new_fn = intel_dsa_batch_new;
+  cd->private_data = index;
+
+  for (u32 thread = 0; thread < n_threads; thread++)
+    {
+      intel_dsa_batch_t *idb;
+      vlib_dma_batch_t *b;
+      idc = vec_elt_at_index (idm->dsa_config_heap, index + thread);
+
+      /* size of physmem allocation for this config */
+      idc->max_transfers = cd->cfg.max_transfers;
+      idc->alloc_size = sizeof (intel_dsa_batch_t) +
+			sizeof (intel_dsa_desc_t) * (idc->max_transfers + 1);
+      /* fill batch template */
+      idb = &idc->batch_template;
+      idb->ch = idm->dsa_threads[thread].ch;
+      if (intel_dsa_check_channel(idb->ch, cd))
+        return 0;
+
+      dsa_log_debug ("config %d in thread %d using channel %u/%u", cd->config_index,
+			thread, idb->ch->did, idb->ch->qid);
+      idb->config_heap_index = index + thread;
+      idb->config_index = cd->config_index;
+      idb->batch.callback_fn = cd->cfg.callback_fn;
+      idb->features = cd->cfg.features;
+      b = &idb->batch;
+      b->stride = sizeof (intel_dsa_desc_t);
+      b->src_ptr_off = STRUCT_OFFSET_OF (intel_dsa_batch_t, descs[0].src);
+      b->dst_ptr_off = STRUCT_OFFSET_OF (intel_dsa_batch_t, descs[0].dst);
+      b->size_off = STRUCT_OFFSET_OF (intel_dsa_batch_t, descs[0].size);
+      b->submit_fn = intel_dsa_batch_submit;
+      dsa_log_debug ("config %d in thread %d stride %d src/dst/size offset %d-%d-%d",
+      		     cd->config_index, thread, b->stride,  b->src_ptr_off, b->dst_ptr_off,
+		     b->size_off);
+    }
+
+  dsa_log_info ("config %u added", cd->private_data);
+
+  return 1;
+}
+
+static void
+intel_dsa_config_del_fn (vlib_main_t *vm, vlib_dma_config_data_t *cd)
+{
+  intel_dsa_main_t *idm = &intel_dsa_main;
+  intel_dsa_thread_t *t =
+    vec_elt_at_index (idm->dsa_threads, vm->thread_index);
+  u32 n_pending, n_threads, config_heap_index, n = 0;
+  n_threads = vlib_get_n_threads ();
+
+  if (!t->pending_batches)
+    goto free_heap;
+
+  n_pending = vec_len (t->pending_batches);
+  intel_dsa_batch_t *b;
+
+  /* clean pending list and free list */
+  for (u32 i = 0; i < n_pending; i++)
+    {
+      b = t->pending_batches[i];
+      if (b->config_index == cd->config_index)
+      {
+	vec_add1 (idm->dsa_config_heap[b->config_heap_index].freelist, b);
+	if (b->status == INTEL_DSA_STATUS_SUCCESS ||
+	    b->status == INTEL_DSA_STATUS_BUSY)
+          b->ch->n_enq --;
+      } else
+        t->pending_batches[n++] = b;
+    }
+
+  vec_set_len (t->pending_batches, n);
+
+free_heap:
+  for (u32 thread = 0; thread < n_threads; thread++)
+  {
+    config_heap_index = cd->private_data + thread;
+    while (vec_len (idm->dsa_config_heap[config_heap_index].freelist) > 0)
+    {
+      b = vec_pop (idm->dsa_config_heap[config_heap_index].freelist);
+      vlib_physmem_free (vm, b);
+    }
+  }
+
+  heap_dealloc (
+    idm->dsa_config_heap,
+    idm->dsa_config_heap_handle_by_config_index[cd->config_index]);
+
+  dsa_log_debug ("config %u removed", cd->private_data);
+}
+
+static uword
+intel_dsa_node_fn (vlib_main_t *vm, vlib_node_runtime_t *node,
+		     vlib_frame_t *frame)
+{
+  intel_dsa_main_t *idm = &intel_dsa_main;
+  intel_dsa_thread_t *t =
+    vec_elt_at_index (idm->dsa_threads, vm->thread_index);
+  u32 n_pending = 0, n = 0;
+  u8 glitch = 0;
+
+  if (!t->pending_batches)
+    return 0;
+
+  n_pending = vec_len (t->pending_batches);
+
+  for (u32 i = 0; i < n_pending; i++)
+    {
+      intel_dsa_batch_t *b = t->pending_batches[i];
+      intel_dsa_channel_t *ch = b->ch;
+
+      if ((b->status == INTEL_DSA_STATUS_SUCCESS ||
+           b->status == INTEL_DSA_STATUS_CPU_SUCCESS) && !glitch)
+	{
+          struct vlib_dma_batch args[1] = { (struct vlib_dma_batch) b->batch };
+	  /* callback */
+	  if (b->batch.callback_fn)
+	    b->batch.callback_fn (vm, args);
+
+	  /* restore last descriptor fields */
+	  if (b->batch.n_enq == 1)
+	    {
+	      b->descs[0].completion = 0;
+	      b->descs[0].op_flags = (INTEL_DSA_OP_MEMMOVE << INTEL_DSA_OP_SHIFT) |
+				INTEL_DSA_FLAG_CACHE_CONTROL;
+	      if (b->ch->block_on_fault)
+	        b->descs[0].op_flags |= INTEL_DSA_FLAG_BLOCK_ON_FAULT;
+	    }
+	  /* add to freelist */
+	  vec_add1 (idm->dsa_config_heap[b->config_heap_index].freelist, b);
+
+	  intel_dsa_channel_lock (ch);
+	  if (b->status == INTEL_DSA_STATUS_SUCCESS)
+	  {
+	    ch->n_enq --;
+	    ch->completed ++;
+	  } else
+	    ch->sw_fallback ++;
+	  intel_dsa_channel_unlock (ch);
+
+	  b->batch.n_enq = 0;
+	  b->status = INTEL_DSA_STATUS_IDLE;
+	} else if (b->status == INTEL_DSA_STATUS_BUSY) {
+	  glitch = 1 & b->barrier_before_last;
+	  t->pending_batches[n++] = b;
+	} else if (!glitch) {
+	    /* fallback to software if exception happened */
+            intel_dsa_batch_fallback (vm, b, ch);
+	    glitch = 1 & b->barrier_before_last;
+	} else {
+	    t->pending_batches[n++] = b;
+	}
+    }
+  vec_set_len (t->pending_batches, n);
+
+  if (n)
+  {
+    vlib_node_set_interrupt_pending (vm, intel_dsa_node.index);
+  }
+
+  return n_pending - n;
+}
+
+u8 *
+format_dsa_info (u8 * s, va_list * args)
+{
+  intel_dsa_main_t *idm = &intel_dsa_main;
+  vlib_main_t *vm = va_arg (*args, vlib_main_t *);
+  intel_dsa_channel_t *ch;
+  ch = idm->dsa_threads[vm->thread_index].ch;
+  s = format(s, "thread %d dma %u/%u@%d request %-16lld hw %-16lld cpu %-16lld",
+		 vm->thread_index, ch->did, ch->qid, ch->bus, ch->submitted, ch->completed,
+		 ch->sw_fallback);
+  return s;
+}
+
+VLIB_REGISTER_NODE (intel_dsa_node) = {
+  .function = intel_dsa_node_fn,
+  .name = "intel-dsa",
+  .type = VLIB_NODE_TYPE_INPUT,
+  .state = VLIB_NODE_STATE_INTERRUPT,
+  .vector_size = 4,
+};
+
+vlib_dma_backend_t intel_dsa_backend = {
+  .name = "Intel DSA",
+  .config_add_fn = intel_dsa_config_add_fn,
+  .config_del_fn = intel_dsa_config_del_fn,
+  .info_fn = format_dsa_info,
+};
diff --git a/src/plugins/dsa_intel/dsa_intel.h b/src/plugins/dsa_intel/dsa_intel.h
new file mode 100644
index 000000000..3545d955a
--- /dev/null
+++ b/src/plugins/dsa_intel/dsa_intel.h
@@ -0,0 +1,171 @@
+/* SPDX-License-Identifier: Apache-2.0
+ * Copyright (c) 2022 Intel and/or its affiliates.
+ */
+
+#ifndef __dsa_intel_dma_intel_h__
+#define __dsa_intel_dma_intel_h__
+
+#include <vlib/vlib.h>
+#include <vlib/dma/dma.h>
+#include <vlib/pci/pci.h>
+#include <vppinfra/format.h>
+#include <dsa_intel/dsa_pci.h>
+
+typedef struct
+{
+  u32 pasid;
+  u32 op_flags;
+  u64 completion;
+  union
+  {
+    void *src;
+    void *desc_addr;
+  };
+  void *dst;
+  u32 size;
+  u16 intr_handle;
+  /* remaining 26 bytes are reserved */
+  u16 __reserved[13];
+} intel_dsa_desc_t;
+
+STATIC_ASSERT_SIZEOF (intel_dsa_desc_t, 64);
+
+
+#define DSA_DEV_PATH "/dev/dsa"
+#define SYS_DSA_PATH "/sys/bus/dsa/devices"
+
+typedef enum
+{
+  INTEL_DSA_DEVICE_TYPE_UNKNOWN,
+  INTEL_DSA_DEVICE_TYPE_KERNEL,
+  INTEL_DSA_DEVICE_TYPE_USER,
+  INTEL_DSA_DEVICE_TYPE_MDEV,
+} intel_dsa_wq_type_t;
+
+enum dsa_ops
+{
+  INTEL_DSA_OP_NOP = 0,
+  INTEL_DSA_OP_BATCH,
+  INTEL_DSA_OP_DRAIN,
+  INTEL_DSA_OP_MEMMOVE,
+  INTEL_DSA_OP_FILL
+};
+#define INTEL_DSA_OP_SHIFT 24
+#define INTEL_DSA_FLAG_FENCE			(1 << 0)
+#define INTEL_DSA_FLAG_BLOCK_ON_FAULT		(1 << 1)
+#define INTEL_DSA_FLAG_COMPLETION_ADDR_VALID 	(1 << 2)
+#define INTEL_DSA_FLAG_REQUEST_COMPLETION	(1 << 3)
+#define INTEL_DSA_FLAG_CACHE_CONTROL		(1 << 8)
+
+typedef struct
+{
+  CLIB_CACHE_LINE_ALIGN_MARK (cacheline0);
+  volatile void *portal; /* portal exposed by dedicated work queue */
+  u64 submitted;
+  u64 completed;
+  u64 sw_fallback;
+  void *pci_common;
+  vlib_pci_dev_handle_t pci_handle;
+  u32 max_transfer_size; /* maximum size of each transfer */
+  u16 max_transfers; /* maximum number referenced in a batch */
+  u16 n_threads; /* number of threads using this channel */
+  u16 n_enq;	 /* number of batches currently enqueued */
+  union {
+    u16 wq_control;
+    struct
+    {
+      u16 type: 2;
+      u16 state : 1;
+      u16 ats_disable : 1;
+      u16 block_on_fault : 1;
+      u16 mode : 1;
+    };
+  };
+  u8 lock;	 /* spinlock, only used if m_threads > 1 */
+  u8 numa;	 /* numa node */
+  u8 size;	 /* size of work queue */
+  u8 did;	 /* dsa device id */
+  u8 qid;        /* work queue id */
+  u8 bus;	 /* pci function id */
+} intel_dsa_channel_t;
+
+STATIC_ASSERT_SIZEOF (intel_dsa_channel_t, 64);
+
+typedef struct intel_dsa_batch
+{
+  CLIB_CACHE_LINE_ALIGN_MARK (start);
+  vlib_dma_batch_t batch; /* must be first */
+  intel_dsa_channel_t *ch;
+  u32 config_heap_index;
+  u32 max_transfers;
+  u32 config_index;
+  union
+  {
+    struct
+    {
+      u32 barrier_before_last : 1;
+      u32 sw_fallback : 1;
+    };
+    u32 features;
+  };
+  CLIB_CACHE_LINE_ALIGN_MARK (completion_cl);
+#define INTEL_DSA_STATUS_IDLE 0x0
+#define INTEL_DSA_STATUS_SUCCESS 0x1
+#define INTEL_DSA_STATUS_BUSY 0xa
+#define INTEL_DSA_STATUS_CPU_SUCCESS 0xb
+  u8 status;
+  /* to avoid read-modify-write completion is written as 64-byte
+   * DMA FILL operation */
+  CLIB_CACHE_LINE_ALIGN_MARK (descriptors);
+  intel_dsa_desc_t descs[0];
+} intel_dsa_batch_t;
+
+STATIC_ASSERT_OFFSET_OF (intel_dsa_batch_t, batch, 0);
+
+typedef struct
+{
+  CLIB_CACHE_LINE_ALIGN_MARK (cacheline0);
+  intel_dsa_batch_t batch_template;
+  u32 alloc_size;
+  u32 max_transfers;
+  intel_dsa_batch_t **freelist;
+} intel_dsa_config_t;
+
+typedef struct
+{
+  CLIB_CACHE_LINE_ALIGN_MARK (cacheline0);
+  intel_dsa_channel_t *ch; /* channel used by this thread */
+  intel_dsa_batch_t **pending_batches;
+} intel_dsa_thread_t;
+
+typedef struct
+{
+  intel_dsa_channel_t ***channels;
+  intel_dsa_thread_t *dsa_threads;
+  intel_dsa_config_t *dsa_config_heap;
+  uword *dsa_config_heap_handle_by_config_index;
+  /* spin lock protect pmem */
+  clib_spinlock_t lock;
+} intel_dsa_main_t;
+
+extern intel_dsa_main_t intel_dsa_main;
+extern vlib_dma_backend_t intel_dsa_backend;
+format_function_t format_intel_dsa_addr;
+
+clib_error_t *
+dsa_pci_add_channel (vlib_main_t *vm, intel_dsa_channel_t *ch);
+
+#define dsa_log_debug(f, ...)                                                     \
+  vlib_log (VLIB_LOG_LEVEL_DEBUG, intel_dsa_log.class, "%s: " f, __func__,    \
+	    ##__VA_ARGS__)
+
+#define dsa_log_info(f, ...)                                                     \
+  vlib_log (VLIB_LOG_LEVEL_INFO, intel_dsa_log.class, "%s: " f, __func__,    \
+	    ##__VA_ARGS__)
+
+#define dsa_log_error(f, ...)                                                     \
+  vlib_log (VLIB_LOG_LEVEL_ERR, intel_dsa_log.class, "%s: " f, __func__,    \
+	    ##__VA_ARGS__)
+
+
+#endif
diff --git a/src/plugins/dsa_intel/dsa_pci.c b/src/plugins/dsa_intel/dsa_pci.c
new file mode 100644
index 000000000..478a9fb0c
--- /dev/null
+++ b/src/plugins/dsa_intel/dsa_pci.c
@@ -0,0 +1,211 @@
+/* SPDX-License-Identifier: Apache-2.0
+ * Copyright (c) 2022 Intel and/or its affiliates.
+ */
+#include <vlib/vlib.h>
+#include <vlib/pci/pci.h>
+#include <dsa_intel/dsa_intel.h>
+
+
+#define PCI_VENDOR_ID_INTEL	0x8086
+#define PCI_DEVICE_ID_DSA_SPR	0x0B25
+
+static pci_device_id_t dsa_pci_device_ids[] = {
+  {.vendor_id = PCI_VENDOR_ID_INTEL, .device_id = PCI_DEVICE_ID_DSA_SPR},
+  {0},
+};
+
+static inline int
+dsa_pci_command(struct dsa_pci_common *pci, uint8_t wq_idx, enum dsa_pci_cmds command)
+{
+	uint32_t err_code;
+	uint16_t qid = wq_idx;
+	int i = 0;
+
+	if (command >= dsa_disable_wq && command <= dsa_reset_wq)
+		qid = (1 << qid);
+	clib_spinlock_lock (&pci->lock);
+	pci->regs->cmd = (command << DSA_CMD_SHIFT) | qid;
+
+	do {
+		CLIB_PAUSE();
+		err_code = pci->regs->cmdstatus;
+		if (++i >= 1000) {
+			printf("Timeout waiting for command response from HW");
+			clib_spinlock_unlock(&pci->lock);
+			err_code &= CMDSTATUS_ERR_MASK;
+			return -err_code;
+		}
+	} while (err_code & CMDSTATUS_ACTIVE_MASK);
+	clib_spinlock_unlock(&pci->lock);
+
+	err_code &= CMDSTATUS_ERR_MASK;
+	return -err_code;
+}
+
+static uint32_t *
+dsa_get_wq_cfg(struct dsa_pci_common *pci, uint8_t wq_idx)
+{
+	return (uint32_t *)((uintptr_t)pci->wq_regs_base + ((uintptr_t)wq_idx << (5 + pci->wq_cfg_sz)));
+}
+
+static int
+dsa_is_wq_enabled(struct dsa_pci_common *pci, uint8_t wq_idx)
+{
+	uint32_t state = dsa_get_wq_cfg(pci, wq_idx)[wq_state_idx];
+	return ((state >> WQ_STATE_SHIFT) & WQ_STATE_MASK) == 0x1;
+}
+
+static int
+dsa_pci_wq_start(struct dsa_pci_common *pci, uint8_t wq_idx)
+{
+  uint32_t err_code;
+
+  if (dsa_is_wq_enabled(pci, wq_idx))
+    {
+      printf("WQ %d already enabled\n", wq_idx);
+      return 0;
+    }
+
+  err_code = dsa_pci_command(pci, wq_idx, dsa_enable_wq);
+  if (err_code || !dsa_is_wq_enabled(pci, wq_idx))
+    {
+      printf("failed enabling work queue %d, error code: %#x\n", wq_idx, err_code);
+      return err_code == 0 ? -1 : -err_code;
+    }
+  printf("Work queue %d enabled OK\n", wq_idx);
+  return 0;
+}
+
+clib_error_t *
+dsa_pci_add_channel (vlib_main_t *vm, intel_dsa_channel_t *ch)
+{
+  clib_error_t *error = 0;
+  vlib_pci_addr_t addr;
+  addr.domain = 0;
+  addr.bus = ch->bus;
+  addr.slot = 0x1;
+  addr.function = 0;
+  struct dsa_pci_common *pci_common;
+  uint8_t nb_groups, nb_engines, nb_wqs;
+  uint16_t grp_offset, wq_offset; /* how far into bar0 the regs are */
+  uint16_t wq_size, total_wq_size;
+  uint8_t lg2_max_batch, lg2_max_copy_size;
+  int i;
+  intel_dsa_main_t *dm = &intel_dsa_main;
+  vlib_pci_device_info_t *di;
+
+  ch->pci_common = clib_mem_alloc_aligned(sizeof(struct dsa_pci_common), CLIB_CACHE_LINE_BYTES);
+  if (!ch->pci_common)
+    {
+    	clib_error_return (error, "failed to alloc pci region");
+	return error;
+    }
+  if ((error = vlib_pci_device_open (vm, &addr, dsa_pci_device_ids, &ch->pci_handle)))
+    {
+	clib_error_return (error, "pci-addr %U", format_vlib_pci_addr,
+			   &addr);
+      return error;
+    }
+
+  di = vlib_pci_get_device_info (vm, &addr, &error);
+  ch->numa = di->numa_node;
+  vlib_pci_free_device_info (di);
+
+  if ((error = vlib_pci_bus_master_enable (vm, ch->pci_handle)))
+    return error;
+
+  pci_common = (struct dsa_pci_common *)ch->pci_common;
+  clib_spinlock_init (&pci_common->lock);
+
+  if ((error = vlib_pci_map_region (vm, ch->pci_handle, 0, (void **)&pci_common->regs)))
+    return error;
+
+  if ((error = vlib_pci_map_region (vm, ch->pci_handle, 2, (void **)&ch->portal)))
+    return error;
+
+  grp_offset = (uint16_t)pci_common->regs->offsets[0];
+  pci_common->grp_regs = (void *)((uintptr_t)pci_common->regs + grp_offset * 0x100);
+  wq_offset = (uint16_t)(pci_common->regs->offsets[0] >> 16);
+  pci_common->wq_regs_base = (u32 *)((uintptr_t)pci_common->regs + wq_offset * 0x100);
+  pci_common->wq_cfg_sz = (pci_common->regs->wqcap >> 24) & 0x0F;
+  
+	/* sanity check device status */
+  if (pci_common->regs->gensts & GENSTS_DEV_STATE_MASK)
+    {
+      /* need function-level-reset (FLR) or is enabled */
+      clib_error_return (error, "Device status is not disabled, cannot init");
+      return error;
+    }
+  if (pci_common->regs->cmdstatus & CMDSTATUS_ACTIVE_MASK)
+    {
+      /* command in progress */
+      clib_error_return (error,"Device has a command in progress, cannot init");
+      return error;
+    }
+
+  /* read basic info about the hardware for use when configuring */
+  nb_groups = (uint8_t)pci_common->regs->grpcap;
+  nb_engines = (uint8_t)pci_common->regs->engcap;
+  nb_wqs = (uint8_t)(pci_common->regs->wqcap >> 16);
+  total_wq_size = (uint16_t)pci_common->regs->wqcap;
+  lg2_max_copy_size = (uint8_t)(pci_common->regs->gencap >> 16) & 0x1F;
+  lg2_max_batch = (uint8_t)(pci_common->regs->gencap >> 21) & 0x0F;
+  printf("nb_groups = %u, nb_engines = %u, nb_wqs = %u\n",
+			nb_groups, nb_engines, nb_wqs);
+  ch->max_transfers = (u16) 1 << lg2_max_batch;
+  ch->max_transfer_size = (u32) 1 << lg2_max_copy_size;
+  ch->block_on_fault = 0;
+  nb_wqs = 1;
+  nb_groups = 1;
+  /* zero out any old config */
+  for (i = 0; i < nb_groups; i++)
+    {
+      pci_common->grp_regs[i].grpengcfg = 0;
+      pci_common->grp_regs[i].grpwqcfg[0] = 0;
+    }
+  for (i = 0; i < nb_wqs; i++)
+    dsa_get_wq_cfg(pci_common, i)[0] = 0;
+
+  /* put each engine into a separate group to avoid reordering */
+  if (nb_groups > nb_engines)
+    nb_groups = nb_engines;
+//   if (nb_groups < nb_engines)
+//     nb_engines = nb_groups;
+  /* assign engines to groups, round-robin style */
+  for (i = 0; i < nb_engines; i++)
+    {
+      printf("Assigning engine %u to group %u\n", i, i % nb_groups);
+	pci_common->grp_regs[i % nb_groups].grpengcfg |= (1ULL << i);
+    }
+  wq_size = total_wq_size / nb_wqs;
+  printf("Work queue size = %u, max batch = 2^%u, max copy = 2^%u\n",
+			wq_size, lg2_max_batch, lg2_max_copy_size);
+  vec_validate (dm->channels, ch->numa);
+  intel_dsa_channel_t *wq_ch;
+
+  for (i = 0; i < nb_wqs; i++)
+    {
+      /* add engine "i" to a group */
+      printf("Assigning work queue %u to group %u\n", i, i % nb_groups);
+      pci_common->grp_regs[i % nb_groups].grpwqcfg[0] |= (1ULL << i);
+      /* now configure it, in terms of size, max batch, mode */
+      dsa_get_wq_cfg(pci_common, i)[wq_size_idx] = wq_size;
+      dsa_get_wq_cfg(pci_common, i)[wq_mode_idx] = (1 << WQ_PRIORITY_SHIFT) |
+				WQ_MODE_DEDICATED;
+      dsa_get_wq_cfg(pci_common, i)[wq_sizes_idx] = lg2_max_copy_size |
+				(lg2_max_batch << WQ_BATCH_SZ_SHIFT);
+    }
+
+  dsa_pci_command(pci_common, 0, dsa_enable_dev);
+  for (i = 0; i < nb_wqs; i++)
+    {
+      wq_ch = clib_mem_alloc_aligned (sizeof (intel_dsa_channel_t), CLIB_CACHE_LINE_BYTES);
+      clib_memcpy_fast ((void *) wq_ch, (void *) ch, sizeof (intel_dsa_channel_t));
+      wq_ch->portal = ch->portal + i * IDXD_PORTAL_SIZE;
+      vec_add1 (dm->channels[ch->numa], wq_ch);
+      wq_ch->size = wq_size;
+      dsa_pci_wq_start(pci_common, i);
+    }
+
+  return NULL;
+}
diff --git a/src/plugins/dsa_intel/dsa_pci.h b/src/plugins/dsa_intel/dsa_pci.h
new file mode 100644
index 000000000..96d0df97b
--- /dev/null
+++ b/src/plugins/dsa_intel/dsa_pci.h
@@ -0,0 +1,86 @@
+/* SPDX-License-Identifier: Apache-2.0
+ * Copyright (c) 2022 Intel and/or its affiliates.
+ */
+
+#ifndef __dsa_pci_h__
+#define __dsa_pci_h__
+
+#include <vlib/vlib.h>
+#include <vlib/dma/dma.h>
+#include <vlib/pci/pci.h>
+#include <vppinfra/format.h>
+#include <vppinfra/clib.h>
+#include <vppinfra/cache.h>
+#include <vppinfra/lock.h>
+
+#define DSA_CMD_SHIFT 20
+enum dsa_pci_cmds {
+	dsa_enable_dev = 1,
+	dsa_disable_dev,
+	dsa_drain_all,
+	dsa_abort_all,
+	dsa_reset_device,
+	dsa_enable_wq,
+	dsa_disable_wq,
+	dsa_drain_wq,
+	dsa_abort_wq,
+	dsa_reset_wq,
+};
+
+struct dsa_bar0 {
+	uint32_t __clib_aligned(CLIB_CACHE_LINE_BYTES) version;    /* offset 0x00 */
+	uint64_t __clib_aligned(0x10) gencap;     /* offset 0x10 */
+	uint64_t __clib_aligned(0x10) wqcap;      /* offset 0x20 */
+	uint64_t __clib_aligned(0x10) grpcap;     /* offset 0x30 */
+	uint64_t __clib_aligned(0x08) engcap;     /* offset 0x38 */
+	uint64_t __clib_aligned(0x10) opcap;      /* offset 0x40 */
+	uint64_t __clib_aligned(0x20) offsets[2]; /* offset 0x60 */
+	uint32_t __clib_aligned(0x20) gencfg;     /* offset 0x80 */
+	uint32_t __clib_aligned(0x08) genctrl;    /* offset 0x88 */
+	uint32_t __clib_aligned(0x10) gensts;     /* offset 0x90 */
+	uint32_t __clib_aligned(0x08) intcause;   /* offset 0x98 */
+	uint32_t __clib_aligned(0x10) cmd;        /* offset 0xA0 */
+	uint32_t __clib_aligned(0x08) cmdstatus;  /* offset 0xA8 */
+	uint64_t __clib_aligned(0x20) swerror[4]; /* offset 0xC0 */
+};
+
+struct dsa_grpcfg {
+	uint64_t __clib_aligned(CLIB_CACHE_LINE_BYTES) grpwqcfg[4]; /* 64-byte register set */
+	uint64_t grpengcfg;  /* offset 32 */
+	uint32_t grpflags;   /* offset 40 */
+};
+
+struct dsa_pci_common {
+	volatile struct dsa_bar0 *regs;
+	volatile uint32_t *wq_regs_base;
+	volatile struct dsa_grpcfg *grp_regs;
+	clib_spinlock_t lock;
+	uint8_t wq_cfg_sz;
+};
+
+#define GENSTS_DEV_STATE_MASK 0x03
+#define CMDSTATUS_ACTIVE_SHIFT 31
+#define CMDSTATUS_ACTIVE_MASK (1 << 31)
+#define CMDSTATUS_ERR_MASK 0xFF
+
+/* workqueue config is provided by array of uint32_t. */
+enum dsa_wqcfg {
+	wq_size_idx,       /* size is in first 32-bit value */
+	wq_threshold_idx,  /* WQ threshold second 32-bits */
+	wq_mode_idx,       /* WQ mode and other flags */
+	wq_sizes_idx,      /* WQ transfer and batch sizes */
+	wq_occ_int_idx,    /* WQ occupancy interrupt handle */
+	wq_occ_limit_idx,  /* WQ occupancy limit */
+	wq_state_idx,      /* WQ state and occupancy state */
+};
+
+#define WQ_MODE_SHARED    0
+#define WQ_MODE_DEDICATED 1
+#define WQ_BLOCK_ON_FAULT 2
+#define WQ_PRIORITY_SHIFT 4
+#define WQ_BATCH_SZ_SHIFT 5
+#define WQ_STATE_SHIFT 30
+#define WQ_STATE_MASK 0x3
+
+#define IDXD_PORTAL_SIZE 4096 * 4
+#endif
\ No newline at end of file
diff --git a/src/plugins/dsa_intel/format.c b/src/plugins/dsa_intel/format.c
new file mode 100644
index 000000000..3c285f90c
--- /dev/null
+++ b/src/plugins/dsa_intel/format.c
@@ -0,0 +1,15 @@
+/* SPDX-License-Identifier: Apache-2.0
+ * Copyright (c) 2022 Intel and/or its affiliates.
+ */
+#include <vlib/vlib.h>
+#include <vlib/pci/pci.h>
+#include <vlib/dma/dma.h>
+#include <vnet/plugin/plugin.h>
+#include <dsa_intel/dsa_intel.h>
+
+u8 *
+format_intel_dsa_addr (u8 *s, va_list *va)
+{
+  intel_dsa_channel_t *ch = va_arg (*va, intel_dsa_channel_t *);
+  return format (s, "wq%d.%d", ch->did, ch->qid);
+}
diff --git a/src/plugins/dsa_intel/main.c b/src/plugins/dsa_intel/main.c
new file mode 100644
index 000000000..d6ea8964a
--- /dev/null
+++ b/src/plugins/dsa_intel/main.c
@@ -0,0 +1,284 @@
+/* SPDX-License-Identifier: Apache-2.0
+ * Copyright (c) 2022 Cisco Systems, Inc.
+ * Copyright (c) 2022 Intel and/or its affiliates.
+ */
+#include <sys/types.h>
+#include <sys/stat.h>
+#include <fcntl.h>
+#include <vlib/vlib.h>
+#include <vlib/pci/pci.h>
+#include <vlib/dma/dma.h>
+#include <vnet/plugin/plugin.h>
+#include <vpp/app/version.h>
+#include <vppinfra/linux/sysfs.h>
+#include <dsa_intel/dsa_intel.h>
+
+VLIB_REGISTER_LOG_CLASS (intel_dsa_log, static) = {
+  .class_name = "intel_dsa",
+};
+
+intel_dsa_main_t intel_dsa_main;
+
+void
+intel_dsa_assign_channels (vlib_main_t *vm)
+{
+  intel_dsa_main_t *idm = &intel_dsa_main;
+  intel_dsa_channel_t *ch, **chv = 0;
+  u16 n_threads;
+  int n;
+
+  vec_foreach_index (n, idm->channels)
+    vec_append (chv, idm->channels[n]);
+
+  vec_validate (idm->dsa_threads, vlib_get_n_threads () - 1);
+
+  if (vec_len (chv) == 0)
+    {
+      dsa_log_debug ("No DSA channels found");
+      goto done;
+    }
+
+  if (vec_len (chv) >= vlib_get_n_threads ())
+    n_threads = 1;
+  else
+    n_threads = vlib_get_n_threads () % vec_len (chv) ?
+    			vlib_get_n_threads () / vec_len (chv) + 1 :
+			vlib_get_n_threads () / vec_len (chv);
+
+  for (int i = 0; i < vlib_get_n_threads (); i++)
+    {
+      vlib_main_t *tvm = vlib_get_main_by_index (i);
+      ch = *vec_elt_at_index (chv, i / n_threads);
+      idm->dsa_threads[i].ch = ch;
+      ch->n_threads = n_threads;
+      dsa_log_debug ("Assigning channel %u/%u@%d to thread %u (numa %u)",
+		 ch->did, ch->qid, ch->bus, i, tvm->numa_node);
+    }
+
+done:
+  /* free */
+  vec_free (chv);
+}
+
+static clib_error_t *
+intel_dsa_map_region (intel_dsa_channel_t *ch)
+{
+  static clib_error_t *error = NULL;
+  // one page
+  uword size = 0x1000;
+  uword offset = 0;
+  char path[256] = { 0 };
+
+  snprintf (path, sizeof (path), "%s/wq%d.%d", DSA_DEV_PATH, ch->did, ch->qid);
+  int fd = open (path, O_RDWR);
+  if (fd < 0)
+    return clib_error_return (0, "failed to open dsa device %s", path);
+
+  ch->portal =
+    clib_mem_vm_map_shared (0, size, fd, offset, "%s", (char *) path);
+  if (ch->portal == CLIB_MEM_VM_MAP_FAILED)
+    {
+      error = clib_error_return (0, "mmap portal %s failed", path);
+      close (fd);
+      return error;
+    }
+
+  return NULL;
+}
+
+static clib_error_t *
+intel_dsa_get_info (intel_dsa_channel_t *ch, clib_error_t **error)
+{
+  clib_error_t *err;
+  u8 *tmpstr;
+  u8 *dev_dir_name = 0, *wq_dir_name = 0;
+
+  u8 *f = 0;
+  dev_dir_name =
+    format (0, "%s/dsa%d", SYS_DSA_PATH, ch->did);
+
+  vec_reset_length (f);
+  f = format (f, "%v/numa_node%c", dev_dir_name, 0);
+  err = clib_sysfs_read ((char *) f, "%s", &tmpstr);
+  if (err)
+    goto error;
+  ch->numa = atoi ((char *) tmpstr);
+
+  wq_dir_name =
+    format (0, "%s/%U", SYS_DSA_PATH, format_intel_dsa_addr, ch);
+
+  vec_reset_length (f);
+  f = format (f, "%v/max_transfer_size%c", wq_dir_name, 0);
+  err = clib_sysfs_read ((char *) f, "%s", &tmpstr);
+  if (err)
+    goto error;
+  ch->max_transfer_size = atoi ((char *) tmpstr);
+
+  vec_reset_length (f);
+  f = format (f, "%v/max_batch_size%c", wq_dir_name, 0);
+  err = clib_sysfs_read ((char *) f, "%s", &tmpstr);
+  if (err)
+    goto error;
+  ch->max_transfers = atoi ((char *) tmpstr);
+
+  vec_reset_length (f);
+  f = format (f, "%v/size%c", wq_dir_name, 0);
+  err = clib_sysfs_read ((char *) f, "%s", &tmpstr);
+  if (err)
+    goto error;
+  ch->size = atoi ((char *) tmpstr);
+
+  vec_reset_length (f);
+  f = format (f, "%v/type%c", wq_dir_name, 0);
+  err = clib_sysfs_read ((char *) f, "%s", &tmpstr);
+  if (err)
+    goto error;
+  if (tmpstr)
+    {
+      if (!clib_strcmp ((char *) tmpstr, "enabled"))
+	ch->type = INTEL_DSA_DEVICE_TYPE_UNKNOWN;
+      else if (!clib_strcmp ((char *) tmpstr, "user"))
+	ch->type = INTEL_DSA_DEVICE_TYPE_USER;
+      else if (!clib_strcmp ((char *) tmpstr, "mdev"))
+	ch->type = INTEL_DSA_DEVICE_TYPE_KERNEL;
+      else
+	ch->type = INTEL_DSA_DEVICE_TYPE_UNKNOWN;
+      vec_free (tmpstr);
+    }
+
+  vec_reset_length (f);
+  f = format (f, "%v/state%c", wq_dir_name, 0);
+  err = clib_sysfs_read ((char *) f, "%s", &tmpstr);
+  if (err)
+    goto error;
+  if (tmpstr)
+    {
+      if (!clib_strcmp ((char *) tmpstr, "enabled"))
+	ch->state = 1;
+      else
+	ch->state = 0;
+      vec_free (tmpstr);
+    }
+
+  vec_reset_length (f);
+  f = format (f, "%v/ats_disable%c", wq_dir_name, 0);
+  err = clib_sysfs_read ((char *) f, "%s", &tmpstr);
+  if (err)
+    goto error;
+  ch->ats_disable = atoi ((char *) tmpstr);
+
+  vec_reset_length (f);
+  f = format (f, "%v/block_on_fault%c", wq_dir_name, 0);
+  err = clib_sysfs_read ((char *) f, "%s", &tmpstr);
+  if (err)
+    goto error;
+  ch->block_on_fault = atoi ((char *) tmpstr);
+
+  vec_reset_length (f);
+  f = format (f, "%v/mode%c", wq_dir_name, 0);
+  err = clib_sysfs_read ((char *) f, "%s", &tmpstr);
+  if (err)
+    goto error;
+  if (tmpstr)
+    {
+      if (!clib_strcmp ((char *) tmpstr, "dedicated"))
+	ch->mode = 1;
+      else
+	ch->mode = 0;
+      vec_free (tmpstr);
+    }
+
+  vec_free (f);
+  vec_free (dev_dir_name);
+  vec_free (wq_dir_name);
+  return NULL;
+
+error:
+  vec_free (f);
+  vec_free (dev_dir_name);
+  vec_free (wq_dir_name);
+
+  return err;
+}
+
+clib_error_t *
+intel_dsa_add_channel (vlib_main_t *vm, intel_dsa_channel_t *ch)
+{
+  intel_dsa_main_t *dm = &intel_dsa_main;
+  clib_error_t *err = 0;
+
+  if (intel_dsa_map_region (ch))
+    return clib_error_return (0, "dsa open device failed");
+
+  if (intel_dsa_get_info (ch, &err))
+    return clib_error_return (err, "dsa info not scanned");
+
+  vec_validate (dm->channels, ch->numa);
+  vec_add1 (dm->channels[ch->numa], ch);
+
+  return err;
+}
+
+static clib_error_t *
+dsa_config (vlib_main_t *vm, unformat_input_t *input)
+{
+  clib_error_t *error = 0;
+  intel_dsa_channel_t *ch;
+  u32 did, qid;
+  vlib_pci_addr_t addr;
+
+  if (intel_dsa_main.lock == 0)
+     clib_spinlock_init (&(intel_dsa_main.lock));
+
+  if ((error = vlib_dma_register_backend (vm, &intel_dsa_backend)))
+    goto done;
+    
+  while (unformat_check_input (input) != UNFORMAT_END_OF_INPUT)
+    {
+      if (unformat (input, "dev wq%d.%d", &did, &qid))
+	{
+	  ch = clib_mem_alloc_aligned (sizeof (*ch), CLIB_CACHE_LINE_BYTES);
+	  clib_memset (ch, 0, sizeof (*ch));
+	  ch->did = did;
+	  ch->qid = qid;
+	  if (intel_dsa_add_channel (vm, ch))
+	    clib_mem_free (ch);
+	}
+      else if (unformat_skip_white_space (input))
+	;
+      else if (unformat (input, "dev %U", unformat_vlib_pci_addr, &addr))
+	{
+	  ch = clib_mem_alloc_aligned (sizeof (*ch), CLIB_CACHE_LINE_BYTES);
+	  clib_memset (ch, 0, sizeof (*ch));
+	  ch->bus = addr.bus;
+	  
+	  if (dsa_pci_add_channel (vm, ch))
+	    clib_mem_free (ch);
+	}
+      else
+	{
+	  error = clib_error_return (0, "unknown input `%U'",
+				     format_unformat_error, input);
+	  goto done;
+	}
+    }
+
+done:
+  return error;
+}
+
+VLIB_CONFIG_FUNCTION (dsa_config, "dsa");
+
+clib_error_t *
+intel_dsa_num_workers_change (vlib_main_t *vm)
+{
+  intel_dsa_assign_channels (vm);
+  return 0;
+}
+
+VLIB_NUM_WORKERS_CHANGE_FN (intel_dsa_num_workers_change);
+
+VLIB_PLUGIN_REGISTER () = {
+    .version = VPP_BUILD_VER,
+    .description = "Intel DSA Backend",
+};
diff --git a/src/plugins/memif/CMakeLists.txt b/src/plugins/memif/CMakeLists.txt
index b86d30adb..b916dc6dd 100644
--- a/src/plugins/memif/CMakeLists.txt
+++ b/src/plugins/memif/CMakeLists.txt
@@ -19,6 +19,7 @@ add_vpp_plugin(memif
   node.c
   device.c
   socket.c
+  node.c
 
   API_FILES
   memif.api
diff --git a/src/plugins/memif/cli.c b/src/plugins/memif/cli.c
index 19f624aa0..f90d0fe7b 100644
--- a/src/plugins/memif/cli.c
+++ b/src/plugins/memif/cli.c
@@ -209,6 +209,8 @@ memif_create_command_fn (vlib_main_t * vm, unformat_input_t * input,
 	args.is_master = 0;
       else if (unformat (line_input, "no-zero-copy"))
 	args.is_zero_copy = 0;
+      else if (unformat (line_input, "dma"))
+	args.use_dma = 1;
       else if (unformat (line_input, "mode ip"))
 	args.mode = MEMIF_INTERFACE_MODE_IP;
       else if (unformat (line_input, "hw-addr %U",
diff --git a/src/plugins/memif/device.c b/src/plugins/memif/device.c
index 94789223e..cf69b2f76 100644
--- a/src/plugins/memif/device.c
+++ b/src/plugins/memif/device.c
@@ -22,6 +22,7 @@
 #include <sys/uio.h>
 
 #include <vlib/vlib.h>
+#include <vlib/dma/dma.h>
 #include <vlib/unix/unix.h>
 #include <vnet/ethernet/ethernet.h>
 
@@ -96,6 +97,327 @@ memif_add_copy_op (memif_per_thread_data_t * ptd, void *data, u32 len,
   co->buffer_vec_index = buffer_vec_index;
 }
 
+CLIB_MARCH_FN (memif_tx_dma_completion_cb, void, vlib_main_t *vm,
+	      vlib_dma_batch_t *b)
+{
+  memif_main_t *mm = &memif_main;
+  memif_if_t *mif = vec_elt_at_index (mm->interfaces, b->cookie >> 16);
+  memif_queue_t *mq;
+  memif_dma_info_t *tx_dma_info;
+  u32 thread_index = vm->thread_index;
+  memif_per_thread_data_t *ptd =
+    vec_elt_at_index (mm->per_thread_data, thread_index);
+  tx_dma_info = ptd->tx_dma_info + ptd->tx_head;
+
+//   for (int i = 0; i < tx_dma_info->transfers; i++)
+//   {
+//     vlib_buffer_known_state_t k;
+//     k = vlib_buffer_is_known(vm, tx_dma_info->buffers[i]);
+// #ifdef MEMIF_DEBUG
+//     printf("dma transfer callback free buffer index %d state %d\n", tx_dma_info->buffers[i], k);
+// #endif
+//     if (k != VLIB_BUFFER_KNOWN_FREE)
+//       vlib_buffer_free (vm, &tx_dma_info->buffers[i], 1);
+//   }
+
+  vlib_buffer_free (vm, tx_dma_info->buffers, tx_dma_info->transfers);
+
+  mq = vec_elt_at_index (mif->tx_queues, b->cookie & 0xffff);
+  if (tx_dma_info->type == MEMIF_RING_S2M)
+  {
+#ifdef MEMIF_DEBUG
+   printf("memif_tx_dma_completion_cb slave to master update head from %d to %d\n", mq->ring->head, tx_dma_info->dma_head);
+#endif
+    __atomic_store_n (&mq->ring->head, tx_dma_info->dma_head, __ATOMIC_RELEASE);
+  } else {
+#ifdef MEMIF_DEBUG
+   printf("memif_tx_dma_completion_cb master to slave update tail from %d to %d at %d\n", mq->ring->tail, tx_dma_info->dma_tail, ptd->tx_head);
+#endif
+    __atomic_store_n (&mq->ring->tail, tx_dma_info->dma_tail, __ATOMIC_RELEASE);
+  }
+  ptd->tx_head++;
+  if (ptd->tx_head == ptd->size)
+    ptd->tx_head = 0;
+}
+
+#ifndef CLIB_MARCH_VARIANT
+void
+memif_tx_dma_completion_cb (vlib_main_t *vm, vlib_dma_batch_t *b)
+{
+  return CLIB_MARCH_FN_SELECT (memif_tx_dma_completion_cb) (vm, b);
+}
+#endif
+
+static_always_inline uword
+memif_interface_tx_inline_dma (vlib_main_t *vm, vlib_node_runtime_t *node,
+			       u32 *buffers, memif_if_t *mif,
+			       memif_ring_type_t type, memif_queue_t *mq,
+			       memif_per_thread_data_t *ptd, u32 n_left)
+{
+  memif_ring_t *ring;
+  u32 n_copy_op, left;
+  u16 ring_size, mask, slot, free_slots;
+  int n_retries = 5, fallback = 0;
+  vlib_buffer_t *b0, *b1, *b2, *b3;
+  u32 *ori_buffers;
+  memif_copy_op_t *co;
+  memif_region_index_t last_region = ~0;
+  void *last_region_shm = 0;
+  u16 head, tail;
+  memif_main_t *mm = &memif_main;
+  u16 mif_id = mif - mm->interfaces;
+
+  ring = mq->ring;
+  ring_size = 1 << mq->log2_ring_size;
+  mask = ring_size - 1;
+
+  if ((ptd->tx_tail + 1 == ptd->tx_head) || ((ptd->tx_head == ptd->size -1 ) && (ptd->tx_tail == 0)))
+  {
+//      printf("memif_interface_tx_inline_dma no free dma info slots tail %d head %d\n", ptd->tx_tail, ptd->tx_head);
+     fallback = 1;
+     left = n_left;
+     ori_buffers = buffers;
+//      return n_left;
+  }
+
+retry1:
+  if (type == MEMIF_RING_S2M)
+    {
+      slot = head = mq->dma_head;
+//       slot = tail = ring->head;
+      tail = __atomic_load_n (&ring->tail, __ATOMIC_ACQUIRE);
+#ifdef MEMIF_DEBUG
+   printf("memif_interface_tx_inline_dma slave to master tail from %d to %d\n", mq->last_tail, tail);
+#endif
+      mq->last_tail += tail - mq->last_tail;
+      free_slots = ring_size - head + mq->last_tail;
+#ifdef MEMIF_DEBUG
+   printf("memif_interface_tx_inline_dma slave to master free slots %d\n", free_slots);
+#endif
+    }
+  else
+    {
+      slot = tail = mq->dma_tail;
+//       slot = tail = ring->tail;
+      head = __atomic_load_n (&ring->head, __ATOMIC_ACQUIRE);
+#ifdef MEMIF_DEBUG
+   printf("memif_interface_tx_inline_dma master to slave got new head %d\n", head);
+#endif
+      mq->last_tail += tail - mq->last_tail;
+      free_slots = head - tail;
+#ifdef MEMIF_DEBUG
+   printf("memif_interface_tx_inline_dma master to slave free slots %d\n", free_slots);
+#endif
+    }
+
+  memif_dma_info_t *tx_dma_info;
+  tx_dma_info = ptd->tx_dma_info + ptd->tx_tail;
+  tx_dma_info->type = type;
+  tx_dma_info->transfers = 0;
+
+  /* break out if no free slots */
+  if (!free_slots)
+  {
+    if (n_retries)
+    {
+	n_retries--;
+	goto retry1;
+    } else
+      return n_left;
+  }
+
+  if (PREDICT_TRUE(!fallback))
+    clib_memcpy_fast (tx_dma_info->buffers, buffers, n_left * sizeof (buffers[0]));
+
+  vlib_dma_batch_t *b = NULL;
+  if (PREDICT_TRUE(!fallback))
+    b = vlib_dma_batch_new (vm, ptd->tx_dma_config);
+
+retry:
+
+  while (n_left && free_slots)
+    {
+      memif_desc_t *d0;
+      void *mb0;
+      i32 src_off;
+      u32 bi0, dst_off, src_left, dst_left, bytes_to_copy;
+      u32 saved_ptd_copy_ops_len = _vec_len (ptd->copy_ops);
+      u32 saved_ptd_buffers_len = _vec_len (ptd->buffers);
+      u16 saved_slot = slot;
+
+      clib_prefetch_load (&ring->desc[(slot + 8) & mask]);
+
+      d0 = &ring->desc[slot & mask];
+      if (PREDICT_FALSE (last_region != d0->region))
+	{
+	  last_region_shm = mif->regions[d0->region].shm;
+	  last_region = d0->region;
+	}
+      mb0 = last_region_shm + d0->offset;
+
+      dst_off = 0;
+
+      /* slave is the producer, so it should be able to reset buffer length */
+      dst_left = (type == MEMIF_RING_S2M) ? mif->run.buffer_size : d0->length;
+
+      if (PREDICT_TRUE (n_left >= 4))
+	vlib_prefetch_buffer_header (vlib_get_buffer (vm, buffers[3]), LOAD);
+      bi0 = buffers[0];
+
+    next_in_chain:
+
+      b0 = vlib_get_buffer (vm, bi0);
+      src_off = b0->current_data;
+      src_left = b0->current_length;
+
+      while (src_left)
+	{
+	  if (PREDICT_FALSE (dst_left == 0))
+	    {
+	      if (free_slots)
+		{
+		  slot++;
+		  free_slots--;
+		  d0->length = dst_off;
+		  d0->flags = MEMIF_DESC_FLAG_NEXT;
+		  d0 = &ring->desc[slot & mask];
+		  dst_off = 0;
+		  dst_left = (type == MEMIF_RING_S2M) ? mif->run.buffer_size :
+							d0->length;
+
+		  if (PREDICT_FALSE (last_region != d0->region))
+		    {
+		      last_region_shm = mif->regions[d0->region].shm;
+		      last_region = d0->region;
+		    }
+		  mb0 = last_region_shm + d0->offset;
+		}
+	      else
+		{
+		  /* we need to rollback vectors before bailing out */
+		  _vec_len (ptd->buffers) = saved_ptd_buffers_len;
+		  _vec_len (ptd->copy_ops) = saved_ptd_copy_ops_len;
+		  vlib_error_count (vm, node->node_index,
+				    MEMIF_TX_ERROR_ROLLBACK, 1);
+		  slot = saved_slot;
+		  goto no_free_slots;
+		}
+	    }
+	  bytes_to_copy = clib_min (src_left, dst_left);
+	  memif_add_copy_op (ptd, mb0 + dst_off, bytes_to_copy, src_off,
+			     vec_len (ptd->buffers));
+	  vec_add1_aligned (ptd->buffers, bi0, CLIB_CACHE_LINE_BYTES);
+	  src_off += bytes_to_copy;
+	  dst_off += bytes_to_copy;
+	  src_left -= bytes_to_copy;
+	  dst_left -= bytes_to_copy;
+	}
+
+      if (PREDICT_FALSE (b0->flags & VLIB_BUFFER_NEXT_PRESENT))
+	{
+	  bi0 = b0->next_buffer;
+	  goto next_in_chain;
+	}
+
+      d0->length = dst_off;
+      d0->flags = 0;
+
+      free_slots -= 1;
+      slot += 1;
+
+      buffers++;
+      n_left--;
+    }
+no_free_slots:
+
+  /* copy data */
+  n_copy_op = vec_len (ptd->copy_ops);
+  co = ptd->copy_ops;
+
+  while (n_copy_op >= 8)
+    {
+      b0 = vlib_get_buffer (vm, ptd->buffers[co[0].buffer_vec_index]);
+      b1 = vlib_get_buffer (vm, ptd->buffers[co[1].buffer_vec_index]);
+      b2 = vlib_get_buffer (vm, ptd->buffers[co[2].buffer_vec_index]);
+      b3 = vlib_get_buffer (vm, ptd->buffers[co[3].buffer_vec_index]);
+      if (PREDICT_TRUE(!fallback)) {
+      vlib_dma_batch_add (vm, b, co[0].data, b0->data + co[0].buffer_offset, co[0].data_len);
+      vlib_dma_batch_add (vm, b, co[1].data, b1->data + co[1].buffer_offset, co[1].data_len);
+      vlib_dma_batch_add (vm, b, co[2].data, b2->data + co[2].buffer_offset, co[2].data_len);
+      vlib_dma_batch_add (vm, b, co[3].data, b3->data + co[3].buffer_offset, co[3].data_len);
+            tx_dma_info->transfers += 4;
+      } else {
+        clib_memcpy_fast (co[0].data, b0->data + co[0].buffer_offset, co[0].data_len);
+        clib_memcpy_fast (co[1].data, b1->data + co[1].buffer_offset, co[1].data_len);
+        clib_memcpy_fast (co[2].data, b2->data + co[2].buffer_offset, co[2].data_len);
+        clib_memcpy_fast (co[3].data, b3->data + co[3].buffer_offset, co[3].data_len);
+      }
+      co += 4;
+      n_copy_op -= 4;
+    }
+  while (n_copy_op)
+    {
+      b0 = vlib_get_buffer (vm, ptd->buffers[co[0].buffer_vec_index]);
+      if (PREDICT_TRUE(!fallback))
+      {
+          vlib_dma_batch_add (vm, b, co[0].data, b0->data + co[0].buffer_offset, co[0].data_len);
+	  tx_dma_info->transfers += 1;
+      }
+      else
+	  clib_memcpy_fast (co[0].data, b0->data + co[0].buffer_offset, co[0].data_len);
+
+
+      co += 1;
+      n_copy_op -= 1;
+    }
+
+//   vlib_dma_transfer (vm, ptd->tx_dma_config, tx_dma_info->iov,
+// 		     tx_dma_info->transfers,
+// 		     (mif_id << 16) | (mq - mif->tx_queues));
+
+
+  vec_reset_length (ptd->copy_ops);
+  vec_reset_length (ptd->buffers);
+
+// #ifdef MEMIF_DEBUG
+//   for (int i = 0; i < tx_dma_info->transfers; i++)
+//   {
+//     vlib_buffer_known_state_t k;
+//     k = vlib_buffer_is_known(vm, tx_dma_info->buffers[i]);
+//     printf("dma transfer buffer index %d state %d\n", tx_dma_info->buffers[i], k);
+//   }
+// #endif
+
+  if (type == MEMIF_RING_S2M)
+  {
+    tx_dma_info->dma_head = slot;
+    mq->dma_head = slot;
+  } else
+  {
+    tx_dma_info->dma_tail = slot;
+    mq->dma_tail = slot;
+#ifdef MEMIF_DEBUG
+   printf("memif_interface_tx_inline_dma: record dma tail %d at %d\n", tx_dma_info->dma_tail, ptd->tx_tail);
+#endif
+  }
+
+  if (n_left && n_retries--)
+    goto retry;
+
+  if (PREDICT_TRUE(!fallback))
+  {
+    ptd->tx_tail++;
+    if (ptd->tx_tail == ptd->tx_size)
+      ptd->tx_tail = 0;
+    vlib_dma_batch_set_cookie (vm, b, (uword)(mif_id << 16) | (mq - mif->tx_queues));
+    vlib_dma_batch_submit (vm, b);
+  } else {
+    vlib_buffer_free (vm, ori_buffers, left - n_left);
+  }
+
+  return n_left;
+}
+
 static_always_inline uword
 memif_interface_tx_inline (vlib_main_t *vm, vlib_node_runtime_t *node,
 			   u32 *buffers, memif_if_t *mif,
@@ -396,11 +718,23 @@ VNET_DEVICE_CLASS_TX_FN (memif_device_class) (vlib_main_t * vm,
     n_left =
       memif_interface_tx_zc_inline (vm, node, from, mif, mq, ptd, n_left);
   else if (mif->flags & MEMIF_IF_FLAG_IS_SLAVE)
-    n_left = memif_interface_tx_inline (vm, node, from, mif, MEMIF_RING_S2M,
-					mq, ptd, n_left);
+    {
+      if (mif->flags & MEMIF_IF_FLAG_USE_DMA)
+	n_left = memif_interface_tx_inline_dma (
+	  vm, node, from, mif, MEMIF_RING_S2M, mq, ptd, n_left);
+      else
+	n_left = memif_interface_tx_inline (vm, node, from, mif,
+					    MEMIF_RING_S2M, mq, ptd, n_left);
+    }
   else
-    n_left = memif_interface_tx_inline (vm, node, from, mif, MEMIF_RING_M2S,
-					mq, ptd, n_left);
+    {
+      if (mif->flags & MEMIF_IF_FLAG_USE_DMA)
+	n_left = memif_interface_tx_inline_dma (
+	  vm, node, from, mif, MEMIF_RING_M2S, mq, ptd, n_left);
+      else
+	n_left = memif_interface_tx_inline (vm, node, from, mif,
+					    MEMIF_RING_M2S, mq, ptd, n_left);
+    }
 
   if (tf->shared_queue)
     clib_spinlock_unlock (&mq->lockp);
@@ -416,7 +750,11 @@ VNET_DEVICE_CLASS_TX_FN (memif_device_class) (vlib_main_t * vm,
       mq->int_count++;
     }
 
-  if ((mif->flags & MEMIF_IF_FLAG_ZERO_COPY) == 0)
+  if ((mif->flags & MEMIF_IF_FLAG_USE_DMA))
+  {
+    if (n_left)
+      vlib_buffer_free (vm, from + frame->n_vectors - n_left, n_left);
+  } else if ((mif->flags & MEMIF_IF_FLAG_ZERO_COPY) == 0)
     vlib_buffer_free (vm, from, frame->n_vectors);
   else if (n_left)
     vlib_buffer_free (vm, from + frame->n_vectors - n_left, n_left);
diff --git a/src/plugins/memif/memif.api b/src/plugins/memif/memif.api
index 9e32db5b4..91e72f73a 100644
--- a/src/plugins/memif/memif.api
+++ b/src/plugins/memif/memif.api
@@ -51,6 +51,40 @@ autoreply define memif_socket_filename_add_del
   option vat_help = "[add|del] id <id> filename <file>";
 };
 
+/** \brief Create or remove named socket file for memif interfaces
+    @param client_index - opaque cookie to identify the sender
+    @param context - sender context, to match reply w/ request
+    @param is_add - 0 = remove, 1 = add association
+    @param socket_id - non-0 32-bit integer used to identify a socket file
+          ~0 means autogenerate
+    @param socket_filename - filename of the socket to be used for connection
+           establishment; id 0 always maps to default "/var/vpp/memif.sock";
+	   no socket filename needed when is_add == 0.
+	   socket_filename starting with '@' will create an abstract socket
+	   in the given namespace
+*/
+define memif_socket_filename_add_del_v2
+{
+  u32 client_index;
+  u32 context;
+  bool is_add;		                /* 0 = remove, 1 = add association */
+  u32 socket_id [default=0xffffffff];	/* unique non-0 id for given socket file name */
+  string socket_filename[];             /* NUL terminated filename */
+  option vat_help = "[add|del] id <id> filename <file>";
+};
+
+/** \brief Create memory interface socket file response
+    @param context - sender context, to match reply w/ request
+    @param retval - return value for request
+    @param socket_id - non-0 32-bit integer used to identify a socket file
+*/
+define memif_socket_filename_add_del_v2_reply
+{
+  u32 context;
+  i32 retval;
+  u32 socket_id;
+};
+
 /** \brief Create memory interface
     @param client_index - opaque cookie to identify the sender
     @param context - sender context, to match reply w/ request
diff --git a/src/plugins/memif/memif.c b/src/plugins/memif/memif.c
index 5df8709b5..7723700b1 100644
--- a/src/plugins/memif/memif.c
+++ b/src/plugins/memif/memif.c
@@ -33,6 +33,9 @@
 
 #include <vlib/vlib.h>
 #include <vlib/unix/unix.h>
+#include <vlib/pci/pci.h>
+#include <vlib/linux/vfio.h>
+#include <vlib/dma/dma.h>
 #include <vnet/plugin/plugin.h>
 #include <vnet/ethernet/ethernet.h>
 #include <vnet/interface/rx_queue_funcs.h>
@@ -267,11 +270,14 @@ memif_connect (memif_if_t * mif)
 	}
 
       if ((mr->shm = mmap (NULL, mr->region_size, PROT_READ | PROT_WRITE,
-			   MAP_SHARED, mr->fd, 0)) == MAP_FAILED)
+			   MAP_SHARED | MAP_POPULATE, mr->fd, 0)) ==
+	  MAP_FAILED)
 	{
 	  err = clib_error_return_unix (0, "mmap");
 	  goto error;
 	}
+       if (mif->flags & MEMIF_IF_FLAG_USE_DMA)
+	    vfio_map_one_page (uword_to_pointer(mr->shm, u64), (u64) mr->region_size);
     }
   /* *INDENT-ON* */
 
@@ -456,6 +462,12 @@ memif_init_regions_and_queues (memif_if_t * mif)
 
   r->fd = fd;
 
+  if (mif->flags & MEMIF_IF_FLAG_USE_DMA)
+  {
+     printf("memif_init_regions_and_queues mapping\n");
+     vfio_map_one_page (uword_to_pointer(r->shm, u64), (u64) r->region_size);
+  }
+
   if (mif->flags & MEMIF_IF_FLAG_ZERO_COPY)
     {
       vlib_buffer_pool_t *bp;
@@ -741,6 +753,36 @@ memif_delete_socket_file (u32 sock_id)
   return 0;
 }
 
+/*
+ * Returns an unused socket id, and ~0 if it can't find one.
+ */
+u32
+memif_get_unused_socket_id ()
+{
+  memif_main_t *mm = &memif_main;
+  uword *p;
+  int i, j;
+
+  static u32 seed = 0;
+  /* limit to 1M tries */
+  for (j = 0; j < 1 << 10; j++)
+    {
+      seed = random_u32 (&seed);
+      for (i = 0; i < 1 << 10; i++)
+	{
+	  /* look around randomly generated id */
+	  seed += (2 * (i % 2) - 1) * i;
+	  if (seed == (u32) ~0)
+	    continue;
+	  p = hash_get (mm->socket_file_index_by_sock_id, seed);
+	  if (!p)
+	    return seed;
+	}
+    }
+
+  return ~0;
+}
+
 int
 memif_socket_filename_add_del (u8 is_add, u32 sock_id, u8 * sock_filename)
 {
@@ -763,7 +805,14 @@ memif_socket_filename_add_del (u8 is_add, u32 sock_id, u8 * sock_filename)
       return VNET_API_ERROR_INVALID_ARGUMENT;
     }
 
-  if (sock_filename[0] != '/')
+  if (clib_socket_name_is_abstract (sock_filename))
+    {
+      /* Abstract socket */
+      if (sock_filename[1] == 0)
+	return VNET_API_ERROR_INVALID_ARGUMENT;
+      sock_filename = format (0, "%s%c", sock_filename, 0);
+    }
+  else if (sock_filename[0] != '/')
     {
       clib_error_t *error;
 
@@ -899,6 +948,17 @@ VNET_HW_INTERFACE_CLASS (memif_ip_hw_if_class, static) = {
 };
 /* *INDENT-ON* */
 
+static void
+memif_prepare_dma_args (vlib_dma_config_t *args)
+{
+
+  args->max_transfers = 256;
+  args->max_transfer_size = 65535;
+  args->barrier_before_last = 1;
+  args->sw_fallback = 1;
+  args->callback_fn = NULL;
+}
+
 int
 memif_create_if (vlib_main_t * vm, memif_create_if_args_t * args)
 {
@@ -913,6 +973,9 @@ memif_create_if (vlib_main_t * vm, memif_create_if_args_t * args)
   uword *p;
   memif_socket_file_t *msf = 0;
   int rv = 0;
+  vlib_dma_config_t dma_args;
+  bzero (&dma_args, sizeof(dma_args));
+  memif_prepare_dma_args (&dma_args);
 
   p = hash_get (mm->socket_file_index_by_sock_id, args->socket_id);
   if (p == 0)
@@ -947,7 +1010,8 @@ memif_create_if (vlib_main_t * vm, memif_create_if_args_t * args)
 
       /* If we are creating listener make sure file doesn't exist or if it
        * exists thn delete it if it is old socket file */
-      if (args->is_master && (stat ((char *) msf->filename, &file_stat) == 0))
+      if (args->is_master && !clib_socket_name_is_abstract (msf->filename) &&
+	  (stat ((char *) msf->filename, &file_stat) == 0))
 	{
 	  if (S_ISSOCK (file_stat.st_mode))
 	    {
@@ -970,6 +1034,13 @@ memif_create_if (vlib_main_t * vm, memif_create_if_args_t * args)
       memif_log_debug (0, "initializing socket file %s", msf->filename);
     }
 
+  /* register dma config if enabled */
+  dma_args.callback_fn = memif_dma_completion_cb;
+  int dma_config = -1, tx_dma_config = -1;
+  dma_config = vlib_dma_config_add (vm, &dma_args);
+  dma_args.callback_fn = memif_tx_dma_completion_cb;
+  tx_dma_config= vlib_dma_config_add (vm, &dma_args);
+
   if (mm->per_thread_data == 0)
     {
       int i;
@@ -993,6 +1064,25 @@ memif_create_if (vlib_main_t * vm, memif_create_if_args_t * args)
 	  vec_reset_length (ptd->copy_ops);
 	  vec_validate_aligned (ptd->buffers, 0, CLIB_CACHE_LINE_BYTES);
 	  vec_reset_length (ptd->buffers);
+	  /* dma structure */
+	  ptd->dma_config = dma_config;
+	  ptd->tx_dma_config = tx_dma_config;
+	  printf("ptd %p ptd->dma_config is %d ptd->tx_dma_config is %d at thread %d\n",ptd, ptd->dma_config, ptd->tx_dma_config, i);
+	  vec_validate_aligned (ptd->dma_info, 1024, CLIB_CACHE_LINE_BYTES);
+	  vec_validate_aligned (ptd->tx_dma_info, 1024, CLIB_CACHE_LINE_BYTES);
+	//   for (int j = 0; j < 1024; j++)
+	//     {
+	//       memif_dma_info_t *dma_info = ptd->dma_info + j;
+	// //       vec_validate_aligned (dma_info->buffers, 0,
+	// // 			    CLIB_CACHE_LINE_BYTES);
+	// //       vec_set_len (dma_info->buffers, 0);
+	//     }
+	  ptd->head = 0;
+	  ptd->tail = 0;
+	  ptd->size = 1024;
+	  ptd->tx_head = 0;
+	  ptd->tx_tail = 0;
+	  ptd->tx_size = 1024;
 	}
     }
 
@@ -1078,7 +1168,8 @@ memif_create_if (vlib_main_t * vm, memif_create_if_args_t * args)
 	  goto error;
 	}
 
-      if (stat ((char *) msf->filename, &file_stat) == -1)
+      if (!clib_socket_name_is_abstract (msf->filename) &&
+	  stat ((char *) msf->filename, &file_stat) == -1)
 	{
 	  ret = VNET_API_ERROR_SYSCALL_ERROR_8;
 	  goto error;
@@ -1101,6 +1192,9 @@ memif_create_if (vlib_main_t * vm, memif_create_if_args_t * args)
 	mif->flags |= MEMIF_IF_FLAG_ZERO_COPY;
     }
 
+  if (args->is_master)
+    mif->flags |= MEMIF_IF_FLAG_USE_DMA;
+
   vnet_hw_if_set_caps (vnm, mif->hw_if_index, VNET_HW_IF_CAP_INT_MODE);
   vnet_hw_if_set_input_node (vnm, mif->hw_if_index, memif_input_node.index);
   mhash_set (&msf->dev_instance_by_id, &mif->id, mif->dev_instance, 0);
diff --git a/src/plugins/memif/memif.h b/src/plugins/memif/memif.h
index 1c92d2640..2ac75a7f2 100644
--- a/src/plugins/memif/memif.h
+++ b/src/plugins/memif/memif.h
@@ -28,7 +28,7 @@
 #define MEMIF_VERSION		((MEMIF_VERSION_MAJOR << 8) | MEMIF_VERSION_MINOR)
 
 #define MEMIF_SECRET_SIZE       24
-
+#undef MEMIF_DEBUG
 /*
  *  Type definitions
  */
@@ -167,6 +167,8 @@ typedef struct
   MEMIF_CACHELINE_ALIGN_MARK (cacheline0);
   uint32_t cookie;
   uint16_t flags;
+//   uint16_t dma_head;
+//   uint16_t dma_tail;
 #define MEMIF_RING_FLAG_MASK_INT 1
   volatile uint16_t head;
     MEMIF_CACHELINE_ALIGN_MARK (cacheline1);
diff --git a/src/plugins/memif/memif_api.c b/src/plugins/memif/memif_api.c
index a50e7ce88..cbe049718 100644
--- a/src/plugins/memif/memif_api.c
+++ b/src/plugins/memif/memif_api.c
@@ -82,6 +82,41 @@ reply:
   REPLY_MACRO (VL_API_MEMIF_SOCKET_FILENAME_ADD_DEL_REPLY);
 }
 
+/**
+ * @brief Message handler for memif_socket_filename_add_del API.
+ * @param mp the vl_api_memif_socket_filename_add_del_t API message
+ */
+void
+vl_api_memif_socket_filename_add_del_v2_t_handler (
+  vl_api_memif_socket_filename_add_del_v2_t *mp)
+{
+  vl_api_memif_socket_filename_add_del_v2_reply_t *rmp;
+  memif_main_t *mm = &memif_main;
+  u8 *socket_filename = 0;
+  u32 socket_id;
+  int rv;
+
+  /* socket_id */
+  socket_id = clib_net_to_host_u32 (mp->socket_id);
+  if (socket_id == 0)
+    {
+      rv = VNET_API_ERROR_INVALID_ARGUMENT;
+      goto reply;
+    }
+
+  /* socket filename */
+  socket_filename = vl_api_from_api_to_new_vec (mp, &mp->socket_filename);
+  if (mp->is_add && socket_id == (u32) ~0)
+    socket_id = memif_get_unused_socket_id ();
+
+  rv = memif_socket_filename_add_del (mp->is_add, socket_id, socket_filename);
+
+  vec_free (socket_filename);
+
+reply:
+  REPLY_MACRO2 (VL_API_MEMIF_SOCKET_FILENAME_ADD_DEL_V2_REPLY,
+		({ rmp->socket_id = htonl (socket_id); }));
+}
 
 /**
  * @brief Message handler for memif_create API.
diff --git a/src/plugins/memif/memif_test.c b/src/plugins/memif/memif_test.c
index 98c9354a9..07d68924b 100644
--- a/src/plugins/memif/memif_test.c
+++ b/src/plugins/memif/memif_test.c
@@ -121,6 +121,86 @@ api_memif_socket_filename_add_del (vat_main_t * vam)
   return ret;
 }
 
+/* memif_socket_filename_add_del API */
+static int
+api_memif_socket_filename_add_del_v2 (vat_main_t *vam)
+{
+  unformat_input_t *i = vam->input;
+  vl_api_memif_socket_filename_add_del_v2_t *mp;
+  u8 is_add;
+  u32 socket_id;
+  u8 *socket_filename;
+  int ret;
+
+  is_add = 1;
+  socket_id = ~0;
+  socket_filename = 0;
+
+  while (unformat_check_input (i) != UNFORMAT_END_OF_INPUT)
+    {
+      if (unformat (i, "id %u", &socket_id))
+	;
+      else if (unformat (i, "filename %s", &socket_filename))
+	;
+      else if (unformat (i, "del"))
+	is_add = 0;
+      else if (unformat (i, "add"))
+	is_add = 1;
+      else
+	{
+	  vec_free (socket_filename);
+	  clib_warning ("unknown input `%U'", format_unformat_error, i);
+	  return -99;
+	}
+    }
+
+  if (socket_id == 0 || socket_id == ~0)
+    {
+      vec_free (socket_filename);
+      errmsg ("Invalid socket id");
+      return -99;
+    }
+
+  if (is_add && (!socket_filename || *socket_filename == 0))
+    {
+      vec_free (socket_filename);
+      errmsg ("Invalid socket filename");
+      return -99;
+    }
+
+  M2 (MEMIF_SOCKET_FILENAME_ADD_DEL_V2, mp, strlen ((char *) socket_filename));
+
+  mp->is_add = is_add;
+  mp->socket_id = htonl (socket_id);
+  char *p = (char *) &mp->socket_filename;
+  p += vl_api_vec_to_api_string (socket_filename, (vl_api_string_t *) p);
+
+  vec_free (socket_filename);
+
+  S (mp);
+  W (ret);
+
+  return ret;
+}
+
+/* memif socket-create reply handler */
+static void
+vl_api_memif_socket_filename_add_del_v2_reply_t_handler (
+  vl_api_memif_socket_filename_add_del_v2_reply_t *mp)
+{
+  vat_main_t *vam = memif_test_main.vat_main;
+  i32 retval = ntohl (mp->retval);
+
+  if (retval == 0)
+    {
+      fformat (vam->ofp, "created memif socket with socket_id %d\n",
+	       ntohl (mp->socket_id));
+    }
+
+  vam->retval = retval;
+  vam->result_ready = 1;
+}
+
 /* memif_socket_filename_add_del reply handler */
 #define VL_API_MEMIF_SOCKET_FILENAME_ADD_DEL_REPLY_T_HANDLER
 static void vl_api_memif_socket_filename_add_del_reply_t_handler
diff --git a/src/plugins/memif/node.c b/src/plugins/memif/node.c
index 1f636f2b3..c150e85c6 100644
--- a/src/plugins/memif/node.c
+++ b/src/plugins/memif/node.c
@@ -23,6 +23,7 @@
 
 #include <vlib/vlib.h>
 #include <vlib/unix/unix.h>
+#include <vlib/dma/dma.h>
 #include <vnet/ethernet/ethernet.h>
 #include <vnet/interface/rx_queue_funcs.h>
 #include <vnet/feature/feature.h>
@@ -464,6 +465,268 @@ memif_fill_buffer_mdata (vlib_main_t *vm, vlib_node_runtime_t *node,
     }
 }
 
+CLIB_MARCH_FN (memif_dma_completion_cb, void, vlib_main_t *vm, vlib_dma_batch_t *b)
+{
+  memif_main_t *mm = &memif_main;
+  memif_if_t *mif = vec_elt_at_index (mm->interfaces, b->cookie >> 16);
+  memif_queue_t *mq;
+  mq = vec_elt_at_index (mif->rx_queues, b->cookie & 0xffff);
+  u32 thread_index = vm->thread_index;
+  memif_per_thread_data_t *ptd =
+    vec_elt_at_index (mm->per_thread_data, thread_index);
+  u32 n_left_to_next;
+  u32 _to_next_bufs[MEMIF_RX_VECTOR_SZ], *to_next_bufs = _to_next_bufs;
+  u16 nexts[MEMIF_RX_VECTOR_SZ];
+
+  u32 next_index = VNET_DEVICE_INPUT_NEXT_ETHERNET_INPUT;
+  vnet_main_t *vnm = vnet_get_main ();
+  memif_dma_info_t *dma_info;
+  dma_info = ptd->dma_info + ptd->head;
+#ifdef MEMIF_DEBUG
+  printf("memif_dma_completion_cb: handle dma info at %d\n", ptd->head);
+#endif
+  if (dma_info->type == MEMIF_RING_S2M)
+  {
+#ifdef MEMIF_DEBUG
+    printf("memif_dma_completion_cb: slave to master update tail to %d\n", dma_info->dma_tail);
+#endif
+    __atomic_store_n (&mq->ring->tail, dma_info->dma_tail, __ATOMIC_RELEASE);
+   } else
+   {
+#ifdef MEMIF_DEBUG
+    printf("memif_dma_completion_cb: master to slave update head to %d\n", dma_info->dma_head);
+#endif
+    __atomic_store_n (&mq->ring->head, dma_info->dma_head, __ATOMIC_RELEASE);
+   }
+
+  i16 start_offset =
+    (dma_info->mode == MEMIF_INTERFACE_MODE_IP) ? MEMIF_IP_OFFSET : 0;
+  ptd->n_packets = b->n_enq;
+  ptd->desc_len = dma_info->desc_len;
+
+  /* prepare buffer template and next indices */
+  vnet_buffer (&ptd->buffer_template)->sw_if_index[VLIB_RX] = mif->sw_if_index;
+  vnet_buffer (&ptd->buffer_template)->feature_arc_index = 0;
+  ptd->buffer_template.current_data = start_offset;
+  ptd->buffer_template.current_config_index = 0;
+  ptd->buffer_template.buffer_pool_index = mq->buffer_pool_index;
+  ptd->buffer_template.ref_count = 1;
+
+  if (dma_info->mode == MEMIF_INTERFACE_MODE_ETHERNET)
+    {
+      next_index = VNET_DEVICE_INPUT_NEXT_ETHERNET_INPUT;
+      if (mif->per_interface_next_index != ~0)
+	next_index = mif->per_interface_next_index;
+      else
+	vnet_feature_start_device_input_x1 (mif->sw_if_index, &next_index,
+					    &ptd->buffer_template);
+
+      vlib_get_new_next_frame (vm, dma_info->node, next_index, to_next_bufs,
+			       n_left_to_next);
+      if (PREDICT_TRUE (next_index == VNET_DEVICE_INPUT_NEXT_ETHERNET_INPUT))
+	{
+	  vlib_next_frame_t *nf;
+	  vlib_frame_t *f;
+	  ethernet_input_frame_t *ef;
+	  nf =
+	    vlib_node_runtime_get_next_frame (vm, dma_info->node, next_index);
+	  f = vlib_get_frame (vm, nf->frame);
+	  f->flags = ETH_INPUT_FRAME_F_SINGLE_SW_IF_IDX;
+
+	  ef = vlib_frame_scalar_args (f);
+	  ef->sw_if_index = mif->sw_if_index;
+	  ef->hw_if_index = mif->hw_if_index;
+	  vlib_frame_no_append (f);
+	}
+    }
+
+  vlib_buffer_copy_indices (to_next_bufs, dma_info->buffers, b->n_enq);
+  if (dma_info->mode == MEMIF_INTERFACE_MODE_IP)
+    memif_fill_buffer_mdata_simple (dma_info->node, ptd, dma_info->buffer_ptrs,
+				    nexts, 1);
+  else
+    memif_fill_buffer_mdata_simple (dma_info->node, ptd, dma_info->buffer_ptrs,
+				    nexts, 0);
+
+  if (dma_info->mode == MEMIF_INTERFACE_MODE_ETHERNET)
+    {
+      n_left_to_next -= ptd->n_packets;
+      vlib_put_next_frame (vm, dma_info->node, next_index, n_left_to_next);
+    }
+  else
+    vlib_buffer_enqueue_to_next (vm, dma_info->node, to_next_bufs, nexts,
+				 ptd->n_packets);
+
+  vlib_increment_combined_counter (
+    vnm->interface_main.combined_sw_if_counters + VNET_INTERFACE_COUNTER_RX,
+    thread_index, mif->sw_if_index, ptd->n_packets, ptd->n_rx_bytes);
+
+  ptd->head++;
+  if (ptd->head == ptd->size)
+    ptd->head = 0;
+  return;
+}
+
+#ifndef CLIB_MARCH_VARIANT
+void
+memif_dma_completion_cb (vlib_main_t *vm, vlib_dma_batch_t *b)
+{
+  return CLIB_MARCH_FN_SELECT (memif_dma_completion_cb) (vm, b);
+}
+#endif
+
+static_always_inline uword
+memif_device_input_inline_dma (vlib_main_t *vm, vlib_node_runtime_t *node,
+			       memif_if_t *mif, memif_ring_type_t type,
+			       u16 qid, memif_interface_mode_t mode)
+{
+  memif_ring_t *ring;
+  memif_queue_t *mq;
+  u16 cur_slot, ring_size, n_slots, mask;
+  u16 n_buffers, n_alloc, n_desc;
+  memif_main_t *mm = &memif_main;
+  u32 thread_index = vm->thread_index;
+  memif_per_thread_data_t *ptd =
+    vec_elt_at_index (mm->per_thread_data, thread_index);
+  i16 start_offset;
+  int is_slave = (mif->flags & MEMIF_IF_FLAG_IS_SLAVE) != 0;
+  int i;
+  memif_dma_info_t *dma_info;
+
+  u16 mif_id = mif - mm->interfaces;
+  if ((ptd->tail + 1 == ptd->head) || ((ptd->head == ptd->size -1 ) && (ptd->tail == 0)))
+     return 0;
+  dma_info = ptd->dma_info + ptd->tail;
+
+  mq = vec_elt_at_index (mif->rx_queues, qid);
+  ring = mq->ring;
+  ring_size = 1 << mq->log2_ring_size;
+  mask = ring_size - 1;
+
+  start_offset = (mode == MEMIF_INTERFACE_MODE_IP) ? MEMIF_IP_OFFSET : 0;
+
+  if (is_slave)
+    {
+      cur_slot = mq->last_tail;
+      n_slots = __atomic_load_n (&ring->tail, __ATOMIC_ACQUIRE) - cur_slot;
+    }
+  else
+    {
+      cur_slot = mq->last_head;
+      n_slots = __atomic_load_n (&ring->head, __ATOMIC_ACQUIRE) - cur_slot;
+    }
+
+  if (n_slots == 0)
+    goto refill;
+
+  /* assume all simple */
+  n_desc = memif_parse_desc (ptd, mif, mq, cur_slot, n_slots);
+  cur_slot += n_desc;
+
+  if (mif->mode == MEMIF_INTERFACE_MODE_ETHERNET)
+    memif_validate_desc_data (ptd, mif, n_desc, /* is_ethernet */ 1);
+  else
+    memif_validate_desc_data (ptd, mif, n_desc, /* is_ethernet */ 0);
+
+  n_buffers = ptd->n_packets;
+  /* allocate free buffers */
+  n_alloc = vlib_buffer_alloc_from_pool (vm, dma_info->buffers, n_buffers,
+					 mq->buffer_pool_index);
+  if (PREDICT_FALSE (n_alloc != n_buffers))
+    {
+      if (n_alloc)
+	vlib_buffer_free (vm, dma_info->buffers, n_alloc);
+      vlib_error_count (vm, node->node_index,
+			MEMIF_INPUT_ERROR_BUFFER_ALLOC_FAIL, 1);
+      return 0;
+    }
+
+  int n_pkts = ptd->n_packets;
+  void **desc_data = ptd->desc_data;
+  u16 *desc_len = ptd->desc_len;
+
+  dma_info->node = node;
+  dma_info->type = type;
+  dma_info->mode = mode;
+  clib_memcpy_fast (dma_info->desc_len, ptd->desc_len, sizeof (u16) * n_pkts);
+  vlib_get_buffers (vm, dma_info->buffers, dma_info->buffer_ptrs, n_buffers);
+  dma_info->transfers = 0;
+  vlib_dma_batch_t *b;
+  b = vlib_dma_batch_new (vm, ptd->dma_config);
+
+  for (i = 0; i < n_pkts; i++)
+    {
+      vlib_dma_batch_add (vm, b, dma_info->buffer_ptrs[i]->data + start_offset, desc_data[i], desc_len[i]);
+      dma_info->transfers++;
+    }
+
+     vlib_dma_batch_set_cookie (vm, b, (uword)(mif_id << 16) | qid);
+     vlib_dma_batch_submit (vm, b);
+
+  /* release slots from the ring */
+  if (dma_info->type == MEMIF_RING_S2M)
+    {
+      dma_info->dma_tail = cur_slot;
+      mq->last_head = cur_slot;
+#ifdef MEMIF_DEBUG
+      printf("memif_device_input_inline_dma: slave to master cur slot is %d and update dma_tail and last_head\n", cur_slot);
+#endif
+    }
+  else
+    {
+#ifdef MEMIF_DEBUG
+      printf("memif_device_input_inline_dma: master to slave cur slot is %d and update last tail\n", cur_slot);
+#endif
+      mq->last_tail = cur_slot;
+    }
+
+  if (dma_info->type == MEMIF_RING_M2S)
+    {
+      u16 head = mq->ring->head;
+      n_slots = ring_size - head + mq->last_tail;
+#ifdef MEMIF_DEBUG
+      printf("memif_device_input_inline_dma: master to slave cur slot is %d and update last tail\n", cur_slot);
+#endif
+      while (n_slots--)
+	{
+	  u16 s = head++ & mask;
+	  memif_desc_t *d = &mq->ring->desc[s];
+	  d->length = mif->run.buffer_size;
+	}
+
+      dma_info->dma_head = head;
+    }
+#ifdef MEMIF_DEBUG
+  printf("memif_device_input_inline_dma: update dma info at %d\n", ptd->tail);
+#endif
+  ptd->tail++;
+  if (ptd->tail == ptd->size)
+    ptd->tail = 0;
+
+  return n_buffers;
+
+  /* refill ring with empty buffers */
+refill:
+  vec_reset_length (ptd->buffers);
+  vec_reset_length (ptd->copy_ops);
+
+  if (type == MEMIF_RING_M2S)
+    {
+      u16 head = ring->head;
+      n_slots = ring_size - head + mq->last_tail;
+
+      while (n_slots--)
+	{
+	  u16 s = head++ & mask;
+	  memif_desc_t *d = &ring->desc[s];
+	  d->length = mif->run.buffer_size;
+	}
+
+      __atomic_store_n (&ring->head, head, __ATOMIC_RELEASE);
+    }
+  return 0;
+}
+
 static_always_inline uword
 memif_device_input_inline (vlib_main_t *vm, vlib_node_runtime_t *node,
 			   memif_if_t *mif, memif_ring_type_t type, u16 qid,
@@ -502,11 +765,19 @@ memif_device_input_inline (vlib_main_t *vm, vlib_node_runtime_t *node,
     {
       cur_slot = mq->last_tail;
       n_slots = __atomic_load_n (&ring->tail, __ATOMIC_ACQUIRE) - cur_slot;
+#ifdef MEMIF_DEBUG
+      if (n_slots)
+        printf("memif_device_input_inline: got new tail %d last tail %d n_slots is %d\n", ring->tail, cur_slot, n_slots);
+#endif
     }
   else
     {
       cur_slot = mq->last_head;
       n_slots = __atomic_load_n (&ring->head, __ATOMIC_ACQUIRE) - cur_slot;
+#ifdef MEMIF_DEBUG
+      if (n_slots)
+        printf("memif_device_input_inline: got new head %d last head %d n_slots is %d\n", ring->head, cur_slot, n_slots);
+#endif
     }
 
   if (n_slots == 0)
@@ -760,10 +1031,15 @@ memif_device_input_zc_inline (vlib_main_t *vm, vlib_node_runtime_t *node,
 
   cur_slot = mq->last_tail;
   last_slot = __atomic_load_n (&ring->tail, __ATOMIC_ACQUIRE);
+
   if (cur_slot == last_slot)
     goto refill;
   n_slots = last_slot - cur_slot;
 
+#ifdef MEMIF_DEBUG
+      if (n_slots)
+        printf("memif_device_input_inline: got new tail %d last tail %d n_slots is %d\n", ring->tail, cur_slot, n_slots);
+#endif
   /* process ring slots */
   vec_validate_aligned (ptd->buffers, MEMIF_RX_VECTOR_SZ,
 			CLIB_CACHE_LINE_BYTES);
@@ -1060,21 +1336,45 @@ VLIB_NODE_FN (memif_input_node) (vlib_main_t * vm,
 	    }
 	  else if (mif->flags & MEMIF_IF_FLAG_IS_SLAVE)
 	    {
-	      if (mif->mode == MEMIF_INTERFACE_MODE_IP)
-		n_rx += memif_device_input_inline (
-		  vm, node, mif, MEMIF_RING_M2S, qid, mode_ip);
+	      if (mif->flags & MEMIF_IF_FLAG_USE_DMA)
+		{
+		  if (mif->mode == MEMIF_INTERFACE_MODE_IP)
+		    n_rx += memif_device_input_inline_dma (
+		      vm, node, mif, MEMIF_RING_M2S, qid, mode_ip);
+		  else
+		    n_rx += memif_device_input_inline_dma (
+		      vm, node, mif, MEMIF_RING_M2S, qid, mode_eth);
+		}
 	      else
-		n_rx += memif_device_input_inline (
-		  vm, node, mif, MEMIF_RING_M2S, qid, mode_eth);
+		{
+		  if (mif->mode == MEMIF_INTERFACE_MODE_IP)
+		    n_rx += memif_device_input_inline (
+		      vm, node, mif, MEMIF_RING_M2S, qid, mode_ip);
+		  else
+		    n_rx += memif_device_input_inline (
+		      vm, node, mif, MEMIF_RING_M2S, qid, mode_eth);
+		}
 	    }
 	  else
 	    {
-	      if (mif->mode == MEMIF_INTERFACE_MODE_IP)
-		n_rx += memif_device_input_inline (
-		  vm, node, mif, MEMIF_RING_S2M, qid, mode_ip);
+	      if (mif->flags & MEMIF_IF_FLAG_USE_DMA)
+		{
+		  if (mif->mode == MEMIF_INTERFACE_MODE_IP)
+		    n_rx += memif_device_input_inline_dma (
+		      vm, node, mif, MEMIF_RING_S2M, qid, mode_ip);
+		  else
+		    n_rx += memif_device_input_inline_dma (
+		      vm, node, mif, MEMIF_RING_S2M, qid, mode_eth);
+		}
 	      else
-		n_rx += memif_device_input_inline (
-		  vm, node, mif, MEMIF_RING_S2M, qid, mode_eth);
+		{
+		  if (mif->mode == MEMIF_INTERFACE_MODE_IP)
+		    n_rx += memif_device_input_inline (
+		      vm, node, mif, MEMIF_RING_S2M, qid, mode_ip);
+		  else
+		    n_rx += memif_device_input_inline (
+		      vm, node, mif, MEMIF_RING_S2M, qid, mode_eth);
+		}
 	    }
 	}
     }
diff --git a/src/plugins/memif/private.h b/src/plugins/memif/private.h
index 0e4ca4af9..da6ad85e6 100644
--- a/src/plugins/memif/private.h
+++ b/src/plugins/memif/private.h
@@ -16,6 +16,7 @@
  */
 
 #include <vppinfra/lock.h>
+#include <vlib/dma/dma.h>
 #include <vlib/log.h>
 
 #define MEMIF_DEFAULT_SOCKET_FILENAME  "memif.sock"
@@ -130,6 +131,9 @@ typedef struct
   memif_region_index_t region;
   memif_region_offset_t offset;
 
+  uint16_t dma_head;
+  uint16_t dma_tail;
+
   u16 last_head;
   u16 last_tail;
   u32 *buffers;
@@ -145,14 +149,15 @@ typedef struct
   u32 queue_index;
 } memif_queue_t;
 
-#define foreach_memif_if_flag \
-  _(0, ADMIN_UP, "admin-up")		\
-  _(1, IS_SLAVE, "slave")		\
-  _(2, CONNECTING, "connecting")	\
-  _(3, CONNECTED, "connected")		\
-  _(4, DELETING, "deleting")		\
-  _(5, ZERO_COPY, "zero-copy")		\
-  _(6, ERROR, "error")
+#define foreach_memif_if_flag                                                 \
+  _ (0, ADMIN_UP, "admin-up")                                                 \
+  _ (1, IS_SLAVE, "slave")                                                    \
+  _ (2, CONNECTING, "connecting")                                             \
+  _ (3, CONNECTED, "connected")                                               \
+  _ (4, DELETING, "deleting")                                                 \
+  _ (5, ZERO_COPY, "zero-copy")                                               \
+  _ (6, ERROR, "error")                                                       \
+  _ (7, USE_DMA, "use_dma")
 
 typedef enum
 {
@@ -207,6 +212,9 @@ typedef struct
   /* disconnect strings */
   u8 *local_disc_string;
   u8 *remote_disc_string;
+
+  /* dma */
+  u32 config_index;
 } memif_if_t;
 
 typedef struct
@@ -249,6 +257,21 @@ typedef union
 
 STATIC_ASSERT_SIZEOF (memif_desc_status_t, 1);
 
+typedef struct
+{
+  u32 buffers[256];
+  u16 desc_len[256];
+  vlib_buffer_t *buffer_ptrs[256];
+  vlib_dma_batch_t *batch;
+  u32 transfers;
+  memif_interface_mode_t mode;
+  vlib_node_runtime_t *node;
+  memif_ring_type_t type;
+  vlib_buffer_t buffer_template;
+  u32 dma_head;
+  u32 dma_tail;
+} memif_dma_info_t;
+
 typedef struct
 {
   CLIB_CACHE_LINE_ALIGN_MARK (cacheline0);
@@ -266,6 +289,20 @@ typedef struct
   u16 *desc_len;
   memif_desc_status_t *desc_status;
 
+  /* dma related */
+  int dma_config;
+  int tx_dma_config;
+  u16 completed_desc;
+  memif_dma_info_t *dma_info;
+  memif_dma_info_t *tx_dma_info;
+  u32 n_vectors;
+  u16 head;
+  u16 tail;
+  u16 size;
+  u16 tx_head;
+  u16 tx_tail;
+  u16 tx_size;
+  u32 *from;
   /* buffer template */
   vlib_buffer_t buffer_template;
 } memif_per_thread_data_t;
@@ -309,6 +346,7 @@ typedef struct
   u8 *secret;
   u8 is_master;
   u8 is_zero_copy;
+  u8 use_dma;
   memif_interface_mode_t mode:8;
   memif_log2_ring_size_t log2_ring_size;
   u16 buffer_size;
@@ -323,6 +361,7 @@ typedef struct
 
 int memif_socket_filename_add_del (u8 is_add, u32 sock_id,
 				   u8 * sock_filename);
+u32 memif_get_unused_socket_id ();
 int memif_create_if (vlib_main_t * vm, memif_create_if_args_t * args);
 int memif_delete_if (vlib_main_t * vm, memif_if_t * mif);
 clib_error_t *memif_plugin_api_hookup (vlib_main_t * vm);
@@ -353,7 +392,8 @@ clib_error_t *memif_slave_conn_fd_error (clib_file_t * uf);
 clib_error_t *memif_msg_send_disconnect (memif_if_t * mif,
 					 clib_error_t * err);
 u8 *format_memif_device_name (u8 * s, va_list * args);
-
+void memif_dma_completion_cb (vlib_main_t *vm, vlib_dma_batch_t *b);
+void memif_tx_dma_completion_cb (vlib_main_t *vm, vlib_dma_batch_t *b);
 
 /*
  * fd.io coding-style-patch-verification: ON
diff --git a/src/plugins/nat/CMakeLists.txt b/src/plugins/nat/CMakeLists.txt
index 54c153742..3bf92238d 100644
--- a/src/plugins/nat/CMakeLists.txt
+++ b/src/plugins/nat/CMakeLists.txt
@@ -178,16 +178,16 @@ set (PACKET_DEFS
   ${CMAKE_CURRENT_SOURCE_DIR}/pnat/tests/missing_rule.def)
 set (PACKET_TESTGET ${CMAKE_CURRENT_SOURCE_DIR}/pnat/tests/test_genpackets.py)
 
-add_vpp_executable(test_pnat
-  SOURCES
-  pnat/tests/pnat_test.c
-  pnat/pnat_node.c
-  pnat/pnat.c
-  ../../vnet/ip/ip_checksum.c
-
-  LINK_LIBRARIES vppinfra vlib
-  NO_INSTALL
-)
+# add_vpp_executable(test_pnat
+#   SOURCES
+#   pnat/tests/pnat_test.c
+#   pnat/pnat_node.c
+#   pnat/pnat.c
+#   ../../vnet/ip/ip_checksum.c
+
+#   LINK_LIBRARIES vppinfra vlib
+#   NO_INSTALL
+# )
 
 add_custom_target(test_pnat-generate
   COMMAND ${PACKET_TESTGET} ${PACKET_DEFS} > ${PACKET_HEADER}
diff --git a/src/plugins/pbl/CMakeLists.txt b/src/plugins/pbl/CMakeLists.txt
new file mode 100644
index 000000000..a4ce971c2
--- /dev/null
+++ b/src/plugins/pbl/CMakeLists.txt
@@ -0,0 +1,22 @@
+# Copyright (c) 2021 Cisco and/or its affiliates.
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at:
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+add_vpp_plugin(pbl
+  SOURCES
+  pbl_client.c
+  pbl_node.c
+  pbl_api.c
+
+  API_FILES
+  pbl.api
+)
diff --git a/src/plugins/pbl/FEATURE.yaml b/src/plugins/pbl/FEATURE.yaml
new file mode 100644
index 000000000..34f3a479f
--- /dev/null
+++ b/src/plugins/pbl/FEATURE.yaml
@@ -0,0 +1,8 @@
+---
+name: PBL (Port based Balencer)
+maintainer: Nathan Skrzypczak <nathan.skrzypczak@gmail.com>
+features:
+  - Port based balancer
+description: "Feature that enables selective punting of flows to an interface"
+state: experimental
+properties: [MULTITHREAD]
diff --git a/src/plugins/pbl/pbl.api b/src/plugins/pbl/pbl.api
new file mode 100644
index 000000000..eada35314
--- /dev/null
+++ b/src/plugins/pbl/pbl.api
@@ -0,0 +1,89 @@
+/* Hey Emacs use -*- mode: C -*- */
+/*
+ * Copyright (c) 2021 Cisco and/or its affiliates.
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at:
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+/** \file
+    This file defines the vpp control-plane API messages
+    used to control the PBL plugin
+*/
+
+option version = "0.1.0";
+import "vnet/ip/ip_types.api";
+import "vnet/fib/fib_types.api";
+import "vnet/interface_types.api";
+
+enum pbl_client_flags
+{
+  PBL_API_FLAG_EXCLUSIVE = 1,
+};
+
+typedef pbl_port_range
+{
+    u16 start;
+    u16 end;
+    vl_api_ip_proto_t iproto;
+};
+
+typedef pbl_client
+{
+  u32 id [default=0xffffffff];
+  vl_api_address_t addr;
+  vl_api_fib_path_t paths; /* we support only one now due to api limit */
+  u8 flags;
+  u32 table_id;
+  u32 n_ports;
+  vl_api_pbl_port_range_t port_ranges[n_ports];
+};
+
+define pbl_client_update
+{
+  u32 client_index;
+  u32 context;
+  vl_api_pbl_client_t client;
+};
+
+define pbl_client_update_reply
+{
+  u32 context;
+  i32 retval;
+  u32 id;
+};
+
+autoreply define pbl_client_del
+{
+  u32 client_index;
+  u32 context;
+  u32 id;
+};
+
+define pbl_client_details
+{
+  u32 context;
+  vl_api_pbl_client_t client;
+};
+
+define pbl_client_dump
+{
+  u32 client_index;
+  u32 context;
+};
+
+/*
+ * fd.io coding-style-patch-verification: ON
+ *
+ * Local Variables:
+ * eval: (c-set-style "gnu")
+ * End:
+ */
diff --git a/src/plugins/pbl/pbl_api.c b/src/plugins/pbl/pbl_api.c
new file mode 100644
index 000000000..e948357b0
--- /dev/null
+++ b/src/plugins/pbl/pbl_api.c
@@ -0,0 +1,179 @@
+/*
+ * Copyright (c) 2016 Cisco and/or its affiliates.
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at:
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include <stddef.h>
+
+#include <vnet/vnet.h>
+#include <vnet/plugin/plugin.h>
+#include <pbl/pbl_client.h>
+
+#include <vnet/ip/ip_types_api.h>
+
+#include <vpp/app/version.h>
+#include <vnet/fib/fib_api.h>
+
+#include <vlibapi/api.h>
+#include <vlibmemory/api.h>
+
+/* define message IDs */
+#include <vnet/format_fns.h>
+#include <pbl/pbl.api_enum.h>
+#include <pbl/pbl.api_types.h>
+
+/**
+ * Base message ID fot the plugin
+ */
+static u32 pbl_base_msg_id;
+
+#define REPLY_MSG_ID_BASE pbl_base_msg_id
+
+#include <vlibapi/api_helper_macros.h>
+
+static void
+vl_api_pbl_client_update_t_handler (vl_api_pbl_client_update_t *mp)
+{
+  pbl_client_update_args_t _args = { 0 }, *args = &_args;
+  vl_api_pbl_client_update_reply_t *rmp;
+  pbl_client_port_map_proto_t proto;
+  fib_route_path_t *rpath;
+  ip_protocol_t iproto;
+  int rv = 0;
+  u32 ii, n_ports;
+  u16 port_a, port_b;
+
+  args->pci = clib_net_to_host_u32 (mp->client.id);
+  ip_address_decode2 (&mp->client.addr, &args->addr);
+
+  for (ii = 0; ii < PBL_CLIENT_PORT_MAP_N_PROTOS; ii++)
+    {
+      clib_bitmap_alloc (args->port_maps[ii], (1 << 16) - 1);
+      clib_bitmap_zero (args->port_maps[ii]);
+    }
+
+  n_ports = clib_net_to_host_u32 (mp->client.n_ports);
+  for (ii = 0; ii < n_ports; ii++)
+    {
+      port_a = clib_net_to_host_u16 (mp->client.port_ranges[ii].start);
+      port_b = clib_net_to_host_u16 (mp->client.port_ranges[ii].end);
+      port_b = clib_max (port_a, port_b);
+
+      rv = ip_proto_decode (mp->client.port_ranges[ii].iproto, &iproto);
+      if (rv)
+	goto done;
+      proto = pbl_iproto_to_port_map_proto (iproto);
+
+      if (proto < PBL_CLIENT_PORT_MAP_N_PROTOS)
+	clib_bitmap_set_region (args->port_maps[proto], port_a, 1,
+				port_b - port_a + 1);
+    }
+  args->flags = mp->client.flags;
+  args->table_id = clib_net_to_host_u32 (mp->client.table_id);
+
+  vec_validate (args->rpaths, 0);
+  rpath = &args->rpaths[0];
+
+  rv = fib_api_path_decode (&mp->client.paths, rpath);
+  if (rv)
+    goto done;
+
+  args->pci = pbl_client_update (args);
+
+done:
+  vec_free (args->rpaths);
+
+  REPLY_MACRO2 (VL_API_PBL_CLIENT_UPDATE_REPLY,
+		({ rmp->id = clib_host_to_net_u32 (args->pci); }));
+}
+
+static void
+vl_api_pbl_client_del_t_handler (vl_api_pbl_client_del_t *mp)
+{
+  vl_api_pbl_client_del_reply_t *rmp;
+  int rv;
+
+  rv = pbl_client_delete (ntohl (mp->id));
+
+  REPLY_MACRO (VL_API_PBL_CLIENT_DEL_REPLY);
+}
+
+typedef struct pbl_dump_walk_ctx_t_
+{
+  vl_api_registration_t *rp;
+  u32 context;
+} pbl_dump_walk_ctx_t;
+
+static walk_rc_t
+pbl_client_send_details (u32 cti, void *args)
+{
+  vl_api_pbl_client_details_t *mp;
+  pbl_dump_walk_ctx_t *ctx;
+  size_t msg_size;
+  pbl_client_t *pc;
+
+  ctx = args;
+  pc = pbl_client_get (cti);
+  msg_size = sizeof (*mp);
+
+  mp = vl_msg_api_alloc_zero (msg_size);
+  mp->_vl_msg_id = ntohs (VL_API_PBL_CLIENT_DETAILS + pbl_base_msg_id);
+
+  mp->client.id = clib_host_to_net_u32 (cti);
+  ip_address_encode2 (&pc->pc_addr, &mp->client.addr);
+  mp->client.flags = clib_host_to_net_u32 (pc->flags);
+
+  /* TODO : we miss routes & ports */
+
+  vl_api_send_msg (ctx->rp, (u8 *) mp);
+
+  return (WALK_CONTINUE);
+}
+
+static void
+vl_api_pbl_client_dump_t_handler (vl_api_pbl_client_dump_t *mp)
+{
+  vl_api_registration_t *rp;
+
+  rp = vl_api_client_index_to_registration (mp->client_index);
+  if (rp == 0)
+    return;
+
+  pbl_dump_walk_ctx_t ctx = {
+    .rp = rp,
+    .context = mp->context,
+  };
+
+  pbl_client_walk (pbl_client_send_details, &ctx);
+}
+
+#include <pbl/pbl.api.c>
+
+static clib_error_t *
+pbl_api_init (vlib_main_t *vm)
+{
+  /* Ask for a correctly-sized block of API message decode slots */
+  pbl_base_msg_id = setup_message_id_table ();
+
+  return 0;
+}
+
+VLIB_INIT_FUNCTION (pbl_api_init);
+
+/*
+ * fd.io coding-style-patch-verification: ON
+ *
+ * Local Variables:
+ * eval: (c-set-style "gnu")
+ * End:
+ */
diff --git a/src/plugins/pbl/pbl_client.c b/src/plugins/pbl/pbl_client.c
new file mode 100644
index 000000000..dc527ca25
--- /dev/null
+++ b/src/plugins/pbl/pbl_client.c
@@ -0,0 +1,570 @@
+/*
+ * Copyright (c) 2020 Cisco and/or its affiliates.
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at:
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include <vnet/fib/fib_source.h>
+#include <vnet/fib/fib_table.h>
+#include <vnet/fib/fib_entry_track.h>
+#include <vnet/fib/fib_path_list.h>
+#include <vnet/dpo/load_balance.h>
+#include <vnet/dpo/drop_dpo.h>
+#include <vnet/plugin/plugin.h>
+#include <vpp/app/version.h>
+
+#include <pbl/pbl_client.h>
+
+char *pbl_error_strings[] = {
+#define pbl_error(n, s) s,
+#include <pbl/pbl_error.def>
+#undef pbl_error
+};
+
+pbl_client_t *pbl_client_pool;
+fib_source_t pbl_fib_source;
+dpo_type_t pbl_client_dpo;
+
+static fib_node_type_t pbl_client_fib_node_type;
+
+static_always_inline u8
+pbl_client_is_clone (pbl_client_t *pc)
+{
+  return (FIB_NODE_INDEX_INVALID == pc->pc_fei);
+}
+
+static u8 *
+format_pbl_ports (u8 *s, va_list *args)
+{
+  clib_bitmap_t *map = va_arg (*args, clib_bitmap_t *);
+  if (NULL == map)
+    {
+      s = format (s, "(empty)");
+      return (s);
+    }
+  u32 last, cur, next_set, next_clear;
+  last = clib_bitmap_last_set (map);
+  cur = clib_bitmap_first_set (map);
+
+  if (cur == (u32) -1)
+    {
+      s = format (s, "(empty)");
+      return (s);
+    }
+
+  while (cur <= last)
+    {
+      next_set = clib_bitmap_next_set (map, cur);
+      next_clear = clib_bitmap_next_clear (map, next_set + 1);
+      if (next_clear == next_set + 1)
+	s = format (s, " %d", next_set);
+      else
+	s = format (s, " %d-%d", next_set, next_clear - 1);
+      cur = next_clear;
+    }
+
+  return (s);
+}
+
+u8 *
+format_pbl_client (u8 *s, va_list *args)
+{
+  index_t pci = va_arg (*args, index_t);
+  pbl_client_t *pc = pool_elt_at_index (pbl_client_pool, pci);
+  u32 indent = va_arg (*args, u32);
+
+  s = format (s, "%U[%d] pbl-client: %U", format_white_space, indent, pci,
+	      format_ip_address, &pc->pc_addr);
+
+  if (pc->flags & PBL_FLAG_EXCLUSIVE)
+    s = format (s, " exclusive");
+
+  if (!pbl_client_is_clone (pc) && INDEX_INVALID != pc->clone_pci)
+    {
+      s = format (s, " clone:%d", pc->clone_pci);
+      return (s);
+    }
+
+  s = format (s, "\n%UTCP ports:%U", format_white_space, indent + 2,
+	      format_pbl_ports, pc->pc_port_maps[PBL_CLIENT_PORT_MAP_TCP]);
+
+  s = format (s, "\n%UUDP ports:%U", format_white_space, indent + 2,
+	      format_pbl_ports, pc->pc_port_maps[PBL_CLIENT_PORT_MAP_UDP]);
+
+  s = format (s, "\n%Umatched dpo\n%U%U", format_white_space, indent + 2,
+	      format_white_space, indent + 4, format_dpo_id, &pc->pc_dpo,
+	      indent + 4);
+
+  if (pbl_client_is_clone (pc))
+    {
+      s = format (s, "\n%Udefault dpo\n%U%U", format_white_space, indent + 2,
+		  format_white_space, indent + 4, format_dpo_id,
+		  &pc->pc_parent, indent + 4);
+    }
+
+  return (s);
+}
+
+/**
+ * Interpose a policy DPO
+ */
+static void
+pbl_client_dpo_interpose (const dpo_id_t *original, const dpo_id_t *parent,
+			  dpo_id_t *clone)
+{
+  pbl_client_t *pc, *pc_clone;
+  int ii;
+
+  pool_get_zero (pbl_client_pool, pc_clone);
+  pc = pbl_client_get (original->dpoi_index);
+
+  pc_clone->pc_fei = FIB_NODE_INDEX_INVALID;
+  pc_clone->clone_pci = INDEX_INVALID;
+  ip_address_copy (&pc_clone->pc_addr, &pc->pc_addr);
+  pc_clone->flags = pc->flags;
+  for (ii = 0; ii < PBL_CLIENT_PORT_MAP_N_PROTOS; ii++)
+    pc_clone->pc_port_maps[ii] = pc->pc_port_maps[ii];
+
+  dpo_copy (&pc_clone->pc_dpo, &pc->pc_dpo);
+
+  pc->clone_pci = pc_clone - pbl_client_pool;
+
+  /* stack the clone on the FIB provided parent */
+  dpo_stack (pbl_client_dpo, original->dpoi_proto, &pc_clone->pc_parent,
+	     parent);
+
+  /* return the clone */
+  dpo_set (clone, pbl_client_dpo, original->dpoi_proto,
+	   pc_clone - pbl_client_pool);
+}
+
+static clib_error_t *
+pbl_client_show (vlib_main_t *vm, unformat_input_t *input,
+		 vlib_cli_command_t *cmd)
+{
+  index_t pci;
+
+  pci = INDEX_INVALID;
+
+  while (unformat_check_input (input) != UNFORMAT_END_OF_INPUT)
+    {
+      if (unformat (input, "%d", &pci))
+	;
+      else
+	return (clib_error_return (0, "unknown input '%U'",
+				   format_unformat_error, input));
+    }
+
+  if (INDEX_INVALID == pci)
+    {
+      pool_foreach_index (pci, pbl_client_pool)
+	vlib_cli_output (vm, "%U", format_pbl_client, pci, 0);
+    }
+
+  return (NULL);
+}
+
+VLIB_CLI_COMMAND (pbl_client_show_cmd_node, static) = {
+  .path = "show pbl client",
+  .function = pbl_client_show,
+  .short_help = "show pbl client",
+  .is_mp_safe = 1,
+};
+
+const static char *const pbl_client_dpo_ip4_nodes[] = {
+  "ip4-pbl-tx",
+  NULL,
+};
+
+const static char *const pbl_client_dpo_ip6_nodes[] = {
+  "ip6-pbl-tx",
+  NULL,
+};
+
+const static char *const *const pbl_client_dpo_nodes[DPO_PROTO_NUM] = {
+  [DPO_PROTO_IP4] = pbl_client_dpo_ip4_nodes,
+  [DPO_PROTO_IP6] = pbl_client_dpo_ip6_nodes,
+};
+
+static void
+pbl_client_dpo_lock (dpo_id_t *dpo)
+{
+  pbl_client_t *pc;
+
+  pc = pbl_client_get (dpo->dpoi_index);
+
+  pc->pc_locks++;
+}
+
+static void
+pbl_client_dpo_unlock (dpo_id_t *dpo)
+{
+  pbl_client_t *pc;
+
+  pc = pbl_client_get (dpo->dpoi_index);
+
+  pc->pc_locks--;
+
+  if (0 == pc->pc_locks)
+    {
+      ASSERT (pbl_client_is_clone (pc));
+      dpo_reset (&pc->pc_parent);
+      pool_put (pbl_client_pool, pc);
+    }
+}
+
+u8 *
+format_pbl_client_dpo (u8 *s, va_list *ap)
+{
+  index_t pci = va_arg (*ap, index_t);
+  u32 indent = va_arg (*ap, u32);
+
+  s = format (s, "\n%U", format_pbl_client, pci, indent);
+
+  return (s);
+}
+
+const static dpo_vft_t pbl_client_dpo_vft = {
+  .dv_lock = pbl_client_dpo_lock,
+  .dv_unlock = pbl_client_dpo_unlock,
+  .dv_format = format_pbl_client_dpo,
+  .dv_mk_interpose = pbl_client_dpo_interpose,
+};
+
+static void
+pbl_client_stack (pbl_client_t *pc)
+{
+  dpo_id_t dpo = DPO_INVALID;
+  fib_protocol_t fproto;
+  vlib_node_t *pnode;
+  pbl_client_t *pc_clone;
+
+  fproto = ip_address_family_to_fib_proto (pc->pc_addr.version);
+  fib_path_list_contribute_forwarding (
+    pc->pc_pl, fib_forw_chain_type_from_fib_proto (fproto),
+    FIB_PATH_LIST_FWD_FLAG_COLLAPSE, &dpo);
+
+  if (AF_IP4 == pc->pc_addr.version)
+    pnode = vlib_get_node_by_name (vlib_get_main (), (u8 *) "ip4-pbl-tx");
+  else
+    pnode = vlib_get_node_by_name (vlib_get_main (), (u8 *) "ip6-pbl-tx");
+
+  dpo_stack_from_node (pnode->index, &pc->pc_dpo, &dpo);
+
+  if (INDEX_INVALID != pc->clone_pci)
+    {
+      pc_clone = pbl_client_get_if_exists (pc->clone_pci);
+      if (pc_clone)
+	dpo_copy (&pc_clone->pc_dpo, &pc->pc_dpo);
+    }
+
+  dpo_reset (&dpo);
+
+  pc->flags |= PBL_CLIENT_STACKED;
+}
+
+int
+pbl_client_delete (u32 id)
+{
+  pbl_client_t *pc;
+  int ii;
+
+  if (pool_is_free_index (pbl_client_pool, id))
+    return (VNET_API_ERROR_NO_SUCH_ENTRY);
+
+  pc = pool_elt_at_index (pbl_client_pool, id);
+
+  fib_path_list_child_remove (pc->pc_pl, pc->pc_sibling);
+
+  dpo_reset (&pc->pc_dpo);
+
+  ASSERT (!pbl_client_is_clone (pc));
+
+  ASSERT (fib_entry_is_sourced (pc->pc_fei, pbl_fib_source));
+  fib_table_entry_delete_index (pc->pc_fei, pbl_fib_source);
+
+  for (ii = 0; ii < PBL_CLIENT_PORT_MAP_N_PROTOS; ii++)
+    clib_bitmap_free (pc->pc_port_maps[ii]);
+
+  dpo_reset (&pc->pc_parent);
+  pool_put (pbl_client_pool, pc);
+
+  return (0);
+}
+
+u32
+pbl_client_update (pbl_client_update_args_t *args)
+{
+  pbl_client_t *pc;
+  dpo_id_t tmp = DPO_INVALID;
+  fib_node_index_t fei;
+  dpo_proto_t dproto;
+  fib_prefix_t pfx;
+  u32 fib_flags, fib_index;
+  int ii;
+
+  /* check again if we need this client */
+  pc = pbl_client_get_if_exists (args->pci);
+  if (NULL == pc)
+    {
+      pool_get_aligned (pbl_client_pool, pc, CLIB_CACHE_LINE_BYTES);
+      pc->pc_locks = 1;
+      args->pci = pc - pbl_client_pool;
+      pc->pc_index = pc - pbl_client_pool;
+      pc->flags = args->flags;
+      pc->clone_pci = INDEX_INVALID;
+      for (ii = 0; ii < PBL_CLIENT_PORT_MAP_N_PROTOS; ii++)
+	pc->pc_port_maps[ii] = args->port_maps[ii];
+      fib_node_init (&pc->pc_node, pbl_client_fib_node_type);
+
+      ip_address_copy (&pc->pc_addr, &args->addr);
+
+      ip_address_to_fib_prefix (&pc->pc_addr, &pfx);
+
+      dproto = fib_proto_to_dpo (pfx.fp_proto);
+      dpo_set (&tmp, pbl_client_dpo, dproto, args->pci);
+      dpo_stack (pbl_client_dpo, dproto, &pc->pc_parent,
+		 drop_dpo_get (dproto));
+
+      fib_flags = FIB_ENTRY_FLAG_LOOSE_URPF_EXEMPT;
+      fib_flags |= (args->flags & PBL_FLAG_EXCLUSIVE) ?
+		     FIB_ENTRY_FLAG_EXCLUSIVE :
+		     FIB_ENTRY_FLAG_INTERPOSE;
+
+      fib_index = fib_table_find (pfx.fp_proto, args->table_id);
+      fei = fib_table_entry_special_dpo_add (fib_index, &pfx, pbl_fib_source,
+					     fib_flags, &tmp);
+
+      /* in case of interpose, pool can grow */
+      pc = pool_elt_at_index (pbl_client_pool, args->pci);
+
+      pc->pc_fei = fei;
+
+      pc->flags = args->flags;
+      pc->flags &= ~PBL_CLIENT_STACKED;
+
+      /* Contribute in fib in fib */
+      pc->pc_pl = fib_path_list_create (
+	FIB_PATH_LIST_FLAG_SHARED | FIB_PATH_LIST_FLAG_NO_URPF, args->rpaths);
+
+      /*
+       * become a child of the path list so we get poked when
+       * the forwarding changes.
+       */
+      pc->pc_sibling = fib_path_list_child_add (
+	pc->pc_pl, pbl_client_fib_node_type, pc->pc_index);
+      pbl_client_stack (pc);
+    }
+  else
+    {
+      /* Update unimplemented */
+      clib_warning ("unimplemented");
+    }
+
+  return (pc->pc_index);
+}
+
+void
+pbl_client_walk (pbl_client_walk_cb_t cb, void *ctx)
+{
+  u32 api;
+
+  pool_foreach_index (api, pbl_client_pool)
+    {
+      if (!cb (api, ctx))
+	break;
+    }
+}
+
+int
+pbl_client_purge (void)
+{
+  /* purge all the clients */
+  index_t tri, *trp, *trs = NULL;
+
+  pool_foreach_index (tri, pbl_client_pool)
+    {
+      vec_add1 (trs, tri);
+    }
+
+  vec_foreach (trp, trs)
+    pbl_client_delete (*trp);
+
+  ASSERT (0 == pool_elts (pbl_client_pool));
+
+  vec_free (trs);
+
+  return (0);
+}
+
+static fib_node_t *
+pbl_client_get_node (fib_node_index_t index)
+{
+  pbl_client_t *pc = pbl_client_get (index);
+  return (&(pc->pc_node));
+}
+
+static pbl_client_t *
+pbl_client_get_from_node (fib_node_t *node)
+{
+  return ((pbl_client_t *) (((char *) node) -
+			    STRUCT_OFFSET_OF (pbl_client_t, pc_node)));
+}
+
+static void
+pbl_client_last_lock_gone (fib_node_t *node)
+{
+ /**/}
+
+ /*
+  * A back walk has reached this ABF policy
+  */
+ static fib_node_back_walk_rc_t
+ pbl_client_back_walk_notify (fib_node_t *node, fib_node_back_walk_ctx_t *ctx)
+ {
+   /*
+    * re-stack the fmask on the n-eos of the via
+    */
+   pbl_client_t *pc = pbl_client_get_from_node (node);
+
+   /* If we have more than FIB_PATH_LIST_POPULAR paths
+    * we might get called during path tracking */
+   if (!(pc->flags & PBL_CLIENT_STACKED))
+     return (FIB_NODE_BACK_WALK_CONTINUE);
+
+   pbl_client_stack (pc);
+
+   return (FIB_NODE_BACK_WALK_CONTINUE);
+ }
+
+ /*
+  * The client's graph node virtual function table
+  */
+ static const fib_node_vft_t pbl_client_vft = {
+   .fnv_get = pbl_client_get_node,
+   .fnv_last_lock = pbl_client_last_lock_gone,
+   .fnv_back_walk = pbl_client_back_walk_notify,
+ };
+
+ static clib_error_t *
+ pbl_client_cli_add_del (vlib_main_t *vm, unformat_input_t *input,
+			 vlib_cli_command_t *cmd)
+ {
+   pbl_client_update_args_t _args = { 0 }, *args = &_args;
+   unformat_input_t _line_input, *line_input = &_line_input;
+   dpo_proto_t payload_proto;
+   fib_route_path_t rpath;
+   clib_error_t *e = 0;
+   u32 port_a, port_b;
+   int is_add = 1, ii;
+   u32 iproto, proto;
+
+   args->pci = INDEX_INVALID;
+   for (ii = 0; ii < PBL_CLIENT_PORT_MAP_N_PROTOS; ii++)
+     {
+       clib_bitmap_alloc (args->port_maps[ii], (1 << 16) - 1);
+       clib_bitmap_zero (args->port_maps[ii]);
+     }
+
+   /* Get a line of input. */
+   if (!unformat_user (input, unformat_line_input, line_input))
+     return 0;
+
+   while (unformat_check_input (line_input) != UNFORMAT_END_OF_INPUT)
+     {
+       if (unformat (line_input, "addr %U", unformat_ip_address, &args->addr))
+	 ;
+       else if (unformat (line_input, "add"))
+	 is_add = 1;
+       else if (unformat (line_input, "del"))
+	 is_add = 0;
+       else if (unformat (line_input, "id %d", &args->pci))
+	 ;
+       else if (unformat (line_input, "table %d", &args->table_id))
+	 ;
+       else if (unformat (line_input, "exclusive"))
+	 args->flags = PBL_FLAG_EXCLUSIVE;
+       else if (unformat (line_input, "via %U", unformat_fib_route_path,
+			  &rpath, &payload_proto))
+	 vec_add1 (args->rpaths, rpath);
+       else if (unformat (line_input, "%U %u-%u", unformat_ip_protocol,
+			  &iproto, &port_a, &port_b))
+	 {
+	   proto = pbl_iproto_to_port_map_proto (iproto);
+	   port_b = clib_max (port_a, port_b);
+	   if (proto < PBL_CLIENT_PORT_MAP_N_PROTOS)
+	     clib_bitmap_set_region (args->port_maps[proto], (u16) port_a, 1,
+				     (u16) (port_b - port_a + 1));
+	 }
+       else if (unformat (line_input, "%U %u", unformat_ip_protocol, &iproto,
+			  &port_a))
+	 {
+	   proto = pbl_iproto_to_port_map_proto (iproto);
+	   if (proto < PBL_CLIENT_PORT_MAP_N_PROTOS)
+	     clib_bitmap_set (args->port_maps[proto], (u16) port_a, 1);
+	 }
+       else
+	 {
+	   e = clib_error_return (0, "unknown input '%U'",
+				  format_unformat_error, line_input);
+	   goto done;
+	 }
+     }
+
+   if (is_add)
+     pbl_client_update (args);
+   else
+     pbl_client_delete (args->pci);
+
+ done:
+   vec_free (args->rpaths);
+   unformat_free (line_input);
+   return (e);
+ }
+
+ VLIB_CLI_COMMAND (pbl_client_cli_add_del_command, static) = {
+   .path = "pbl client",
+   .short_help = "pbl client [add|del] [addr <address>] [via <path>]"
+		 "[[id <id>] [table <table-id>] [exclusive]]",
+   .function = pbl_client_cli_add_del,
+ };
+
+ static clib_error_t *
+ pbl_client_init (vlib_main_t *vm)
+ {
+   pbl_client_dpo =
+     dpo_register_new_type (&pbl_client_dpo_vft, pbl_client_dpo_nodes);
+
+   pbl_fib_source = fib_source_allocate ("pbl", PBL_FIB_SOURCE_PRIORITY,
+					 FIB_SOURCE_BH_SIMPLE);
+
+   pbl_client_fib_node_type =
+     fib_node_register_new_type ("pbl-client", &pbl_client_vft);
+
+   return (NULL);
+ }
+
+ VLIB_INIT_FUNCTION (pbl_client_init);
+
+ VLIB_PLUGIN_REGISTER () = {
+   .version = VPP_BUILD_VER,
+   .description = "Port based balancer (PBL)",
+   .default_disabled = 0,
+ };
+
+ /*
+  * fd.io coding-style-patch-verification: ON
+  *
+  * Local Variables:
+  * eval: (c-set-style "gnu")
+  * End:
+  */
diff --git a/src/plugins/pbl/pbl_client.h b/src/plugins/pbl/pbl_client.h
new file mode 100644
index 000000000..431bdc53b
--- /dev/null
+++ b/src/plugins/pbl/pbl_client.h
@@ -0,0 +1,191 @@
+/*
+ * Copyright (c) 2020 Cisco and/or its affiliates.
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at:
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef __PBL_CLIENT_H__
+#define __PBL_CLIENT_H__
+
+#include <vnet/ip/ip_types.h>
+#include <vnet/fib/fib_node.h>
+
+/* This should be strictly lower than FIB_SOURCE_INTERFACE
+ * from fib_source.h */
+#define PBL_FIB_SOURCE_PRIORITY FIB_SOURCE_SPECIAL
+
+typedef enum pbl_client_port_map_proto_t_
+{
+  PBL_CLIENT_PORT_MAP_TCP,
+  PBL_CLIENT_PORT_MAP_UDP,
+  PBL_CLIENT_PORT_MAP_N_PROTOS,
+  PBL_CLIENT_PORT_MAP_UNKNOWN = 255,
+} pbl_client_port_map_proto_t;
+
+/**
+ * A Translation represents the client of a VEP to one of a set
+ * of real server addresses
+ */
+typedef struct pbl_client_t_
+{
+  CLIB_CACHE_LINE_ALIGN_MARK (cacheline0);
+
+  /* Linkage into the FIB graph */
+  fib_node_t pc_node;
+
+  /**
+   * FIB hook for intercepting traffic
+   */
+
+  /* The address we intercept traffic to */
+  ip_address_t pc_addr;
+
+  /* How to send packets to this client post client */
+  dpo_id_t pc_parent;
+
+  /* the FIB entry this client sources */
+  fib_node_index_t pc_fei;
+
+  /* number of DPO locks */
+  u32 pc_locks;
+
+  /**
+   * Parent pbl_client index if cloned via interpose
+   * or own index if vanilla client.
+   * Used to get clients & update session_refcnt
+   */
+  index_t clone_pci;
+
+  /* Matched ports that will forward to pc_dpo */
+  clib_bitmap_t *pc_port_maps[PBL_CLIENT_PORT_MAP_N_PROTOS];
+
+  /**
+   * Forwarding
+   */
+
+  /* Sibling index on the path-list */
+  u32 pc_sibling;
+
+  /* The DPO actually used for forwarding */
+  dpo_id_t pc_dpo;
+
+  /* The path-list describing how to forward in case of a match */
+  fib_node_index_t pc_pl;
+
+  /* Own index (if copied for trace) */
+  index_t pc_index;
+
+  /* Client flags */
+  u8 flags;
+
+} pbl_client_t;
+
+typedef enum pbl_client_flag_t_
+{
+  /* Has this translation been satcked ?
+   * this allow not being called twice when
+   * with more then FIB_PATH_LIST_POPULAR backends  */
+  PBL_CLIENT_STACKED = (1 << 0),
+} pbl_client_flag_t;
+
+typedef struct pbl_client_update_args_t_
+{
+  index_t pci;
+  ip_address_t addr;
+  clib_bitmap_t *port_maps[PBL_CLIENT_PORT_MAP_N_PROTOS];
+  fib_route_path_t *rpaths;
+  u32 table_id;
+  u8 flags;
+} pbl_client_update_args_t;
+
+extern pbl_client_t *pbl_client_pool;
+
+/**
+ * create or update a client
+ *
+ * @param vip The Virtual Endpoint
+ * @param ip_proto The ip protocol to translate
+ * @param backends the backends to choose from
+ *
+ * @return the ID of the client. used to delete and gather stats
+ */
+extern u32 pbl_client_update (pbl_client_update_args_t *args);
+
+/**
+ * Delete a client
+ *
+ * @param id the ID as returned from the create
+ */
+extern int pbl_client_delete (u32 id);
+
+/**
+ * Callback function invoked during a walk of all clients
+ */
+typedef walk_rc_t (*pbl_client_walk_cb_t) (index_t index, void *ctx);
+
+/**
+ * Walk/visit each of the clients
+ */
+extern void pbl_client_walk (pbl_client_walk_cb_t cb, void *ctx);
+
+/**
+ * Purge all the trahslations
+ */
+extern int pbl_client_purge (void);
+
+static_always_inline pbl_client_port_map_proto_t
+pbl_iproto_to_port_map_proto (ip_protocol_t iproto)
+{
+  switch (iproto)
+    {
+    case IP_PROTOCOL_TCP:
+      return PBL_CLIENT_PORT_MAP_TCP;
+    case IP_PROTOCOL_UDP:
+      return PBL_CLIENT_PORT_MAP_UDP;
+    default:
+      return PBL_CLIENT_PORT_MAP_UNKNOWN;
+    }
+}
+
+/*
+ * Data plane functions
+ */
+
+static_always_inline pbl_client_t *
+pbl_client_get (index_t cti)
+{
+  return (pool_elt_at_index (pbl_client_pool, cti));
+}
+
+static_always_inline pbl_client_t *
+pbl_client_get_if_exists (index_t cti)
+{
+  if (pool_is_free_index (pbl_client_pool, cti))
+    return (NULL);
+  return (pool_elt_at_index (pbl_client_pool, cti));
+}
+
+typedef enum
+{
+  /* IP already present in the FIB, need to interpose dpo */
+  PBL_FLAG_EXCLUSIVE = (1 << 1),
+} pbl_entry_flag_t;
+
+/*
+ * fd.io coding-style-patch-verification: ON
+ *
+ * Local Variables:
+ * eval: (c-set-style "gnu")
+ * End:
+ */
+
+#endif
diff --git a/src/plugins/pbl/pbl_error.def b/src/plugins/pbl/pbl_error.def
new file mode 100644
index 000000000..b135bf03c
--- /dev/null
+++ b/src/plugins/pbl/pbl_error.def
@@ -0,0 +1,16 @@
+/*
+ * Copyright (c) 2021 Cisco and/or its affiliates.
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at:
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+pbl_error (NONE, "no error")
\ No newline at end of file
diff --git a/src/plugins/pbl/pbl_node.c b/src/plugins/pbl/pbl_node.c
new file mode 100644
index 000000000..478584019
--- /dev/null
+++ b/src/plugins/pbl/pbl_node.c
@@ -0,0 +1,183 @@
+/*
+ * Copyright (c) 2020 Cisco and/or its affiliates.
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at:
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include <vlibmemory/api.h>
+#include <vnet/dpo/load_balance.h>
+#include <vnet/dpo/load_balance_map.h>
+
+#include <cnat/cnat_session.h>
+#include <cnat/cnat_client.h>
+#include <cnat/cnat_inline.h>
+#include <cnat/cnat_translation.h>
+
+#include <vnet/ip/ip4_inlines.h>
+#include <vnet/ip/ip6_inlines.h>
+
+#include <pbl/pbl_client.h>
+
+typedef enum pbl_translation_next_t_
+{
+  PBL_NEXT_DROP,
+  PBL_NEXT_LOOKUP,
+  PBL_TRANSLATION_N_NEXT,
+} pbl_translation_next_t;
+
+vlib_node_registration_t pbl_vip_ip4_node;
+vlib_node_registration_t pbl_vip_ip6_node;
+
+typedef struct
+{
+  u8 matched;
+} pbl_trace_t;
+
+static u8 *
+format_pbl_trace (u8 *s, va_list *args)
+{
+  vlib_main_t *__clib_unused vm = va_arg (*args, vlib_main_t *);
+  vlib_node_t *__clib_unused node = va_arg (*args, vlib_node_t *);
+  pbl_trace_t *t = va_arg (*args, pbl_trace_t *);
+  if (t->matched)
+    s = format (s, "matched PBL client");
+  else
+    s = format (s, "no match");
+  return s;
+}
+
+/* CNat sub for NAT behind a fib entry (VIP or interposed real IP) */
+static uword
+pbl_node_inline (vlib_main_t *vm, vlib_node_runtime_t *node,
+		 vlib_frame_t *frame, ip_address_family_t af, u8 do_trace)
+{
+
+  u32 n_left, *from;
+  vlib_buffer_t *bufs[VLIB_FRAME_SIZE];
+  vlib_buffer_t **b = bufs;
+  u16 nexts[VLIB_FRAME_SIZE], *next;
+  pbl_trace_t *t;
+  int matched = 0;
+
+  from = vlib_frame_vector_args (frame);
+  n_left = frame->n_vectors;
+  next = nexts;
+  vlib_get_buffers (vm, from, bufs, n_left);
+
+  while (n_left > 0)
+    {
+      ip4_header_t *ip4 = NULL;
+      ip6_header_t *ip6 = NULL;
+      pbl_client_port_map_proto_t proto;
+      udp_header_t *udp0;
+      pbl_client_t *pc;
+
+      if (AF_IP4 == af)
+	{
+	  ip4 = vlib_buffer_get_current (b[0]);
+	  proto = pbl_iproto_to_port_map_proto (ip4->protocol);
+	  udp0 = (udp_header_t *) (ip4 + 1);
+	}
+      else
+	{
+	  ip6 = vlib_buffer_get_current (b[0]);
+	  proto = pbl_iproto_to_port_map_proto (ip6->protocol);
+	  udp0 = (udp_header_t *) (ip6 + 1);
+	}
+
+      pc = pbl_client_get (vnet_buffer (b[0])->ip.adj_index[VLIB_TX]);
+      if (proto < PBL_CLIENT_PORT_MAP_N_PROTOS &&
+	  clib_bitmap_get (pc->pc_port_maps[proto],
+			   clib_net_to_host_u16 (udp0->dst_port)))
+	{
+	  /* matched */
+	  next[0] = pc->pc_dpo.dpoi_next_node;
+	  vnet_buffer (b[0])->ip.adj_index[VLIB_TX] = pc->pc_dpo.dpoi_index;
+	  matched = 1;
+	  goto trace;
+	}
+
+      /* Dont translate & Follow the fib programming */
+      matched = 0;
+      vnet_buffer (b[0])->ip.adj_index[VLIB_TX] = pc->pc_parent.dpoi_index;
+      next[0] = pc->pc_parent.dpoi_next_node;
+
+    trace:
+
+      if (do_trace)
+	{
+	  t = vlib_add_trace (vm, node, b[0], sizeof (*t));
+	  t->matched = matched;
+	}
+
+      b++;
+      next++;
+      n_left--;
+    }
+
+  vlib_buffer_enqueue_to_next (vm, node, from, nexts, frame->n_vectors);
+
+  return frame->n_vectors;
+}
+
+VLIB_NODE_FN (pbl_vip_ip4_node)
+(vlib_main_t *vm, vlib_node_runtime_t *node, vlib_frame_t *frame)
+{
+  if (PREDICT_FALSE ((node->flags & VLIB_NODE_FLAG_TRACE)))
+    return pbl_node_inline (vm, node, frame, AF_IP4, 1 /* do_trace */);
+  return pbl_node_inline (vm, node, frame, AF_IP4, 0 /* do_trace */);
+}
+
+VLIB_NODE_FN (pbl_vip_ip6_node)
+(vlib_main_t *vm, vlib_node_runtime_t *node, vlib_frame_t *frame)
+{
+  if (PREDICT_FALSE ((node->flags & VLIB_NODE_FLAG_TRACE)))
+    return pbl_node_inline (vm, node, frame, AF_IP6, 1 /* do_trace */);
+  return pbl_node_inline (vm, node, frame, AF_IP6, 0 /* do_trace */);
+}
+
+VLIB_REGISTER_NODE (pbl_vip_ip4_node) =
+{
+  .name = "ip4-pbl-tx",
+  .vector_size = sizeof (u32),
+  .format_trace = format_pbl_trace,
+  .type = VLIB_NODE_TYPE_INTERNAL,
+  .n_errors = 0,
+  .n_next_nodes = PBL_TRANSLATION_N_NEXT,
+  .next_nodes =
+  {
+    [PBL_NEXT_DROP] = "ip4-drop",
+    [PBL_NEXT_LOOKUP] = "ip4-lookup",
+  },
+};
+VLIB_REGISTER_NODE (pbl_vip_ip6_node) =
+{
+  .name = "ip6-pbl-tx",
+  .vector_size = sizeof (u32),
+  .format_trace = format_pbl_trace,
+  .type = VLIB_NODE_TYPE_INTERNAL,
+  .n_errors = 0,
+  .n_next_nodes = PBL_TRANSLATION_N_NEXT,
+  .next_nodes =
+  {
+    [PBL_NEXT_DROP] = "ip6-drop",
+    [PBL_NEXT_LOOKUP] = "ip6-lookup",
+  },
+};
+
+/*
+ * fd.io coding-style-patch-verification: ON
+ *
+ * Local Variables:
+ * eval: (c-set-style "gnu")
+ * End:
+ */
diff --git a/src/plugins/unittest/CMakeLists.txt b/src/plugins/unittest/CMakeLists.txt
index 34e47fa24..10163e952 100644
--- a/src/plugins/unittest/CMakeLists.txt
+++ b/src/plugins/unittest/CMakeLists.txt
@@ -57,6 +57,7 @@ add_vpp_plugin(unittest
   util_test.c
   vlib_test.c
   counter_test.c
+  test_socket.c
 
   COMPONENT
   vpp-plugin-devtools
diff --git a/src/vppinfra/test_socket.c b/src/plugins/unittest/test_socket.c
similarity index 55%
rename from src/vppinfra/test_socket.c
rename to src/plugins/unittest/test_socket.c
index ea0ae6589..6dc17010b 100644
--- a/src/vppinfra/test_socket.c
+++ b/src/plugins/unittest/test_socket.c
@@ -35,98 +35,95 @@
   WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 */
 
+#include <vlib/vlib.h>
 #include <vppinfra/format.h>
 #include <vppinfra/socket.h>
 
-static int verbose;
-#define if_verbose(format,args...) \
-  if (verbose) { clib_warning(format, ## args); }
+typedef struct test_clib_socket_example_msg_t_
+{
+  char b;
+  int a;
+} test_clib_socket_example_msg_t;
 
-int
-test_socket_main (unformat_input_t * input)
+static clib_error_t *
+test_clib_socket_fn (vlib_main_t *vm, unformat_input_t *input,
+		     vlib_cli_command_t *cmd)
 {
-  clib_socket_t _s = { 0 }, *s = &_s;
-  char *config;
-  clib_error_t *error;
+  clib_socket_t _srv = { 0 }, *srv = &_srv;
+  clib_socket_t _cli = { 0 }, *cli = &_cli;
+  clib_socket_t _srv2 = { 0 }, *srv2 = &_srv2;
+  clib_error_t *err = 0;
 
-  s->config = "localhost:22";
-  s->flags = CLIB_SOCKET_F_IS_CLIENT;
+  srv->flags = CLIB_SOCKET_F_IS_SERVER;
+  cli->flags = CLIB_SOCKET_F_IS_CLIENT;
 
   while (unformat_check_input (input) != UNFORMAT_END_OF_INPUT)
     {
-      if (unformat (input, "server %s %=", &config,
-		    &s->flags, CLIB_SOCKET_F_IS_SERVER))
-	;
-      else if (unformat (input, "client %s %=", &config,
-			 &s->flags, CLIB_SOCKET_F_IS_CLIENT))
-	;
+      if (unformat (input, "config %s", &srv->config))
+	cli->config = srv->config;
       else
 	{
-	  error = clib_error_create ("unknown input `%U'\n",
-				     format_unformat_error, input);
+	  err = clib_error_create ("unknown input `%U'\n",
+				   format_unformat_error, input);
 	  goto done;
 	}
     }
 
-  error = clib_socket_init (s);
-  if (error)
-    goto done;
-
-  if (0)
+  if (!srv->config)
     {
-      struct
-      {
-	int a, b;
-      } *msg;
-      msg = clib_socket_tx_add (s, sizeof (msg[0]));
-      msg->a = 99;
-      msg->b = 100;
+      err = clib_error_create ("Missing socket name");
+      goto done;
     }
-  else
-    clib_socket_tx_add_formatted (s, "hello there mr server %d\n", 99);
 
-  error = clib_socket_tx (s);
-  if (error)
+  if ((err = clib_socket_init (srv)))
     goto done;
 
-  while (1)
-    {
-      error = clib_socket_rx (s, 100);
-      if (error)
-	break;
+  if ((err = clib_socket_init (cli)))
+    goto done;
 
-      if (clib_socket_rx_end_of_file (s))
-	break;
+  if ((err = clib_socket_accept (srv, srv2)))
+    goto done;
 
-      if_verbose ("%v", s->rx_buffer);
-      _vec_len (s->rx_buffer) = 0;
-    }
+  test_clib_socket_example_msg_t srv_msg;
+  test_clib_socket_example_msg_t cli_msg;
 
-  error = clib_socket_close (s);
+  srv_msg.a = 54321;
+  srv_msg.b = 'f';
 
-done:
-  if (error)
-    clib_error_report (error);
-  return 0;
-}
+  if ((err = clib_socket_sendmsg (srv2, &srv_msg, sizeof (srv_msg), 0, 0)))
+    goto done;
 
-#ifdef CLIB_UNIX
-int
-main (int argc, char *argv[])
-{
-  unformat_input_t i;
-  int r;
+  if ((err = clib_socket_recvmsg (cli, &cli_msg, sizeof (cli_msg), 0, 0)))
+    goto done;
+
+  if (cli_msg.a != 54321 || cli_msg.b != 'f')
+    {
+      err = clib_error_create ("socket message mismatch");
+      goto done;
+    }
+
+  if ((err = clib_socket_close (srv2)))
+    goto done;
 
-  clib_mem_init (0, 64ULL << 20);
+  if ((err = clib_socket_close (cli)))
+    goto done;
+
+  if ((err = clib_socket_close (srv)))
+    goto done;
 
-  verbose = (argc > 1);
-  unformat_init_command_line (&i, argv);
-  r = test_socket_main (&i);
-  unformat_free (&i);
-  return r;
+  fprintf (stderr, "PASS test_socket %s", srv->config);
+done:
+  return err;
 }
+#ifdef CLIB_UNIX
 #endif
 
+VLIB_CLI_COMMAND (test_clib_socket_command, static) = {
+  .path = "test clib socket",
+  .short_help = "test clib socket",
+  .function = test_clib_socket_fn,
+};
+
 /*
  * fd.io coding-style-patch-verification: ON
  *
diff --git a/src/svm/ssvm.c b/src/svm/ssvm.c
index f93f40d05..305bcd841 100644
--- a/src/svm/ssvm.c
+++ b/src/svm/ssvm.c
@@ -226,8 +226,12 @@ ssvm_server_init_memfd (ssvm_private_t * memfd)
 
   ASSERT (vec_c_string_is_terminated (memfd->name));
 
-  memfd->fd = clib_mem_vm_create_fd (CLIB_MEM_PAGE_SZ_DEFAULT,
-				     (char *) memfd->name);
+   if (memfd->huge_page)
+    memfd->fd = clib_mem_vm_create_fd (CLIB_MEM_PAGE_SZ_DEFAULT_HUGE,
+				       (char *) memfd->name);
+  else
+    memfd->fd =
+      clib_mem_vm_create_fd (CLIB_MEM_PAGE_SZ_DEFAULT, (char *) memfd->name);
 
   if (memfd->fd == CLIB_MEM_ERROR)
     {
@@ -269,7 +273,8 @@ ssvm_server_init_memfd (ssvm_private_t * memfd)
   sh->ssvm_va = pointer_to_uword (sh);
   sh->type = SSVM_SEGMENT_MEMFD;
 
-  page_size = 1ULL << log2_page_size;
+//   page_size = 1ULL << log2_page_size;
+  page_size = clib_mem_get_page_size ();
   sh->heap = clib_mem_create_heap (((u8 *) sh) + page_size,
 				   memfd->ssvm_size - page_size,
 				   1 /* locked */ , "ssvm server memfd");
diff --git a/src/svm/ssvm.h b/src/svm/ssvm.h
index 9bd16a9b4..ef982a1b3 100644
--- a/src/svm/ssvm.h
+++ b/src/svm/ssvm.h
@@ -87,7 +87,7 @@ typedef struct
   u8 *name;
   u8 numa;			/**< UNUSED: numa requested at alloc time */
   int is_server;
-
+  int huge_page;
   union
   {
     int fd;			/**< memfd segments */
diff --git a/src/svm/svm_fifo.c b/src/svm/svm_fifo.c
index 2150694ef..c0154ef86 100644
--- a/src/svm/svm_fifo.c
+++ b/src/svm/svm_fifo.c
@@ -84,6 +84,9 @@ CLIB_MARCH_FN (svm_fifo_copy_from_chunk, void, svm_fifo_t *f,
   else
     {
       clib_memcpy_fast (dst, &c->data[head_idx], len);
+      // printf ("software copy from %p to %p len %d\n", &c->data[head_idx],
+      // dst,
+      //	      len);
     }
 }
 
@@ -1170,7 +1173,7 @@ svm_fifo_dequeue_drop (svm_fifo_t * f, u32 len)
   u32 total_drop_bytes, tail, head, cursize;
 
   f_load_head_tail_cons (f, &head, &tail);
-
+  // printf("svm_fifo_dequeue_drop fifo head is %d tail %d\n", head, tail);
   /* number of bytes available */
   cursize = f_cursize (f, head, tail);
   if (PREDICT_FALSE (cursize == 0))
@@ -1195,7 +1198,7 @@ svm_fifo_dequeue_drop (svm_fifo_t * f, u32 len)
 
   /* store-rel: consumer owned index (paired with load-acq in producer) */
   clib_atomic_store_rel_n (&f->shr->head, head);
-
+  // printf("clib_atomic_store_rel_n fifo head is %d\n", head);
   return total_drop_bytes;
 }
 
@@ -1288,7 +1291,7 @@ svm_fifo_segments (svm_fifo_t * f, u32 offset, svm_fifo_seg_t * fs,
   svm_fifo_chunk_t *c;
 
   f_load_head_tail_cons (f, &head, &tail);
-
+  // printf("fifo head is %d tail %d\n", head, tail);
   /* consumer function, cursize can only increase while we're working */
   cursize = f_cursize (f, head, tail);
 
diff --git a/src/vcl/vcl_bapi.c b/src/vcl/vcl_bapi.c
index bb2b94f04..dd8d6cca4 100644
--- a/src/vcl/vcl_bapi.c
+++ b/src/vcl/vcl_bapi.c
@@ -170,6 +170,7 @@ vl_api_app_worker_add_del_reply_t_handler (vl_api_app_worker_add_del_reply_t *
 
   vcl_set_worker_index (wrk_index);
   wrk->vpp_wrk_index = clib_net_to_host_u32 (mp->wrk_index);
+  printf("vl_api_app_worker_add_del reply self worker index %d vpp worker index %d\n",wrk_index, wrk->vpp_wrk_index );
   wrk->ctrl_mq = vcm->ctrl_mq;
 
   segment_handle = clib_net_to_host_u64 (mp->segment_handle);
@@ -366,6 +367,7 @@ vcl_bapi_send_attach (void)
     vcm->cfg.preallocated_fifo_pairs;
   bmp->options[APP_OPTIONS_EVT_QUEUE_SIZE] = vcm->cfg.event_queue_size;
   bmp->options[APP_OPTIONS_TLS_ENGINE] = tls_engine;
+  bmp->options[APP_OPTIONS_SEGMENT_PROPS] = vcm->cfg.huge_page;
   if (nsid_len)
     {
       vl_api_vec_to_api_string (vcm->cfg.namespace_id, &bmp->namespace_id);
@@ -404,7 +406,7 @@ vcl_bapi_send_app_worker_add_del (u8 is_add)
   mp->is_add = is_add;
   if (!is_add)
     mp->wrk_index = clib_host_to_net_u32 (wrk->vpp_wrk_index);
-
+  printf("add new app worker index %d remote index %d\n", wrk->wrk_index, wrk->vpp_wrk_index);
   vl_msg_api_send_shmem (wrk->vl_input_queue, (u8 *) & mp);
 }
 
diff --git a/src/vcl/vcl_cfg.c b/src/vcl/vcl_cfg.c
index 2ac9eddb6..291245ba4 100644
--- a/src/vcl/vcl_cfg.c
+++ b/src/vcl/vcl_cfg.c
@@ -416,6 +416,12 @@ vppcom_cfg_read_file (char *conf_fname)
 	      VCFG_DBG (0, "VCL<%d>: configured app_scope_global (%d)",
 			getpid (), vcl_cfg->app_scope_global);
 	    }
+	  else if (unformat (line_input, "huge_page"))
+	    {
+	      vcl_cfg->huge_page = 1;
+	      VCFG_DBG (0, "VCL<%d>: configured huge_page (%d)",
+			getpid (), vcl_cfg->huge_page);
+	    }
 	  else if (unformat (line_input, "namespace-secret %lu",
 			     &vcl_cfg->namespace_secret))
 	    {
@@ -577,6 +583,13 @@ vppcom_cfg (vppcom_cfg_t * vcl_cfg)
 		VPPCOM_ENV_APP_SCOPE_GLOBAL "!", getpid (),
 		vcm->cfg.app_scope_global);
     }
+  if (getenv (VPPCOM_ENV_HUGE_PAGE))
+    {
+      vcm->cfg.huge_page = 1;
+      VCFG_DBG (0, "VCL<%d>: configured app huge page (%u) from "
+		VPPCOM_ENV_HUGE_PAGE "!", getpid (),
+		vcm->cfg.huge_page);
+    }
   env_var_str = getenv (VPPCOM_ENV_VPP_API_SOCKET);
   if (env_var_str)
     {
diff --git a/src/vcl/vcl_private.h b/src/vcl/vcl_private.h
index f163de201..70906bbcb 100644
--- a/src/vcl/vcl_private.h
+++ b/src/vcl/vcl_private.h
@@ -202,6 +202,7 @@ typedef struct vppcom_cfg_t_
   u8 *vpp_bapi_socket_name;	/**< bapi socket transport socket name */
   u32 tls_engine;
   u8 mt_wrk_supported;
+  u8 huge_page;
 } vppcom_cfg_t;
 
 void vppcom_cfg (vppcom_cfg_t * vcl_cfg);
diff --git a/src/vcl/vcl_sapi.c b/src/vcl/vcl_sapi.c
index 981257ede..f1119325c 100644
--- a/src/vcl/vcl_sapi.c
+++ b/src/vcl/vcl_sapi.c
@@ -137,6 +137,7 @@ vcl_api_send_attach (clib_socket_t * cs)
     vcm->cfg.preallocated_fifo_pairs;
   mp->options[APP_OPTIONS_EVT_QUEUE_SIZE] = vcm->cfg.event_queue_size;
   mp->options[APP_OPTIONS_TLS_ENGINE] = tls_engine;
+  mp->options[APP_OPTIONS_SEGMENT_PROPS] = vcm->cfg.huge_page;
 
   msg.type = APP_SAPI_MSG_TYPE_ATTACH;
   err = clib_socket_sendmsg (cs, &msg, sizeof (msg), 0, 0);
diff --git a/src/vcl/vppcom.h b/src/vcl/vppcom.h
index 46517ad8c..958760f42 100644
--- a/src/vcl/vppcom.h
+++ b/src/vcl/vppcom.h
@@ -42,6 +42,7 @@ extern "C"
 #define VPPCOM_ENV_APP_NAMESPACE_SECRET      	"VCL_APP_NAMESPACE_SECRET"
 #define VPPCOM_ENV_APP_SCOPE_LOCAL           	"VCL_APP_SCOPE_LOCAL"
 #define VPPCOM_ENV_APP_SCOPE_GLOBAL          	"VCL_APP_SCOPE_GLOBAL"
+#define VPPCOM_ENV_HUGE_PAGE              	"VCL_HUGE_PAGE"
 #define VPPCOM_ENV_VPP_API_SOCKET           	"VCL_VPP_API_SOCKET"
 #define VPPCOM_ENV_VPP_SAPI_SOCKET		"VCL_VPP_SAPI_SOCKET"
 
diff --git a/src/vlib/CMakeLists.txt b/src/vlib/CMakeLists.txt
index a74c8cefb..13ac2bb1e 100644
--- a/src/vlib/CMakeLists.txt
+++ b/src/vlib/CMakeLists.txt
@@ -99,6 +99,8 @@ add_vpp_library(vlib
   unix/util.c
   vmbus/vmbus.c
   ${VMBUS_SOURCE}
+  dma/dma.c
+  dma/cli.c
 
   MULTIARCH_SOURCES
   buffer_funcs.c
diff --git a/src/vlib/buffer.c b/src/vlib/buffer.c
index 7a70a8abd..c6782052e 100644
--- a/src/vlib/buffer.c
+++ b/src/vlib/buffer.c
@@ -797,6 +797,20 @@ buffer_get_by_index (vlib_buffer_main_t * bm, u32 index)
   return bp;
 }
 
+void
+get_buffers_stats (buffers_stats_t *bs, u32 index)
+{
+  vlib_main_t *vm = vlib_get_main ();
+  vlib_buffer_pool_t *bp =
+    buffer_get_by_index (vm->buffer_main, clib_net_to_host_u32 (index));
+  if (!bp)
+    return;
+  bs->available_buffers = htonl (bp->n_avail);
+  bs->cached_buffers = htonl (buffer_get_cached (bp));
+  bs->used_buffers =
+    htonl (bp->n_buffers - bp->n_avail - buffer_get_cached (bp));
+}
+
 static void
 buffer_gauges_update_used_fn (stat_segment_directory_entry_t * e, u32 index)
 {
diff --git a/src/vlib/buffer.h b/src/vlib/buffer.h
index b548adf4b..043c8c6ea 100644
--- a/src/vlib/buffer.h
+++ b/src/vlib/buffer.h
@@ -440,6 +440,15 @@ struct vlib_main_t;
 
 #define VLIB_BUFFER_POOL_PER_THREAD_CACHE_SZ 512
 
+typedef struct
+{
+  u32 available_buffers;
+  u32 cached_buffers;
+  u32 used_buffers;
+} buffers_stats_t;
+
+void get_buffers_stats (buffers_stats_t *bs, u32 index);
+
 typedef struct
 {
   CLIB_CACHE_LINE_ALIGN_MARK (cacheline0);
diff --git a/src/vlib/dma/cli.c b/src/vlib/dma/cli.c
new file mode 100644
index 000000000..6e6d975c9
--- /dev/null
+++ b/src/vlib/dma/cli.c
@@ -0,0 +1,168 @@
+/* SPDX-License-Identifier: Apache-2.0
+ * Copyright (c) 2022 Cisco Systems, Inc.
+ */
+
+#include <vlib/vlib.h>
+#include <vlib/physmem_funcs.h>
+#include <vlib/dma/dma.h>
+
+static clib_error_t *
+show_dma_backends_command_fn (vlib_main_t *vm, unformat_input_t *input,
+			      vlib_cli_command_t *cmd)
+{
+  vlib_dma_main_t *dm = &vlib_dma_main;
+
+  if (vec_len (dm->backends))
+    {
+      vlib_dma_backend_t *b;
+      vec_foreach (b, dm->backends)
+	vlib_cli_output (vm, "%s", b->name);
+    }
+  else
+    vlib_cli_output (vm, "No active DMA backends");
+
+  return 0;
+}
+
+VLIB_CLI_COMMAND (avf_create_command, static) = {
+  .path = "show dma backends",
+  .short_help = "show dma backends",
+  .function = show_dma_backends_command_fn,
+};
+
+static void
+test_dma_cb_fn (vlib_main_t *vm, vlib_dma_batch_t *b)
+{
+  fformat (stderr, "%s: cb %p cookie %lx\n", __func__, b,
+	   vlib_dma_batch_get_cookie (vm, b));
+}
+
+static clib_error_t *
+fill_random_data (void *buffer, uword size)
+{
+  uword seed = random_default_seed ();
+
+  uword remain = size;
+  const uword p = clib_mem_get_page_size ();
+  uword offset = 0;
+
+  clib_random_buffer_t rb;
+  clib_random_buffer_init (&rb, seed);
+
+  while (remain > 0)
+    {
+      uword fill_size = clib_min (p, remain);
+
+      clib_random_buffer_fill (&rb, fill_size);
+      void *rbuf = clib_random_buffer_get_data (&rb, fill_size);
+      clib_memcpy_fast (buffer + offset, rbuf, fill_size);
+      clib_random_buffer_free (&rb);
+
+      offset += fill_size;
+      remain -= fill_size;
+    }
+
+  return 0;
+}
+
+static clib_error_t *
+test_dma_command_fn (vlib_main_t *vm, unformat_input_t *input,
+		     vlib_cli_command_t *cmd)
+{
+  clib_error_t *err = 0;
+  vlib_dma_batch_t *b;
+  int config_index = -1;
+  u32 rsz, n_alloc, v;
+  u8 *from = 0, *to = 0;
+  vlib_dma_config_t cfg = { .max_transfers = 16,
+			    .max_transfer_size = 512,
+			    .callback_fn = test_dma_cb_fn };
+
+  while (unformat_check_input (input) != UNFORMAT_END_OF_INPUT)
+    {
+      if (unformat (input, "transfers %u", &v))
+	cfg.max_transfers = v;
+      else if (unformat (input, "size %u", &v))
+	cfg.max_transfer_size = v;
+      else
+	return clib_error_return (0, "unknown input `%U'",
+				  format_unformat_error, input);
+    }
+
+  if ((config_index = vlib_dma_config_add (vm, &cfg)) < 0)
+    {
+      err = clib_error_return (0, "Unable to allocate dma config");
+      goto done;
+    }
+
+  rsz = round_pow2 (cfg.max_transfer_size, CLIB_CACHE_LINE_BYTES);
+  n_alloc = rsz * cfg.max_transfers * 2;
+
+  if ((from = vlib_physmem_alloc_aligned_on_numa (vm, n_alloc,
+  	CLIB_CACHE_LINE_BYTES, vm->numa_node)) == 0)    {
+      err = clib_error_return (0, "Unable to allocate %u bytes of physmem",
+			       n_alloc);
+      goto done;
+    }
+  to = from + n_alloc / 2;
+
+  u32 port_allocator_seed;
+
+  for (int loop = 0; loop < 1000; loop ++)
+  {
+    fill_random_data (from, cfg.max_transfers * rsz);
+
+    b = vlib_dma_batch_new (vm, config_index);
+    vlib_dma_batch_set_cookie (vm, b, 0x12345678);
+
+    port_allocator_seed = clib_cpu_time_now ();
+    int transfers = random_u32 (&port_allocator_seed) % cfg.max_transfers;
+    if (!transfers)
+	transfers = 1;
+    for (int i = 0; i < transfers; i++)
+      vlib_dma_batch_add (vm, b, to + i * rsz, from + i * rsz,
+			cfg.max_transfer_size);
+
+    vlib_dma_batch_submit (vm, b);
+    while (!vlib_dma_batch_completed (vm, b));
+  }
+done:
+  if (config_index != -1)
+    vlib_dma_config_del (vm, config_index);
+  if (from)
+    vlib_physmem_free (vm, from);
+  return err;
+}
+
+static clib_error_t *
+test_show_dma_fn (vlib_main_t *vm, unformat_input_t *input,
+		     vlib_cli_command_t *cmd)
+{
+  clib_error_t *err = 0;
+  int config_index = 0;
+  while (unformat_check_input (input) != UNFORMAT_END_OF_INPUT)
+    {
+       if (unformat (input, "config %u", &config_index))
+        ;
+       else
+       	return clib_error_return (0, "unknown input `%U'",
+				  format_unformat_error, input);
+    }
+
+  for (u32 i = 0; i < vlib_get_n_threads (); i++)
+    vlib_cli_output (vm, "Config %d %U", config_index, vlib_dma_config_info,
+  			  config_index, vlib_get_main_by_index (i));
+  return err;
+}
+
+VLIB_CLI_COMMAND (test_dma_command, static) = {
+  .path = "test dma",
+  .short_help = "test dma [transfers <x> size <x>]",
+  .function = test_dma_command_fn,
+};
+
+VLIB_CLI_COMMAND (show_dma_command, static) = {
+  .path = "show dma",
+  .short_help = "show dma [config <x>]",
+  .function = test_show_dma_fn,
+};
\ No newline at end of file
diff --git a/src/vlib/dma/cli_bk.c b/src/vlib/dma/cli_bk.c
new file mode 100644
index 000000000..9726c3793
--- /dev/null
+++ b/src/vlib/dma/cli_bk.c
@@ -0,0 +1,356 @@
+/* SPDX-License-Identifier: Apache-2.0
+ * Copyright (c) 2022 Cisco Systems, Inc.
+ * Copyright (c) 2022 Intel and/or its affiliates.
+ */
+#include <sys/types.h>
+#include <sys/stat.h>
+#include <fcntl.h>
+#include <vlib/vlib.h>
+#include <vlib/threads.h>
+#include <vlib/dma/dma.h>
+
+/**
+ * Format DMA backend as per the following format
+ *
+ * verbose:
+ *   "NAME", "Sock", "Transfers", "Transfer Size", "Instance"
+ *   "Assigned thread", "Service configs",
+ *   "Capability"
+ * non-verbose:
+ *   "NAME", "Sock", "Transfers", "Transfer Size", "Instance"
+ */
+u8 *
+format_dma_cap (u8 *s, va_list *args)
+{
+  vlib_dma_cap_t *cap = va_arg (*args, vlib_dma_cap_t *);
+  s =
+    format (s, "Capabilites: %s %s ", cap->dma_cap & DMA_CAPA_SVA ? "SVA" : "",
+	    cap->dma_cap & DMA_CAPA_SCATTER_GATHER ? "| SCATTER_GATHER" : "");
+  s = format (s, "transfer: %d size: %d ordered: %s\n", cap->max_transfers,
+	      cap->max_transfer_size, cap->ordered ? "true" : "false");
+  return s;
+}
+
+u8 *
+format_backend (u8 *s, va_list *args)
+{
+  vlib_dma_backend_t *backend = va_arg (*args, vlib_dma_backend_t *);
+  int verbose = va_arg (*args, int);
+
+  s = format (s, "\n%-12s%-12s%-12s%-12s%-16s%-16s", "NAME", "ID", "Sock", "Transfers",
+	      "Transfer Size", "Instance");
+  s = format (s, "\n%-12s%-12d%-12d%-12d%-16d%-16p\n", backend->name,
+	      backend - vlib_dma_main.backends , backend->cap.numa_node,
+	      backend->cap.max_transfers, backend->cap.max_transfer_size,
+	      backend->instance);
+
+  if (verbose)
+    {
+      if (backend->state == DMA_BACKEND_ASSIGNED)
+	{
+	  s =
+	    format (s, "\n\t    Assigned to thread %d", backend->thread_index);
+	  s =
+	    format (s, "\n\t    Consumed by %d configs", backend->attached_num);	    
+	}
+      else
+	s = format (s, "\n\t    Unassigned");
+      s = format (s, "\n\t    %U", format_dma_cap, &backend->cap);
+    }
+
+  return s;
+}
+
+u8 *
+format_config_stats (u8 *s, va_list *args)
+{
+  vlib_dma_config_t *config = va_arg (*args, vlib_dma_config_t *);
+  s = format (s, "%-12d%-16ld%-12d%-16ld\n", config->n_transfers,
+	      config->n_bytes, config->cpu_transfers, config->cpu_bytes);
+  return s;
+}
+
+/**
+ * Format DMA config info as per the following format
+ *
+ * verbose:
+ *   "Configs"
+ *        "ID", "Backend ID", "Data Addr", "Results Addr"
+ *        "Template", "stride", "src_offset", "dst_offset", "size_offset"
+ *        "Transfers", "Bytes"
+ * non-verbose:
+ *   "Thread", "Configs"
+ */
+u8 *
+format_config (u8 *s, va_list *args)
+{
+  vlib_dma_config_t *config = va_arg (*args, vlib_dma_config_t *);
+  int verbose = va_arg (*args, int);
+  u32 config_index = config - vlib_dma_main.configs;
+
+  s = format (s, "%-12s%-12s%-24s%-24s\n", "ID", "Backend ID",
+                 "Data Addr", "Results Addr");
+  s = format (s, "%-12d%-12d%-24p%-24p\n", vlib_dma_main.configs - config,
+  		  config->backend_index, config->backend_data,
+		  config->result_data);
+
+  s = format (s, "%-12s%-12s%-12s%-12s%-12s\n", "Template", "stride",
+		 "src_offset", "dst_offset", "size_offset");
+  s = format (s, "%-12s%-12d%-12d%-12d%-12d\n", "", config->template.stride,
+		 config->template.src_ptr_offset,
+		 config->template.dst_ptr_offset,
+		 config->template.size_offset);
+  s = format (s, "%-12s%-16s%-12s%-16s\n", "Transfers", "Bytes",
+	      "CPU transfers", "CPU Bytes");
+  s = format (s, "%U\n", format_config_stats, config);
+  if (verbose)
+      s = vlib_dma_dump_info (config_index, s);
+
+  return s;
+}
+
+static void
+dma_cli_show_all_backends (vlib_main_t *vm, int verbose)
+{
+  vlib_dma_main_t *dm = &vlib_dma_main;
+  vlib_dma_backend_t *backend;
+  if (!vec_len (dm->backends))
+    {
+      vlib_cli_output (vm, "No DMA engine registered");
+      return;
+    }
+
+  vec_foreach (backend, dm->backends)
+    {
+      vlib_cli_output (vm, "%U", format_backend, backend, verbose);
+    }
+  return;
+}
+
+static void
+dma_cli_show_all_configs (vlib_main_t *vm, int verbose)
+{
+  vlib_dma_main_t *dm = &vlib_dma_main;
+  vlib_dma_config_t *config;
+  if (!vec_len (dm->configs))
+    {
+      vlib_cli_output (vm, "No config registered");
+      return;
+    }
+
+  vec_foreach (config, dm->configs)
+    {
+      vlib_cli_output (vm, "%U", format_config, config, verbose);
+    }
+
+  return;
+}
+
+static clib_error_t *
+show_dma_command_fn (vlib_main_t *vm, unformat_input_t *input,
+		     vlib_cli_command_t *cmd)
+{
+  unformat_input_t _line_input, *line_input = &_line_input;
+  clib_error_t *error = 0;
+  int verbose = 0, backends = 0, configs = 0;
+
+  if (!unformat_user (input, unformat_line_input, line_input))
+    {
+      dma_cli_show_all_backends (vm, 0);
+      dma_cli_show_all_configs (vm, 0);
+      return 0;
+    }
+  while (unformat_check_input (line_input) != UNFORMAT_END_OF_INPUT)
+    {
+      if (unformat (line_input, "verbose %d", &verbose))
+	;
+      else if (unformat (line_input, "verbose"))
+	verbose = 1;
+      else if (unformat (line_input, "backends"))
+	backends = 1;
+      else if (unformat (line_input, "configs"))
+	configs = 1;
+      else
+	{
+	  error = clib_error_return (0, "unknown input `%U'",
+				     format_unformat_error, line_input);
+	  goto done;
+	}
+    }
+
+  if (backends)
+    dma_cli_show_all_backends (vm, verbose);
+  if (configs)
+    dma_cli_show_all_configs (vm, verbose);
+
+done:
+  unformat_free (line_input);
+  return error;
+}
+
+VLIB_CLI_COMMAND (vlib_cli_show_dma_command) = {
+  .path = "show dma",
+  .short_help = "show dma [backends] [configs] [verbose [n]]",
+  .function = show_dma_command_fn,
+};
+
+void
+fill_random_data (void *buffer, uword size, uword transfers)
+{
+  uword loop = transfers;
+  uword seed = random_default_seed ();
+  uword offset = 0;
+
+  clib_random_buffer_t rb;
+  clib_random_buffer_init (&rb, seed);
+
+  while (loop > 0)
+    {
+      clib_random_buffer_fill (&rb, size);
+      void *rbuf = clib_random_buffer_get_data (&rb, size);
+      clib_memcpy_fast (buffer + offset, rbuf, size);
+      clib_random_buffer_free (&rb);
+
+      offset += size;
+      loop--;
+    }
+
+  return;
+}
+
+static void
+dma_benchmark_result (vlib_main_t *vm, u32 size, u32 transfers, u64 elapsed)
+{
+  vlib_cli_output (vm, "%-24s%-24s%-24s%-24s", "Copy length(B)",
+		   "Throughput(Mb/s)", "IOPS", "Latency(ns)");
+  uword total_size = size * transfers;
+  double throughput = total_size * (1e6) / (1 << 20) * (1e3) / elapsed * 8;
+  double iops = 1e9 * transfers / elapsed;
+  double latency = 1.0 * elapsed / transfers;
+  vlib_cli_output (vm, "\n%-24d%-24.2f%-24.2f%-24.2f", size, throughput, iops,
+		   latency);
+}
+
+static int config_index = -1;
+#define TRANSFER_BATCH_SIZE 256
+static clib_error_t *
+test_dma (vlib_main_t * vm, unformat_input_t * input,
+	   vlib_cli_command_t * cmd_arg)
+{
+  u32 transfers = 256, size = 4096, cnt, remains, cookie;
+  unformat_input_t _line_input, *line_input = &_line_input;
+  clib_error_t *error = 0;
+  vlib_dma_config_args_t args;
+  vlib_dma_completion_cb_fn_t cb = NULL;
+  int i;
+  uword offset = 0;
+  u64 elapsed;
+  void *src = 0, *dst = 0;
+
+  if (!unformat_user (input, unformat_line_input, line_input))
+    return 0;
+
+  while (unformat_check_input (line_input) != UNFORMAT_END_OF_INPUT)
+    {
+      if (unformat (line_input, "num-transfers %d", &transfers))
+	;
+      else if (unformat (line_input, "transfer-size %d", &size))
+	;
+      else
+	{
+	  error = clib_error_return (0, "unknown input `%U'",
+				     format_unformat_error, line_input);
+	  goto done;
+	}
+    }
+
+  remains = transfers;
+  args.max_transfers = 2;
+  args.max_transfer_size = TRANSFER_BATCH_SIZE;
+  args.cpu_fallback = 0;
+  args.barrier_before_last = 0;
+  args.cb = cb;
+  if (config_index < 0)
+    config_index = vlib_dma_config (vm, &args);
+  if (config_index < 0)
+    {
+      error = clib_error_return (0, "No config suitable for test");
+      goto done;
+    }
+
+  /* prepare two hugepages */
+  uword log2_page_size = clib_mem_get_log2_default_hugepage_size ();
+  uword page_size = 1 << log2_page_size;
+  ASSERT (page_size >= (uword) size * transfers);
+
+  src = clib_mem_vm_map (0, page_size, log2_page_size, "Source");
+  if (src == CLIB_MEM_VM_MAP_FAILED)
+    goto done;
+  dst = clib_mem_vm_map (0, page_size, log2_page_size, "Destination");
+  if (dst == CLIB_MEM_VM_MAP_FAILED)
+    goto done;
+
+  fill_random_data (src, size, transfers);
+  fill_random_data (dst, size, transfers);
+
+  vlib_dma_transfer_t dma_transfers[TRANSFER_BATCH_SIZE];
+  u64 start_time, end_time;
+  start_time = unix_time_now_nsec ();
+
+  do
+    {
+      cnt = clib_min (remains, TRANSFER_BATCH_SIZE);
+      for (i = 0; i < cnt; i++)
+	{
+	  dma_transfers[i].dst = (u8 *) (dst + offset);
+	  dma_transfers[i].src = (u8 *) (src + offset);
+	  dma_transfers[i].size = size;
+	  offset += i * size;
+	}
+      remains -= cnt;
+      if (vlib_dma_transfer (vm, config_index, dma_transfers, cnt, 0))
+	{
+	  error =
+	    clib_error_return (0, "DMA node failed to initiate transfer");
+	  goto done;
+	}
+
+      while (!vlib_dma_get_completed (vm, config_index, &cb, &cookie))
+	;
+    }
+  while (remains);
+
+  end_time = unix_time_now_nsec ();
+  elapsed = end_time - start_time;
+
+  if (clib_memcmp (dst, src, size * transfers))
+    {
+      clib_error_return (0, "DMA transfer check failed");
+      goto done;
+    }
+  dma_benchmark_result (vm, size, transfers, elapsed);
+
+  vlib_cli_output (vm, "\nCPU reference");
+  start_time = unix_time_now_nsec ();
+  for (int i = 0; i != transfers; ++i)
+    {
+      uword offset = (uword) size * i;
+      clib_memcpy_fast (dst + offset, src + offset, size);
+    }
+
+  end_time = unix_time_now_nsec ();
+  elapsed = end_time - start_time;
+  dma_benchmark_result (vm, size, transfers, end_time - start_time);
+
+done:
+  clib_mem_vm_unmap (src);
+  clib_mem_vm_unmap (dst);
+  unformat_free (line_input);
+  return error;
+}
+
+VLIB_CLI_COMMAND (test_dma_command, static) = {
+    .path = "test dma",
+    .short_help = "test dma [num-transfers <n>] [transfer-size <n>]",
+    .function = test_dma,
+};
diff --git a/src/vlib/dma/cli_ref.c b/src/vlib/dma/cli_ref.c
new file mode 100644
index 000000000..473668fcb
--- /dev/null
+++ b/src/vlib/dma/cli_ref.c
@@ -0,0 +1,333 @@
+/* SPDX-License-Identifier: Apache-2.0
+ * Copyright (c) 2022 Cisco Systems, Inc.
+ * Copyright (c) 2022 Intel and/or its affiliates.
+ */
+#include <sys/types.h>
+#include <sys/stat.h>
+#include <fcntl.h>
+#include <vlib/vlib.h>
+#include <vlib/threads.h>
+#include <vlib/dma/dma.h>
+
+/**
+ * Format DMA backend as per the following format
+ *
+ * verbose:
+ *   "NAME", "Sock", "Transfers", "Transfer Size", "Instance"
+ *   "Assigned thread", "Service configs",
+ *   "Capability"
+ * non-verbose:
+ *   "NAME", "Sock", "Transfers", "Transfer Size", "Instance"
+ */
+u8 *
+format_dma_cap (u8 *s, va_list *args)
+{
+  vlib_dma_cap_t *cap = va_arg (*args, vlib_dma_cap_t *);
+  s =
+    format (s, "Capabilites: %s %s ", cap->dma_cap & DMA_CAPA_SVA ? "SVA" : "",
+	    cap->dma_cap & DMA_CAPA_SCATTER_GATHER ? "| SCATTER_GATHER" : "");
+  s = format (s, "transfer: %d size: %d ordered: %s\n", cap->max_transfers,
+	      cap->max_transfer_size, cap->ordered ? "true" : "false");
+  return s;
+}
+
+u8 *
+format_backend (u8 *s, va_list *args)
+{
+  vlib_dma_backend_t *backend = va_arg (*args, vlib_dma_backend_t *);
+  int verbose = va_arg (*args, int);
+
+  s = format (s, "\n%-12s%-12s%-12s%-12s%-16s%-16s", "NAME", "ID", "Sock", "Transfers",
+	      "Transfer Size", "Instance");
+  s = format (s, "\n%-12s%-12d%-12d%-12d%-16d%-16p\n", backend->name,
+	      backend - vlib_dma_main.backends , backend->cap.numa_node,
+	      backend->cap.max_transfers, backend->cap.max_transfer_size,
+	      backend->instance);
+
+  if (verbose)
+    {
+      if (backend->state == DMA_BACKEND_ASSIGNED)
+	{
+	  s =
+	    format (s, "\n\t    Assigned to thread %d", backend->thread_index);
+	  s =
+	    format (s, "\n\t    Consumed by %d configs", backend->attached_num);	    
+	}
+      else
+	s = format (s, "\n\t    Unassigned");
+      s = format (s, "\n\t    %U", format_dma_cap, &backend->cap);
+    }
+
+  return s;
+}
+
+u8 *
+format_config_stats (u8 *s, va_list *args)
+{
+  vlib_dma_config_t *config = va_arg (*args, vlib_dma_config_t *);
+  s = format (s, "%-12d%-16ld%-12d%-16ld\n", config->n_transfers,
+	      config->n_bytes, config->cpu_transfers, config->cpu_bytes);
+  return s;
+}
+
+/**
+ * Format DMA config info as per the following format
+ *
+ * verbose:
+ *   "Configs"
+ *        "ID", "Backend ID", "Data Addr", "Results Addr"
+ *        "Template", "stride", "src_offset", "dst_offset", "size_offset"
+ *        "Transfers", "Bytes"
+ * non-verbose:
+ *   "Thread", "Configs"
+ */
+u8 *
+format_config (u8 *s, va_list *args)
+{
+  vlib_dma_config_t *config = va_arg (*args, vlib_dma_config_t *);
+  int verbose = va_arg (*args, int);
+  u32 config_index = config - vlib_dma_main.configs;
+
+  s = format (s, "%-12s%-12s%-24s%-24s\n", "ID", "Backend ID",
+                 "Data Addr", "Results Addr");
+  s = format (s, "%-12d%-12d%-24p%-24p\n", vlib_dma_main.configs - config,
+  		  config->backend_index, config->backend_data,
+		  config->result_data);
+
+  s = format (s, "%-12s%-12s%-12s%-12s%-12s\n", "Template", "stride",
+		 "src_offset", "dst_offset", "size_offset");
+  s = format (s, "%-12s%-12d%-12d%-12d%-12d\n", "", config->template.stride,
+		 config->template.src_ptr_offset,
+		 config->template.dst_ptr_offset,
+		 config->template.size_offset);
+  s = format (s, "%-12s%-16s%-12s%-16s\n", "Transfers", "Bytes",
+	      "CPU transfers", "CPU Bytes");
+  s = format (s, "%U\n", format_config_stats, config);
+  if (verbose)
+      s = vlib_dma_dump_info (config_index, s);
+
+  return s;
+}
+
+
+static void
+dma_cli_show_all_backends (vlib_main_t *vm, int verbose)
+{
+  vlib_dma_main_t *dm = &vlib_dma_main;
+  vlib_dma_backend_t *backend;
+  if (!vec_len (dm->backends))
+    {
+      vlib_cli_output (vm, "No DMA engine registered");
+      return;
+    }
+
+  vec_foreach (backend, dm->backends)
+    {
+      vlib_cli_output (vm, "%U", format_backend, backend, verbose);
+    }
+  return;
+}
+
+static void
+dma_cli_show_all_configs (vlib_main_t *vm, int verbose)
+{
+  vlib_dma_main_t *dm = &vlib_dma_main;
+  vlib_dma_config_t *config;
+  if (!vec_len (dm->configs))
+    {
+      vlib_cli_output (vm, "No config registered");
+      return;
+    }
+
+  vec_foreach (config, dm->configs)
+    {
+      vlib_cli_output (vm, "%U", format_config, config, verbose);
+    }
+
+  return;
+}
+
+static clib_error_t *
+show_dma_command_fn (vlib_main_t *vm, unformat_input_t *input,
+		     vlib_cli_command_t *cmd)
+{
+  unformat_input_t _line_input, *line_input = &_line_input;
+  clib_error_t *error = 0;
+  int verbose = 0, backends = 0, configs = 0;
+
+  if (!unformat_user (input, unformat_line_input, line_input))
+    {
+      dma_cli_show_all_backends (vm, 0);
+      dma_cli_show_all_configs (vm, 0);
+      return 0;
+    }
+  while (unformat_check_input (line_input) != UNFORMAT_END_OF_INPUT)
+    {
+      if (unformat (line_input, "verbose %d", &verbose))
+	;
+      else if (unformat (line_input, "verbose"))
+	verbose = 1;
+      else if (unformat (line_input, "backends"))
+	backends = 1;
+      else if (unformat (line_input, "configs"))
+	configs = 1;
+      else
+	{
+	  error = clib_error_return (0, "unknown input `%U'",
+				     format_unformat_error, line_input);
+	  goto done;
+	}
+    }
+
+  if (backends)
+    dma_cli_show_all_backends (vm, verbose);
+  if (configs)
+    dma_cli_show_all_configs (vm, verbose);
+
+done:
+  unformat_free (line_input);
+  return error;
+}
+
+VLIB_CLI_COMMAND (vlib_cli_show_dma_command) = {
+  .path = "show dma",
+  .short_help = "show dma [backends] [configs] [verbose [n]] [thread] ",
+  .function = show_dma_command_fn,
+};
+
+void
+fill_random_data (void *buffer, uword size, uword transfers)
+{
+  uword loop = transfers;
+  uword seed = random_default_seed ();
+  uword offset = 0;
+
+  clib_random_buffer_t rb;
+  clib_random_buffer_init (&rb, seed);
+
+  while (loop > 0)
+    {
+      clib_random_buffer_fill (&rb, size);
+      void *rbuf = clib_random_buffer_get_data (&rb, size);
+      clib_memcpy_fast (buffer + offset, rbuf, size);
+      clib_random_buffer_free (&rb);
+
+      offset += size;
+      loop--;
+    }
+
+  return;
+}
+
+static void
+dma_benchmark_result (vlib_main_t *vm, u32 size, u32 transfers, uword elapsed)
+{
+  vlib_cli_output (vm, "%-24s%-24s%-24s%-24s", "Copy length(B)",
+		   "Throughput(Mb/s)", "IOPS", "Latency(ns)");
+  uword total_size = size * transfers;
+  double throughput = total_size * (1e6) / (1 << 20) * (1e3) / elapsed * 8;
+  double iops = 1e9 * transfers / elapsed;
+  double latency = 1.0 * elapsed / transfers;
+  vlib_cli_output (vm, "\n%-24d%-24.2f%-24.2f%-24.2f", size, throughput, iops,
+		   latency);
+}
+
+#define TRANSFER_BATCH_SIZE 256
+static clib_error_t *
+test_dma (vlib_main_t * vm, unformat_input_t * input,
+	   vlib_cli_command_t * cmd_arg)
+{
+  u32 transfers = 256, size = 4096, cnt, remains, cookie;
+  unformat_input_t _line_input, *line_input = &_line_input;
+  clib_error_t *error = 0;
+  vlib_dma_config_args_t args;
+  vlib_dma_completion_cb_fn_t cb = NULL;
+  int i;
+  uword offset = 0;
+
+  if (!unformat_user (input, unformat_line_input, line_input))
+    return 0;
+
+  while (unformat_check_input (line_input) != UNFORMAT_END_OF_INPUT)
+    {
+      if (unformat (line_input, "num-transfers %d", &transfers))
+	;
+      else if (unformat (line_input, "transfer-size %d", &size))
+	;
+      else
+	{
+	  error = clib_error_return (0, "unknown input `%U'",
+				     format_unformat_error, line_input);
+	  goto done;
+	}
+    }
+
+  remains = transfers;
+  args.max_transfers = 2;
+  args.max_transfer_size = TRANSFER_BATCH_SIZE;
+  args.cpu_fallback = 0;
+  args.barrier_before_last = 0;
+  args.cb = cb;
+  int config_index = vlib_dma_config (vm, &args);
+  if (config_index < 0)
+    {
+      error = clib_error_return (0, "No config suitable for test");
+      goto done;
+    }
+
+  /* prepare two hugepages */
+  uword log2_page_size = clib_mem_get_log2_default_hugepage_size ();
+  uword page_size = 1 << log2_page_size;
+  ASSERT (page_size >= (uword) size * transfers);
+
+  void *src = clib_mem_vm_map (0, page_size, log2_page_size, "Source");
+  if (src == CLIB_MEM_VM_MAP_FAILED)
+    {
+      return clib_error_return (0, "Error: Hugepage map failed!");
+    }
+  void *dst = clib_mem_vm_map (0, page_size, log2_page_size, "Destination");
+  if (dst == CLIB_MEM_VM_MAP_FAILED)
+    {
+      clib_mem_vm_unmap (src);
+      return clib_error_return (0, "Error: Hugepage map failed!");
+    }
+
+  fill_random_data (src, size, transfers);
+  fill_random_data (dst, size, transfers);
+
+  vlib_dma_transfer_t dma_transfers[TRANSFER_BATCH_SIZE];
+  u64 start_time, end_time;
+  start_time = unix_time_now_nsec ();
+
+  do
+    {
+
+	  cnt = clib_min (remains, TRANSFER_BATCH_SIZE);
+	  for (i = 0; i < cnt; i++)
+	    {
+	      dma_transfers[i].dst = (u8 *) (dst + offset);
+	      dma_transfers[i].src = (u8 *) (src + offset);
+	      dma_transfers[i].size = size;
+	      offset += i * size;
+	    }
+	  remains -= cnt;
+      while(vlib_dma_transfer (vm, config_index, dma_transfers, cnt, 0));
+      while(!vlib_dma_get_completed (vm, config_index, &cb, &cookie));
+    }
+  while (remains);
+
+  end_time = unix_time_now_nsec ();
+  dma_benchmark_result (vm, size, transfers, end_time - start_time);
+
+done:
+  clib_mem_vm_unmap (src);
+  clib_mem_vm_unmap (dst);
+  unformat_free (line_input);
+  return error;
+}
+
+VLIB_CLI_COMMAND (test_dma_command, static) = {
+    .path = "test dma",
+    .short_help = "test dma [num-transfers <n>] [transfer-size <n>]",
+    .function = test_dma,
+};
\ No newline at end of file
diff --git a/src/vlib/dma/dma.c b/src/vlib/dma/dma.c
new file mode 100644
index 000000000..0017ab592
--- /dev/null
+++ b/src/vlib/dma/dma.c
@@ -0,0 +1,83 @@
+/* SPDX-License-Identifier: Apache-2.0
+ * Copyright (c) 2022 Cisco Systems, Inc.
+ */
+
+#include <vlib/vlib.h>
+#include <vlib/log.h>
+#include <vlib/dma/dma.h>
+
+VLIB_REGISTER_LOG_CLASS (dma_log) = {
+  .class_name = "dma",
+};
+
+vlib_dma_main_t vlib_dma_main = {};
+
+clib_error_t *
+vlib_dma_register_backend (vlib_main_t *vm, vlib_dma_backend_t *b)
+{
+  vlib_dma_main_t *dm = &vlib_dma_main;
+  vec_add1 (dm->backends, *b);
+  dma_log_info ("backend '%s' registered", b->name);
+  return 0;
+}
+
+int
+vlib_dma_config_add (vlib_main_t *vm, vlib_dma_config_t *c)
+{
+  vlib_dma_main_t *dm = &vlib_dma_main;
+  vlib_dma_backend_t *b;
+  vlib_dma_config_data_t *cd;
+
+  pool_get_zero (dm->configs, cd);
+  cd->config_index = cd - dm->configs;
+
+  clib_memcpy (&cd->cfg, c, sizeof (vlib_dma_config_t));
+
+  vec_foreach (b, dm->backends)
+    {
+      dma_log_info ("calling '%s' config_add_fn", b->name);
+      if (b->config_add_fn (vm, cd))
+	{
+	  dma_log_info ("config %u added into backend %s",
+	  		 cd - dm->configs, b->name);
+	  cd->backend_index = b - dm->backends;
+	  return cd - dm->configs;
+	}
+    }
+
+  pool_put (dm->configs, cd);
+  return -1;
+}
+
+void
+vlib_dma_config_del (vlib_main_t *vm, u32 config_index)
+{
+  vlib_dma_main_t *dm = &vlib_dma_main;
+  vlib_dma_config_data_t *cd = pool_elt_at_index (dm->configs, config_index);
+  vlib_dma_backend_t *b = vec_elt_at_index (dm->backends, cd->backend_index);
+
+  if (b->config_del_fn)
+    b->config_del_fn (vm, cd);
+
+  pool_put (dm->configs, cd);
+  dma_log_info ("config %u deleted from backend %s",
+  		config_index, b->name);
+}
+
+u8 *
+vlib_dma_config_info (u8 *s, va_list * args)
+{
+  vlib_dma_main_t *dm = &vlib_dma_main;
+  int config_index = va_arg (*args, int);
+  u32 len = pool_elts (dm->configs);
+  if (config_index >= len)
+    return format(s, "%s", "not found");
+  vlib_dma_config_data_t *cd = pool_elt_at_index (dm->configs, config_index);
+
+  vlib_dma_backend_t *b = vec_elt_at_index (dm->backends, cd->backend_index);
+
+  if (b->info_fn)
+    return b->info_fn (s, args);
+
+  return 0;
+}
diff --git a/src/vlib/dma/dma.h b/src/vlib/dma/dma.h
new file mode 100644
index 000000000..e6eff0702
--- /dev/null
+++ b/src/vlib/dma/dma.h
@@ -0,0 +1,141 @@
+/* SPDX-License-Identifier: Apache-2.0
+ * Copyright (c) 2022 Cisco Systems, Inc.
+ */
+
+#ifndef included_vlib_dma_h
+#define included_vlib_dma_h
+#include <vlib/vlib.h>
+
+// #define DEBUG
+#define dma_log_debug(f, ...)                                                     \
+  vlib_log (VLIB_LOG_LEVEL_DEBUG, dma_log.class, "%s: " f, __func__,          \
+	    ##__VA_ARGS__)
+
+#define dma_log_info(f, ...)                                                     \
+  vlib_log (VLIB_LOG_LEVEL_INFO, dma_log.class, "%s: " f, __func__,          \
+	    ##__VA_ARGS__)
+
+struct vlib_dma_batch;
+struct vlib_dma_config_data;
+
+typedef int (vlib_dma_config_add_fn) (vlib_main_t *vm,
+				      struct vlib_dma_config_data *cfg);
+typedef void (vlib_dma_config_del_fn) (vlib_main_t *vm,
+				       struct vlib_dma_config_data *cfg);
+typedef struct vlib_dma_batch *(vlib_dma_batch_new_fn) (
+  vlib_main_t *vm, struct vlib_dma_config_data *);
+typedef int (vlib_dma_batch_submit_fn) (vlib_main_t *vm,
+					struct vlib_dma_batch *b);
+typedef void (vlib_dma_batch_callback_fn) (vlib_main_t *vm,
+					   struct vlib_dma_batch *b);
+typedef int (vlib_dma_get_completed_fn) (vlib_main_t *vm,
+					   struct vlib_dma_batch *b);
+typedef struct
+{
+  union
+  {
+    struct
+    {
+      u32 barrier_before_last : 1;
+      u32 sw_fallback : 1;
+    };
+    u32 features;
+  };
+  u16 max_transfers;
+  u32 max_transfer_size;
+  vlib_dma_batch_callback_fn *callback_fn;
+} vlib_dma_config_t;
+
+typedef struct vlib_dma_batch
+{
+  vlib_dma_batch_submit_fn *submit_fn;
+  vlib_dma_batch_callback_fn *callback_fn;
+  vlib_dma_get_completed_fn *complete_fn;
+  uword cookie;
+  u16 src_ptr_off;
+  u16 dst_ptr_off;
+  u16 size_off;
+  u16 stride;
+  u16 n_enq;
+} vlib_dma_batch_t;
+
+typedef struct
+{
+  char *name;
+  vlib_dma_config_add_fn *config_add_fn;
+  vlib_dma_config_del_fn *config_del_fn;
+  format_function_t *info_fn;
+} vlib_dma_backend_t;
+
+typedef struct vlib_dma_config_data
+{
+  vlib_dma_config_t cfg;
+  vlib_dma_batch_new_fn *batch_new_fn;
+  uword private_data;
+  u32 backend_index;
+  u32 config_index;
+} vlib_dma_config_data_t;
+
+typedef struct
+{
+  vlib_dma_backend_t *backends;
+  vlib_dma_config_data_t *configs;
+} vlib_dma_main_t;
+
+extern vlib_dma_main_t vlib_dma_main;
+
+clib_error_t *vlib_dma_register_backend (vlib_main_t *vm,
+					 vlib_dma_backend_t *b);
+
+int vlib_dma_config_add (vlib_main_t *vm, vlib_dma_config_t *b);
+void vlib_dma_config_del (vlib_main_t *vm, u32 config_index);
+u8 *vlib_dma_config_info (u8 *s, va_list * args);
+
+static_always_inline vlib_dma_batch_t *
+vlib_dma_batch_new (vlib_main_t *vm, u32 config_index)
+{
+  vlib_dma_main_t *dm = &vlib_dma_main;
+  vlib_dma_config_data_t *cd = pool_elt_at_index (dm->configs, config_index);
+
+  return cd->batch_new_fn (vm, cd);
+}
+
+static_always_inline void
+vlib_dma_batch_set_cookie (vlib_main_t *vm, vlib_dma_batch_t *batch,
+			   uword cookie)
+{
+  batch->cookie = cookie;
+}
+
+static_always_inline uword
+vlib_dma_batch_get_cookie (vlib_main_t *vm, vlib_dma_batch_t *batch)
+{
+  return batch->cookie;
+}
+
+static_always_inline void
+vlib_dma_batch_add (vlib_main_t *vm, vlib_dma_batch_t *batch, void *dst,
+		    void *src, u32 size)
+{
+  u8 *p = (u8 *) batch + batch->n_enq * batch->stride;
+
+  *((void **) (p + batch->dst_ptr_off)) = dst;
+  *((void **) (p + batch->src_ptr_off)) = src;
+  *((u32 *) (p + batch->size_off)) = size;
+
+  batch->n_enq++;
+}
+
+static_always_inline void
+vlib_dma_batch_submit (vlib_main_t *vm, vlib_dma_batch_t *batch)
+{
+  batch->submit_fn (vm, batch);
+}
+
+static_always_inline int
+vlib_dma_batch_completed (vlib_main_t *vm, vlib_dma_batch_t *batch)
+{
+  return batch->complete_fn (vm, batch);
+}
+
+#endif
\ No newline at end of file
diff --git a/src/vlib/dma/dma.rst b/src/vlib/dma/dma.rst
new file mode 100644
index 000000000..7dae6026d
--- /dev/null
+++ b/src/vlib/dma/dma.rst
@@ -0,0 +1,70 @@
+.. _dma_plugin:
+
+.. toctree::
+
+DMA plugin
+==========
+
+Overview
+--------
+This plugin utilize platform DMA accelerators like CBDMA/DSA for streaming
+data movement. Modern DMA accelerators has high memory bandwidth and benefit
+cross-numa traffic. Accelerator like DSA has the capability to do IO page
+fault recovery, it will save IOMMU setup for the memory which not pinned.
+
+Terminology & Usage
+-------------------
+
+A ``backend`` is the abstract of resource which inherited from DMA device,
+it support necessary operations for DMA offloading like configuration, DMA
+request and result query.
+
+A ``config`` is the abstract of application DMA capability. Application can
+request a config instance through DMA node. DMA node will check the
+requirements of application and bind suitable backend with it.
+
+Enable DSA work queue:
+----------------------
+
+.. code-block:: console
+  # configure 1 groups, each with one engine
+  accel-config config-engine dsa0/engine0.0 --group-id=0
+
+  # configure 1 queues, putting each in a different group, so each
+  # is backed by a single engine
+  accel-config config-wq dsa0/wq0.0 --group-id=0 --type=user  \
+    --priority=10 --max-batch-size=1024 --mode=dedicated -b 1 -a 0 --name=vpp1
+
+DMA transfer:
+-------------
+
+In this sample, application will request DMA capability which can hold
+a batch contained maximum 256 transfers and total 16 in-flight batch
+from DMA node. If config_index value is not negative, mean resource has
+been allocated and DMA engine is ready for serve.
+
+.. code-block:: console
+
+  typedef struct {
+    ...
+    int config_index;
+    vlib_dma_transfer_t iov[256];
+    u32 n_transfers;
+    ...
+  } wrk_t;
+
+  vlib_dma_config_args_t args;
+  args->max_transfers = 256;
+  args->max_transfer_size = 16;
+  args->cpu_fallback = 1;
+  args->barrier_before_last = 0;
+  args->cb = dma_completion_cb;
+  wrk_t->config_index = vlib_dma_config (vm, &args);
+
+  while (has_buffer && wrk_t->config_index > 0) {
+    wrk->iov[wrk->n_transfers].dst = dst;
+    wrk->iov[wrk->n_transfers].src = src;
+    wrk->iov[wrk->n_transfers].size = size;
+    n_transfers ++;
+  }
+  vlib_dma_transfer (vm, wrk->config_index, wrk->iov, wrk->n_transfers, 0);
diff --git a/src/vlib/init.h b/src/vlib/init.h
index e6235652a..019434edb 100644
--- a/src/vlib/init.h
+++ b/src/vlib/init.h
@@ -171,7 +171,8 @@ static __clib_unused void * __clib_unused_##tag##_##x = x
 
 #define VLIB_INIT_FUNCTION(x) VLIB_DECLARE_INIT_FUNCTION(x,init)
 #define VLIB_WORKER_INIT_FUNCTION(x) VLIB_DECLARE_INIT_FUNCTION(x,worker_init)
-
+#define VLIB_NUM_WORKERS_CHANGE_FN(x)                                         \
+  VLIB_DECLARE_INIT_FUNCTION (x, num_workers_change)
 #define VLIB_MAIN_LOOP_ENTER_FUNCTION(x) \
   VLIB_DECLARE_INIT_FUNCTION(x,main_loop_enter)
 #define VLIB_MAIN_LOOP_EXIT_FUNCTION(x) \
diff --git a/src/vlib/linux/vfio.c b/src/vlib/linux/vfio.c
index dc68c52db..da4ed09bc 100644
--- a/src/vlib/linux/vfio.c
+++ b/src/vlib/linux/vfio.c
@@ -50,8 +50,8 @@ vfio_map_physmem_page (vlib_main_t * vm, void *addr)
 
   if (clib_bitmap_get (lvm->physmem_pages_mapped, page_index))
     {
-      vlib_log_debug (lvm->log_default, "map DMA va:%p page:%u already "
-		      "mapped", addr, page_index);
+      fprintf(stderr, "map DMA va:%p page:%u already "
+		      "mapped\n", addr, page_index);
       return 0;
     }
 
@@ -60,13 +60,13 @@ vfio_map_physmem_page (vlib_main_t * vm, void *addr)
   dm.vaddr = physmem_start + (page_index << log2_page_size);
   dm.size = 1ULL << log2_page_size;
   dm.iova = dm.vaddr;
-  vlib_log_debug (lvm->log_default, "map DMA page:%u va:0x%lx iova:%lx "
-		  "size:0x%lx", page_index, dm.vaddr, dm.iova, dm.size);
+  fprintf (stderr,  "map DMA page:%u va:0x%lx iova:%lx "
+		  "size:0x%lx\n", page_index, dm.vaddr, dm.iova, dm.size);
 
   if (ioctl (lvm->container_fd, VFIO_IOMMU_MAP_DMA, &dm) == -1)
     {
-      vlib_log_err (lvm->log_default, "map DMA page:%u va:0x%lx iova:%lx "
-		    "size:0x%lx failed, error %s (errno %d)", page_index,
+      fprintf (stderr, "map DMA page:%u va:0x%lx iova:%lx "
+		    "size:0x%lx failed, error %s (errno %d)\n", page_index,
 		    dm.vaddr, dm.iova, dm.size, strerror (errno), errno);
       return clib_error_return_unix (0, "physmem DMA map failed");
     }
@@ -76,6 +76,34 @@ vfio_map_physmem_page (vlib_main_t * vm, void *addr)
   return 0;
 }
 
+clib_error_t *
+vfio_map_one_page (u64 iova, u64 size)
+{
+  linux_vfio_main_t *lvm = &vfio_main;
+  struct vfio_iommu_type1_dma_map dm = { 0 };
+
+  if (lvm->container_fd == -1)
+    return clib_error_return (0, "No cointainer fd");
+
+  dm.argsz = sizeof (struct vfio_iommu_type1_dma_map);
+  dm.flags = VFIO_DMA_MAP_FLAG_READ | VFIO_DMA_MAP_FLAG_WRITE;
+  dm.vaddr = iova;
+  dm.size = size;
+  dm.iova = iova;
+  fprintf (stderr, "map DMA page: va:0x%lx iova:%lx "
+ 		  "size:0x%lx\n", dm.vaddr, dm.iova, dm.size);
+
+  if (ioctl (lvm->container_fd, VFIO_IOMMU_MAP_DMA, &dm) == -1)
+    {
+      fprintf (stderr, "map DMA page: va:0x%lx iova:%lx "
+		    "size:0x%lx failed, error %s (errno %d)\n",
+ 		    dm.vaddr, dm.iova, dm.size, strerror (errno), errno);
+      return clib_error_return_unix (0, "physmem DMA map failed");
+    }
+
+  return 0;
+}
+
 static linux_pci_vfio_iommu_group_t *
 get_vfio_iommu_group (int group)
 {
diff --git a/src/vlib/linux/vfio.h b/src/vlib/linux/vfio.h
index fe4f0f753..e4a672ed9 100644
--- a/src/vlib/linux/vfio.h
+++ b/src/vlib/linux/vfio.h
@@ -46,6 +46,8 @@ extern linux_vfio_main_t vfio_main;
 
 clib_error_t *linux_vfio_init (vlib_main_t * vm);
 clib_error_t *vfio_map_physmem_page (vlib_main_t * vm, void *addr);
+clib_error_t *
+vfio_map_one_page (u64 iova, u64 size);
 clib_error_t *linux_vfio_group_get_device_fd (vlib_pci_addr_t * addr,
 					      int *fd, int *is_noiommu);
 
diff --git a/src/vlib/main.h b/src/vlib/main.h
index a16f603f4..9dfd2b3ea 100644
--- a/src/vlib/main.h
+++ b/src/vlib/main.h
@@ -310,6 +310,7 @@ typedef struct vlib_global_main_t
   _vlib_init_function_list_elt_t *main_loop_enter_function_registrations;
   _vlib_init_function_list_elt_t *main_loop_exit_function_registrations;
   _vlib_init_function_list_elt_t *worker_init_function_registrations;
+  _vlib_init_function_list_elt_t *num_workers_change_function_registrations;
   _vlib_init_function_list_elt_t *api_init_function_registrations;
   vlib_config_function_runtime_t *config_function_registrations;
 
diff --git a/src/vlib/pci/pci.c b/src/vlib/pci/pci.c
index 249a26b1d..68815e4c7 100644
--- a/src/vlib/pci/pci.c
+++ b/src/vlib/pci/pci.c
@@ -161,6 +161,13 @@ format_vlib_pci_link_port (u8 *s, va_list *va)
   return format (s, "P%d", r->link_capabilities >> 24);
 }
 
+u8 *
+format_vlib_dsa_addr (u8 *s, va_list *va)
+{
+  vlib_dsa_addr_t *addr = va_arg (*va, vlib_dsa_addr_t *);
+  return format (s, "wq%d.%d", addr->device_id, addr->wq_id);
+}
+
 u8 *
 format_vlib_pci_link_speed (u8 * s, va_list * va)
 {
diff --git a/src/vlib/pci/pci.h b/src/vlib/pci/pci.h
index 1dc4ce6ea..d09786c34 100644
--- a/src/vlib/pci/pci.h
+++ b/src/vlib/pci/pci.h
@@ -330,6 +330,15 @@ format_function_t format_vlib_pci_link_speed;
 format_function_t format_vlib_pci_link_port;
 format_function_t format_vlib_pci_vpd;
 
+// TODO: move to seperated file later
+typedef struct
+{
+  u16 device_id;
+  u16 wq_id;
+} vlib_dsa_addr_t;
+
+format_function_t format_vlib_dsa_addr;
+
 #endif /* included_vlib_pci_h */
 
 /*
diff --git a/src/vlib/threads.c b/src/vlib/threads.c
index f4d95c450..470d35567 100644
--- a/src/vlib/threads.c
+++ b/src/vlib/threads.c
@@ -812,6 +812,14 @@ start_workers (vlib_main_t * vm)
 	}
     }
   vlib_worker_thread_barrier_sync (vm);
+  {
+    clib_error_t *err;
+    err = vlib_call_init_exit_functions (
+      vm, &vgm->num_workers_change_function_registrations, 1 /* call_once */,
+      1 /* is_global */);
+    if (err)
+      clib_error_report (err);
+  }
   vlib_worker_thread_barrier_release (vm);
   return 0;
 }
diff --git a/src/vlib/threads.h b/src/vlib/threads.h
index e406dde5b..cbb4f1e05 100644
--- a/src/vlib/threads.h
+++ b/src/vlib/threads.h
@@ -167,7 +167,7 @@ u32 vlib_frame_queue_main_init (u32 node_index, u32 frame_queue_nelts);
 /* long barrier timeout, for gdb... */
 #define BARRIER_SYNC_TIMEOUT (600.1)
 #else
-#define BARRIER_SYNC_TIMEOUT (1.0)
+#define BARRIER_SYNC_TIMEOUT (600.1)
 #endif
 
 #define vlib_worker_thread_barrier_sync(X) {vlib_worker_thread_barrier_sync_int(X, __FUNCTION__);}
diff --git a/src/vlib/unix/plugin.c b/src/vlib/unix/plugin.c
index 891e2cb64..17544019a 100644
--- a/src/vlib/unix/plugin.c
+++ b/src/vlib/unix/plugin.c
@@ -306,9 +306,9 @@ process_reg:
 
   handle = dlopen ((char *) pi->filename,
 		   RTLD_LAZY | (reg->deep_bind ? RTLD_DEEPBIND : 0));
-
   if (handle == 0)
     {
+      printf("%s", dlerror ());
       PLUGIN_LOG_ERR ("%s", dlerror ());
       PLUGIN_LOG_ERR ("Failed to load plugin '%s'", pi->name);
       goto error;
diff --git a/src/vnet/devices/af_packet/af_packet.h b/src/vnet/devices/af_packet/af_packet.h
index 652e173fd..0ab9cb392 100644
--- a/src/vnet/devices/af_packet/af_packet.h
+++ b/src/vnet/devices/af_packet/af_packet.h
@@ -52,6 +52,7 @@ typedef struct
 
   u32 per_interface_next_index;
   u8 is_admin_up;
+  u8 pending_kick;
   u32 queue_index;
   u32 host_mtu;
   af_packet_if_mode_t mode;
diff --git a/src/vnet/devices/af_packet/device.c b/src/vnet/devices/af_packet/device.c
index c8e59c356..ea3cae957 100644
--- a/src/vnet/devices/af_packet/device.c
+++ b/src/vnet/devices/af_packet/device.c
@@ -192,7 +192,7 @@ VNET_DEVICE_CLASS_TX_FN (af_packet_device_class) (vlib_main_t * vm,
 
   CLIB_MEMORY_BARRIER ();
 
-  if (PREDICT_TRUE (n_sent))
+  if (PREDICT_TRUE (n_sent || apif->pending_kick))
     {
       apif->next_tx_frame = tx_frame;
 
@@ -208,7 +208,10 @@ VNET_DEVICE_CLASS_TX_FN (af_packet_device_class) (vlib_main_t * vm,
 			      AF_PACKET_TX_ERROR_TXRING_FATAL :
 			      AF_PACKET_TX_ERROR_TXRING_EAGAIN,
 			    n_sent);
+	  apif->pending_kick = 1;
 	}
+      else
+	apif->pending_kick = 0;
     }
 
   clib_spinlock_unlock_if_init (&apif->lockp);
diff --git a/src/vnet/interface.api b/src/vnet/interface.api
index 172f6afb8..98e74d3f8 100644
--- a/src/vnet/interface.api
+++ b/src/vnet/interface.api
@@ -733,6 +733,26 @@ autoreply define collect_detailed_interface_stats
   bool  enable_disable;
 };
 
+/** \brief Get available, cached and used buffers
+    @param client_index - opaque cookie to identify the sender
+    @param context - sender context, to match reply w/ request
+    @param buffer_index - buffer stat index
+*/
+define get_buffers_stats
+{
+  u32 client_index;
+  u32 context;
+  u32 buffer_index;
+};
+define get_buffers_stats_reply
+{
+  u32 context;
+  i32 retval;
+  u32 available_buffers;
+  u32 cached_buffers;
+  u32 used_buffers;
+};
+
 /*
  * Local Variables:
  * eval: (c-set-style "gnu")
diff --git a/src/vnet/interface_api.c b/src/vnet/interface_api.c
index 938f3bb32..49e5d09cd 100644
--- a/src/vnet/interface_api.c
+++ b/src/vnet/interface_api.c
@@ -81,6 +81,23 @@ vpe_api_main_t vpe_api_main;
   _ (SW_INTERFACE_ADDRESS_REPLACE_BEGIN, sw_interface_address_replace_begin)  \
   _ (SW_INTERFACE_ADDRESS_REPLACE_END, sw_interface_address_replace_end)
 
+static void
+vl_api_get_buffers_stats_t_handler (vl_api_get_buffers_stats_t *mp)
+{
+  vl_api_get_buffers_stats_reply_t *rmp;
+
+  int rv = 0;
+  buffers_stats_t obj = { 0, 0, 0 };
+  buffers_stats_t *bs = &obj;
+  get_buffers_stats (bs, mp->buffer_index);
+
+  REPLY_MACRO2 (VL_API_GET_BUFFERS_STATS_REPLY, ({
+		  rmp->available_buffers = bs->available_buffers;
+		  rmp->cached_buffers = bs->cached_buffers;
+		  rmp->used_buffers = bs->used_buffers;
+		}));
+}
+
 static void
 vl_api_sw_interface_set_flags_t_handler (vl_api_sw_interface_set_flags_t * mp)
 {
diff --git a/src/vnet/interface_test.c b/src/vnet/interface_test.c
index c3ddcd74c..c15b5c75c 100644
--- a/src/vnet/interface_test.c
+++ b/src/vnet/interface_test.c
@@ -46,6 +46,18 @@ typedef struct
 
 static interface_test_main_t interface_test_main;
 
+static int
+api_get_buffers_stats (vat_main_t *vam)
+{
+  int ret = 0;
+  return ret;
+}
+
+static void
+vl_api_get_buffers_stats_reply_t_handler (vl_api_get_buffers_stats_reply_t *mp)
+{
+}
+
 static int
 api_sw_interface_set_flags (vat_main_t *vam)
 {
diff --git a/src/vnet/session/application.c b/src/vnet/session/application.c
index 46dc6d63e..5aff30575 100644
--- a/src/vnet/session/application.c
+++ b/src/vnet/session/application.c
@@ -819,6 +819,8 @@ application_alloc_and_init (app_init_args_t * a)
       props->add_segment_size = opts[APP_OPTIONS_ADD_SEGMENT_SIZE];
       props->add_segment = 1;
     }
+  if (opts[APP_OPTIONS_SEGMENT_PROPS] & APP_SEG_PROPS_FLAGS_HUGEPAGE)
+    props->huge_page = 1;
   if (opts[APP_OPTIONS_RX_FIFO_SIZE])
     props->rx_fifo_size = opts[APP_OPTIONS_RX_FIFO_SIZE];
   if (opts[APP_OPTIONS_TX_FIFO_SIZE])
diff --git a/src/vnet/session/application_interface.h b/src/vnet/session/application_interface.h
index 733a4627c..13bf0a03e 100644
--- a/src/vnet/session/application_interface.h
+++ b/src/vnet/session/application_interface.h
@@ -205,6 +205,7 @@ typedef enum
   APP_OPTIONS_FLAGS,
   APP_OPTIONS_EVT_QUEUE_SIZE,
   APP_OPTIONS_SEGMENT_SIZE,
+  APP_OPTIONS_SEGMENT_PROPS,
   APP_OPTIONS_ADD_SEGMENT_SIZE,
   APP_OPTIONS_PRIVATE_SEGMENT_COUNT,
   APP_OPTIONS_RX_FIFO_SIZE,
@@ -234,6 +235,8 @@ typedef enum
   _ (EVT_MQ_USE_EVENTFD, "Use eventfds for signaling")                        \
   _ (MEMFD_FOR_BUILTIN, "Use memfd for builtin app segs")
 
+#define foreach_app_seg_props_flags _ (HUGEPAGE, "use hugepage")
+
 typedef enum _app_options
 {
 #define _(sym, str) APP_OPTIONS_##sym,
@@ -248,6 +251,20 @@ typedef enum _app_options_flags
 #undef _
 } app_options_flags_t;
 
+typedef enum _app_seg_props
+{
+#define _(sym, str) APP_SEG_PROPS_##sym,
+  foreach_app_seg_props_flags
+#undef _
+} app_seg_props_t;
+
+typedef enum _app_seg_props_flags
+{
+#define _(sym, str) APP_SEG_PROPS_FLAGS_##sym = 1 << APP_SEG_PROPS_##sym,
+  foreach_app_seg_props_flags
+#undef _
+} app_seg_props_flags_t;
+
 #define foreach_fd_type						\
   _(VPP_MQ_SEGMENT, "Fd for vpp's event mq segment")		\
   _(MEMFD_SEGMENT, "Fd for memfd segment")			\
@@ -825,7 +842,7 @@ typedef enum app_sapi_msg_type
 typedef struct app_sapi_attach_msg_
 {
   u8 name[64];
-  u64 options[18];
+  u64 options[19];
 } __clib_packed app_sapi_attach_msg_t;
 
 STATIC_ASSERT (sizeof (u64) * APP_OPTIONS_N_OPTIONS <=
diff --git a/src/vnet/session/segment_manager.c b/src/vnet/session/segment_manager.c
index e72e833f5..c9f8d4410 100644
--- a/src/vnet/session/segment_manager.c
+++ b/src/vnet/session/segment_manager.c
@@ -16,6 +16,8 @@
 #include <vnet/session/segment_manager.h>
 #include <vnet/session/session.h>
 #include <vnet/session/application.h>
+#include <vlib/pci/pci.h>
+#include <vlib/linux/vfio.h>
 
 typedef struct segment_manager_main_
 {
@@ -93,11 +95,15 @@ segment_manager_add_segment_inline (segment_manager_t *sm, uword segment_size,
 {
   segment_manager_main_t *smm = &sm_main;
   segment_manager_props_t *props;
+  session_main_t *session_mm = &session_main;
   app_worker_t *app_wrk;
   fifo_segment_t *fs;
   u32 fs_index = ~0;
   u8 *seg_name;
   int rv;
+  int page_size = clib_mem_get_page_size ();
+  uword hugepage_size = clib_mem_get_default_hugepage_size ();
+  int log2_page_size = min_log2 (page_size);
 
   props = segment_manager_properties_get (sm);
   app_wrk = app_worker_get (sm->app_wrk_index);
@@ -127,7 +133,22 @@ segment_manager_add_segment_inline (segment_manager_t *sm, uword segment_size,
     sizeof (fifo_segment_header_t) +
     vlib_thread_main.n_vlib_mains * sizeof (fifo_segment_slice_t) +
     FIFO_SEGMENT_ALLOC_OVERHEAD;
-  segment_size = round_pow2 (segment_size, clib_mem_get_page_size ());
+
+  if (props->huge_page)
+    {
+//       uword alloc_size;
+//       log2_page_size = min_log2 (hugepage_size);
+//       u32 rnd_margin = 128 << 10;
+//       alloc_size = (uword) segment_size + rnd_margin;
+//       alloc_size =
+// 	(((alloc_size - 1) >> log2_page_size) + 1) * hugepage_size;
+//       segment_size = alloc_size - rnd_margin;
+       segment_size = round_pow2 (segment_size, hugepage_size);
+       log2_page_size = min_log2 (hugepage_size);
+       fs->ssvm.huge_page = 1;
+    }
+  else
+    segment_size = round_pow2 (segment_size, clib_mem_get_page_size ());
 
   seg_name = format (0, "seg-%u-%u-%u%c", app_wrk->app_index,
 		     app_wrk->wrk_index, smm->seg_name_counter++, 0);
@@ -166,6 +187,17 @@ segment_manager_add_segment_inline (segment_manager_t *sm, uword segment_size,
   fs->flags &= ~FIFO_SEGMENT_F_MEM_LIMIT;
   fs->h->pct_first_alloc = props->pct_first_alloc;
 
+  vlib_main_t *vm = vlib_get_main();
+  if (session_mm->dma && props->huge_page)
+  {
+    uword n_pages = ((segment_size - 1) >> log2_page_size) + 1;
+        for (u32 i = 0; i < n_pages; i++)
+          {
+            char *va = (char *)fs->ssvm.sh + i * page_size;
+	    vfio_map_one_page (uword_to_pointer(va, u64), (u64) 1 << log2_page_size);
+          }
+  }
+
   if (notify_app)
     {
       app_worker_t *app_wrk;
diff --git a/src/vnet/session/segment_manager.h b/src/vnet/session/segment_manager.h
index 8b722a023..e786b3144 100644
--- a/src/vnet/session/segment_manager.h
+++ b/src/vnet/session/segment_manager.h
@@ -40,6 +40,7 @@ typedef struct _segment_manager_props
   u8 high_watermark;			/**< memory usage high watermark % */
   u8 low_watermark;			/**< memory usage low watermark % */
   u8 pct_first_alloc;			/**< pct of fifo size to alloc */
+  u8 huge_page;				/**< use hugepage */
 } segment_manager_props_t;
 
 typedef enum seg_manager_flag_
diff --git a/src/vnet/session/session.api b/src/vnet/session/session.api
index d2a942fb6..9258f921d 100644
--- a/src/vnet/session/session.api
+++ b/src/vnet/session/session.api
@@ -37,7 +37,7 @@ enum transport_proto : u8
  define app_attach {
     u32 client_index;
     u32 context;
-    u64 options[18];
+    u64 options[19];
     string namespace_id[];
  };
 
diff --git a/src/vnet/session/session.c b/src/vnet/session/session.c
index ffe29f9a2..49ccd2929 100644
--- a/src/vnet/session/session.c
+++ b/src/vnet/session/session.c
@@ -21,6 +21,7 @@
 #include <vnet/session/application.h>
 #include <vnet/dpo/load_balance.h>
 #include <vnet/fib/ip4_fib.h>
+#include <vlib/dma/dma.h>
 
 session_main_t session_main;
 
@@ -1926,6 +1927,119 @@ session_manager_main_disable (vlib_main_t * vm)
   transport_enable_disable (vm, 0 /* is_en */ );
 }
 
+void
+session_dma_completion_cb (vlib_main_t *vm, u32 n_transfers, u32 cookie)
+{
+  session_worker_t *wrk;
+  wrk = session_main_get_worker (vm->thread_index);
+  session_dma_transfer *dma_transfer;
+  vlib_buffer_t *b[1];
+  u32 data_len;
+  transport_connection_t *tc;
+  transport_proto_vft_t *tp_vft;
+  transport_proto_t tp;
+  session_t *s;
+  u64 diff;
+  printf("session_dma_completion_cb\n");
+  //  wrk->trans_num += n_transfers;
+  while (wrk->trans_head != wrk->trans_tail)
+    {
+      dma_transfer = &wrk->dma_trans[wrk->trans_head];
+      b[0] = vlib_get_buffer (vm, dma_transfer->bi);
+      data_len = session_tcp_buffer_len (b[0]);
+      dma_transfer->time2 = clib_cpu_time_now ();
+      diff = dma_transfer->time2 - dma_transfer->time1;
+      wrk->total_tsc += diff;
+      if (diff < wrk->min_tsc)
+	wrk->min_tsc = diff;
+      if (diff > wrk->max_tsc)
+	wrk->max_tsc = diff;
+      if (dma_transfer->is_tail == 1)
+	{
+	  // printf("session_dma_completion_cb: buffer %p size %d\n",
+	  // vlib_buffer_get_current(b[0]), data_len);
+	  s = session_get (dma_transfer->s_index, vm->thread_index);
+	  tp = session_get_transport_proto (s);
+	  tp_vft = transport_protocol_get_vft (tp);
+	  tc =
+	    tp_vft->get_connection (dma_transfer->c_index, vm->thread_index);
+	  tp_vft->push_header (tc, b, 1);
+	  vec_add1 (wrk->pending_tx_buffers, dma_transfer->bi);
+	  vec_add1 (wrk->pending_tx_nexts, dma_transfer->next_index);
+	  s->snd_dsa -= data_len;
+	}
+      n_transfers -= dma_transfer->num;
+
+      wrk->trans_head++;
+      if (wrk->trans_head == wrk->trans_size)
+	wrk->trans_head = 0;
+
+      if (n_transfers == 0)
+	break;
+    }
+
+  //    if (n_transfers)
+  //      printf("session_dma_completion_cb: found %d remained transfers\n",
+  //      n_transfers);
+
+  return;
+}
+
+/* in this new callback, cookie hint the index */
+void
+session_dma_completion_cb_v1 (vlib_main_t *vm, struct vlib_dma_batch *batch)
+{
+  session_worker_t *wrk;
+  wrk = session_main_get_worker (vm->thread_index);
+  session_dma_transfer_v1 *dma_transfer;
+  u64 diff;
+#ifdef DEBUG
+  printf("session_dma_completion_cb_v1: got callback for %ld and %d\n", batch->cookie, wrk->trans_head);
+#endif
+  //  wrk->trans_num += n_transfers;
+  if (batch->cookie != wrk->trans_head)
+  {
+//      printf("session_dma_completion_cb_v1: this is not the expected callback %ld and %d\n", batch->cookie, wrk->trans_head);
+//      abort();
+  }
+
+      dma_transfer = &wrk->dma_trans_v1[wrk->trans_head];
+      dma_transfer->time2 = clib_cpu_time_now ();
+      diff = dma_transfer->time2 - dma_transfer->time1;
+      wrk->total_tsc += diff;
+      if (diff < wrk->min_tsc)
+	wrk->min_tsc = diff;
+      if (diff > wrk->max_tsc)
+	wrk->max_tsc = diff;
+
+#ifdef DEBUG
+printf("session_dma_completion_cb_v1: add %d new buffers\n", vec_len(dma_transfer->pending_tx_buffers));
+#endif
+      vec_add (wrk->pending_tx_buffers, dma_transfer->pending_tx_buffers, vec_len(dma_transfer->pending_tx_buffers));
+      vec_add (wrk->pending_tx_nexts, dma_transfer->pending_tx_nexts, vec_len(dma_transfer->pending_tx_nexts));
+      vec_reset_length(dma_transfer->pending_tx_buffers);
+      vec_reset_length(dma_transfer->pending_tx_nexts);
+   //ctx->s->snd_dsa -= data_len;
+#ifdef DEBUG
+  printf("session_dma_completion_cb_v1: has %d buffers\n", vec_len(wrk->pending_tx_buffers));
+#endif
+  wrk->trans_head ++;
+  if (wrk->trans_head == wrk->trans_size)
+    wrk->trans_head = 0;
+  return;
+}
+
+static void
+session_prepare_dma_args (vlib_dma_config_t *args)
+{
+  args->max_transfers = 1024;
+  args->max_transfer_size = 65536;
+  args->features = 0;
+  args->sw_fallback = 1;
+  args->barrier_before_last = 1;
+  args->callback_fn = session_dma_completion_cb_v1;
+}
+
 void
 session_node_enable_disable (u8 is_en)
 {
@@ -1937,6 +2051,22 @@ session_node_enable_disable (u8 is_en)
   int n_vlibs, i;
 
   n_vlibs = vlib_get_n_threads ();
+  vlib_dma_config_t args;
+  session_prepare_dma_args (&args);
+  session_worker_t *wrk;
+
+  int config_index = -1;
+  if (is_en && sm->dma)
+  {
+    vm = vlib_get_main_by_index (0);
+    config_index = vlib_dma_config_add (vm, &args);
+  } else if (sm->dma) {
+    vm = vlib_get_main_by_index (0);
+    wrk = session_main_get_worker (0);
+    if (wrk->config_index >= 0)
+	  vlib_dma_config_del (vm, wrk->config_index);
+  }
+
   for (i = 0; i < n_vlibs; i++)
     {
       vm = vlib_get_main_by_index (i);
@@ -1961,6 +2091,32 @@ session_node_enable_disable (u8 is_en)
 	  if (!sm->poll_main)
 	    continue;
 	}
+      wrk = session_main_get_worker (vm->thread_index);
+      if (is_en  && sm->dma)
+      {
+        wrk->config_index = config_index;
+	if (config_index >= 0)
+          wrk->dma_enabled = true;
+      wrk->dma_trans = (session_dma_transfer *) clib_mem_alloc (
+	sizeof (session_dma_transfer) * DMA_TRANS_SIZE);
+      wrk->dma_trans_v1 = (session_dma_transfer_v1 *) clib_mem_alloc (
+	sizeof (session_dma_transfer_v1) * DMA_TRANS_SIZE);
+	bzero(wrk->dma_trans_v1, sizeof (session_dma_transfer_v1) * DMA_TRANS_SIZE);
+
+      } else if (sm->dma) {
+	if (wrk->dma_trans_v1)
+	  clib_mem_free (wrk->dma_trans_v1);
+	wrk->config_index = -1;
+      }
+
+      wrk->trans_head = 0;
+      wrk->trans_tail = 0;
+      wrk->trans_size = DMA_TRANS_SIZE;
+//      wrk->cb = session_dma_completion_cb_v1;
+      //       for (int i = 0; i < DMA_TRANS_SIZE; i++)
+      // 	wrk->dma_ctx[i].dma_ctx.fn = session_dma_completion_cb;
+      //       wrk->config_index = -1;
+      wrk->min_tsc = -1;
       vlib_node_set_state (vm, session_queue_node.index, state);
     }
 
@@ -2105,6 +2261,8 @@ session_config_fn (vlib_main_t * vm, unformat_input_t * input)
 	smm->use_private_rx_mqs = 1;
       else if (unformat (input, "no-adaptive"))
 	smm->no_adaptive = 1;
+      else if (unformat (input, "dma"))
+	smm->dma = 1;
       /*
        * Deprecated but maintained for compatibility
        */
diff --git a/src/vnet/session/session.h b/src/vnet/session/session.h
index 9d6c945bb..ee6002a9e 100644
--- a/src/vnet/session/session.h
+++ b/src/vnet/session/session.h
@@ -21,6 +21,7 @@
 #include <vnet/session/session_debug.h>
 #include <svm/message_queue.h>
 #include <svm/fifo_segment.h>
+#include <vlib/dma/dma.h>
 
 #define foreach_session_input_error                                    	\
 _(NO_SESSION, "No session drops")                                       \
@@ -85,6 +86,45 @@ typedef enum session_wrk_flags_
   SESSION_WRK_F_ADAPTIVE = 1 << 0,
 } __clib_packed session_wrk_flag_t;
 
+// typedef struct
+// {
+//   session_tx_context_t *ctx;
+//   vlib_buffer_t *b;
+//   transport_connection_t *tc;
+//   session_t *s;
+//   u32 bi;
+//   u16 next_index;
+//   u32 len;
+//   bool is_tail;
+//   vlib_dma_transfer_t trans[32];
+//   u16 n_transfers;
+// } sesion_dma_buffer_t;
+
+#define DMA_TRANS_SIZE 1024
+
+typedef struct
+{
+  session_tx_context_t *ctx;
+  vlib_buffer_t *b;
+  u32 c_index;
+  u32 s_index;
+  u32 bi;
+  u16 next_index;
+  u32 num;
+  bool is_tail;
+  u64 time1;
+  u64 time2;
+} session_dma_transfer;
+
+typedef struct
+{
+  u32 *pending_tx_buffers;
+  u16 *pending_tx_nexts;
+  u64 time1;
+  u64 time2;
+} session_dma_transfer_v1;
+
+
 typedef struct session_worker_
 {
   CLIB_CACHE_LINE_ALIGN_MARK (cacheline0);
@@ -155,6 +195,21 @@ typedef struct session_worker_
   /** Main thread loops in poll mode without a connect */
   u32 no_connect_loops;
 
+  int config_index;
+  bool dma_enabled;
+  vlib_dma_batch_callback_fn *cb;
+  session_dma_transfer *dma_trans;
+  session_dma_transfer_v1 *dma_trans_v1;
+  u16 trans_head;
+  u16 trans_tail;
+  u16 trans_size;
+  u16 batch_num;
+  u64 trans_num;
+  u64 total_tsc;
+  u64 max_tsc;
+  u64 min_tsc;
+  vlib_dma_batch_t *batch;
+
 #if SESSION_DEBUG
   /** last event poll time by thread */
   clib_time_type_t last_event_poll;
@@ -241,6 +296,8 @@ typedef struct session_main_
   u32 preallocated_sessions;
 
   u16 msg_id_base;
+
+  u8 dma;
 } session_main_t;
 
 extern session_main_t session_main;
@@ -759,6 +816,15 @@ session_wrk_update_time (session_worker_t *wrk, f64 now)
   wrk->last_vlib_us_time = wrk->last_vlib_time * CLIB_US_TIME_FREQ;
 }
 
+always_inline int
+session_tcp_buffer_len (vlib_buffer_t *b)
+{
+  u32 data_len = b->current_length;
+  if (PREDICT_FALSE (b->flags & VLIB_BUFFER_NEXT_PRESENT))
+    data_len += b->total_length_not_including_first_buffer;
+  return data_len;
+}
+
 void session_wrk_enable_adaptive_mode (session_worker_t *wrk);
 fifo_segment_t *session_main_get_wrk_mqs_segment (void);
 void session_node_enable_disable (u8 is_en);
diff --git a/src/vnet/session/session_api.c b/src/vnet/session/session_api.c
index f6170debb..2daa39515 100644
--- a/src/vnet/session/session_api.c
+++ b/src/vnet/session/session_api.c
@@ -1625,13 +1625,17 @@ appns_sapi_add_ns_socket (app_namespace_t * app_ns)
   clib_error_t *err;
   clib_socket_t *cs;
   char dir[4096];
+  char *cs_config = 0;
 
   if (app_ns->netns)
     {
       if (!app_ns->sock_name)
 	app_ns->sock_name = format (0, "@vpp/session/%v%c", app_ns->ns_id, 0);
-      if (app_ns->sock_name[0] != '@')
+      if (!clib_socket_name_is_abstract (app_ns->sock_name))
 	return VNET_API_ERROR_INVALID_VALUE;
+
+      cs_config =
+	(char *) format (0, "@netns:%s%s", app_ns->netns, app_ns->sock_name);
     }
   else
     {
@@ -1646,18 +1650,20 @@ appns_sapi_add_ns_socket (app_namespace_t * app_ns)
 
       if (!app_ns->sock_name)
 	app_ns->sock_name = format (0, "%s%v%c", dir, app_ns->ns_id, 0);
+
+      cs_config = (char *) vec_dup (app_ns->sock_name);
     }
 
   /*
    * Create and initialize socket to listen on
    */
   cs = appns_sapi_alloc_socket (app_ns);
-  cs->config = (char *) vec_dup (app_ns->sock_name);
+  cs->config = cs_config;
   cs->flags = CLIB_SOCKET_F_IS_SERVER |
     CLIB_SOCKET_F_ALLOW_GROUP_WRITE |
     CLIB_SOCKET_F_SEQPACKET | CLIB_SOCKET_F_PASSCRED;
 
-  if ((err = clib_socket_init_netns (cs, app_ns->netns)))
+  if ((err = clib_socket_init (cs)))
     {
       clib_error_report (err);
       return -1;
diff --git a/src/vnet/session/session_cli.c b/src/vnet/session/session_cli.c
index 24d8cfb1e..4c903615e 100644
--- a/src/vnet/session/session_cli.c
+++ b/src/vnet/session/session_cli.c
@@ -460,6 +460,24 @@ session_cli_show_events_thread (vlib_main_t * vm, u32 thread_index)
 		   clib_llist_elts (wrk->ctrl_evts_data));
 }
 
+void
+session_cli_show_dma (vlib_main_t *vm, u32 thread_index)
+{
+  session_worker_t *wrk;
+
+  wrk = session_main_get_worker_if_valid (thread_index);
+  if (!wrk)
+    {
+      vlib_cli_output (vm, "invalid thread index %u", thread_index);
+      return;
+    }
+
+  vlib_cli_output (vm, "Thread %d:\n", thread_index);
+  vlib_cli_output (vm, "Total %ld max %ld min %ld avg %ld cycles\n",
+		   wrk->total_tsc, wrk->max_tsc, wrk->min_tsc,
+		   wrk->trans_num ? wrk->total_tsc / wrk->trans_num : 0);
+}
+
 static void
 session_cli_show_events (vlib_main_t * vm, u32 thread_index)
 {
@@ -474,6 +492,20 @@ session_cli_show_events (vlib_main_t * vm, u32 thread_index)
     session_cli_show_events_thread (vm, thread_index);
 }
 
+static void
+session_cli_show_dmas (vlib_main_t *vm, u32 thread_index)
+{
+  session_main_t *smm = &session_main;
+  if (!thread_index)
+    {
+      session_cli_show_dma (vm, thread_index);
+      return;
+    }
+
+  for (thread_index = 0; thread_index < vec_len (smm->wrk); thread_index++)
+    session_cli_show_dma (vm, thread_index);
+}
+
 static void
 session_cli_print_session_states (vlib_main_t * vm)
 {
@@ -486,7 +518,8 @@ static clib_error_t *
 show_session_command_fn (vlib_main_t * vm, unformat_input_t * input,
 			 vlib_cli_command_t * cmd)
 {
-  u8 one_session = 0, do_listeners = 0, sst, do_elog = 0, do_filter = 0;
+  u8 one_session = 0, do_listeners = 0, sst, do_elog = 0, do_filter = 0,
+     do_dma = 0;
   u32 track_index, thread_index = 0, start = 0, end = ~0, session_index;
   unformat_input_t _line_input, *line_input = &_line_input;
   transport_proto_t transport_proto = TRANSPORT_PROTO_INVALID;
@@ -589,6 +622,8 @@ show_session_command_fn (vlib_main_t * vm, unformat_input_t * input,
 	}
       else if (unformat (line_input, "events"))
 	do_events = 1;
+      else if (unformat (line_input, "dma"))
+	do_dma = 1;
       else
 	{
 	  error = clib_error_return (0, "unknown input `%U'",
@@ -645,6 +680,11 @@ show_session_command_fn (vlib_main_t * vm, unformat_input_t * input,
       goto done;
     }
 
+  if (do_dma)
+    {
+      session_cli_show_dmas (vm, thread_index);
+    }
+
   if (do_filter)
     {
       if (end < start)
@@ -667,13 +707,12 @@ done:
 }
 
 /* *INDENT-OFF* */
-VLIB_CLI_COMMAND (vlib_cli_show_session_command) =
-{
+VLIB_CLI_COMMAND (vlib_cli_show_session_command) = {
   .path = "show session",
   .short_help = "show session [verbose [n]] [listeners <proto>] "
 		"[<session-id> [elog]] [thread <n> [index <n>] "
 		"[proto <proto>] [state <state>] [range <min> [<max>]] "
-		"[protos] [states] ",
+		"[protos] [states] [dma] ",
   .function = show_session_command_fn,
 };
 /* *INDENT-ON* */
diff --git a/src/vnet/session/session_node.c b/src/vnet/session/session_node.c
index 403c28f28..2df10b83b 100644
--- a/src/vnet/session/session_node.c
+++ b/src/vnet/session/session_node.c
@@ -845,15 +845,102 @@ session_tx_trace_frame (vlib_main_t * vm, vlib_node_runtime_t * node,
   vlib_set_trace_count (vm, node, n_trace);
 }
 
+always_inline int
+session_tx_fill_dma_transfers_tail (vlib_main_t *vm, session_tx_context_t *ctx,
+				    u32 bi, vlib_buffer_t *b, bool is_tail,
+				    u32 len_to_deq, u8 *data)
+{
+  session_main_t *smm = &session_main;
+  int n_bytes_read, len_write;
+  svm_fifo_seg_t data_fs[2];
+  session_worker_t *wrk = &smm->wrk[vm->thread_index];
+  u32 n_segs = 2;
+  u16 n_transfers = 0;
+
+  n_bytes_read = svm_fifo_segments (ctx->s->tx_fifo, ctx->sp.tx_offset,
+				    data_fs, n_segs, len_to_deq);
+
+  //   if (n_bytes_read < len_to_deq)
+  //     return -1;
+
+  session_dma_transfer *dma_transfer = &wrk->dma_trans[wrk->trans_tail];
+  dma_transfer->is_tail = is_tail;
+  dma_transfer->bi = bi;
+  dma_transfer->s_index = ctx->s->session_index;
+  dma_transfer->c_index = ctx->tc->c_index;
+
+  // printf("session_tx_fill_dma_transfers_tail: add tc %d\n",
+  // dma_transfer->c_index);
+  dma_transfer->next_index = smm->session_type_to_next[ctx->s->session_type];
+
+  len_write = n_bytes_read;
+  // printf ("svm_fifo_segments return n_bytes_read %d\n", n_bytes_read);
+  // save into transfer
+  ASSERT (n_bytes_read == len_to_deq);
+  /* Keep track of progress locally, transport is also supposed to
+   * increment it independently when pushing the header */
+  // ctx->sp.tx_offset += n_bytes_read;
+  // printf("session_tx_fill_dma_transfers_tail fill dma ctx from dma_buf
+  // %d\n", dma_ctx->dma_index);
+  while (n_bytes_read)
+    {
+//       wrk->iov[wrk->batch_num].dst = data;
+//       wrk->iov[wrk->batch_num].src = data_fs[n_transfers].data;
+//       wrk->iov[wrk->batch_num].size = data_fs[n_transfers].len;
+      wrk->batch_num++;
+      vlib_dma_batch_add (vm, wrk->batch, data,
+      			     data_fs[n_transfers].data,
+      			     data_fs[n_transfers].len);
+      // printf("session_tx_fill_dma_transfers_tail: src %p dst %p size %d
+      // times %d\n", data_fs[n_transfers].data, data,
+      // data_fs[n_transfers].len, n_transfers);
+      data += data_fs[n_transfers].len;
+      n_bytes_read -= data_fs[n_transfers].len;
+      //    printf ("\n\n\n\ndma request copy from %.*s to %p len %d\n",
+      //    data_fs[n_transfers].len, data_fs[n_transfers].data, data0,
+      //	       data_fs[n_transfers].len);
+      // printf ("n_bytes_read remain %d\n", n_bytes_read);
+      n_transfers++;
+    }
+//   dma_transfer->num = n_transfers;
+//   wrk->trans_num += n_transfers;
+  //  wrk->batch_num += n_transfers;
+//   wrk->trans_tail++;
+//   if (wrk->trans_tail == wrk->trans_size)
+//     wrk->trans_tail = 0;
+
+  // printf("session_tx_fill_dma_transfers_tail fill dma ctx to dma_buf %d\n",
+  // wrk->dma_tail); printf("session_tx_fill_dma_transfers_tail ctx tail %d\n",
+  // wrk->tail);
+  //   dma_buf->n_transfers = n_transfers;
+  //   dma_buf->len = len_write;
+  //   vec_add1(wrk->vec_dma_bufs, dma_buf);
+  // printf ("-----n bytes read %d\n", len_write);
+  // printf("snd_dsa before dma %d\n",ctx->s->snd_dsa);
+  // ctx->s->snd_dsa += len_write;
+  // printf("snd_dsa after dma %d \n",ctx->s->snd_dsa);
+//   vlib_dma_transfer (vm, wrk->config_index, wrk->iov, wrk->batch_num, 0);
+//   wrk->batch_num = 0;
+  /*
+   * Fill in the remaining buffers in the chain, if any
+   */
+  // if (PREDICT_FALSE (ctx->n_bufs_per_seg > 1 && ctx->left_to_snd))
+  //  session_tx_fifo_chain_tail (vm, ctx, b, n_bufs, peek_data);
+  return len_write;
+}
+
 always_inline void
-session_tx_fifo_chain_tail (vlib_main_t * vm, session_tx_context_t * ctx,
-			    vlib_buffer_t * b, u16 * n_bufs, u8 peek_data)
+session_tx_fifo_chain_tail (vlib_main_t *vm, session_tx_context_t *ctx,
+			    vlib_buffer_t *b, u32 bi, u16 *n_bufs,
+			    u8 peek_data)
 {
+  session_main_t *smm = vnet_get_session_main ();
+  session_worker_t *wrk = &smm->wrk[vm->thread_index];
   vlib_buffer_t *chain_b, *prev_b;
   u32 chain_bi0, to_deq, left_from_seg;
   u16 len_to_deq, n_bytes_read;
   u8 *data, j;
-
+  bool is_tail = 0;
   b->flags |= VLIB_BUFFER_TOTAL_LENGTH_VALID;
   b->total_length_not_including_first_buffer = 0;
 
@@ -871,11 +958,30 @@ session_tx_fifo_chain_tail (vlib_main_t * vm, session_tx_context_t * ctx,
       chain_b = vlib_get_buffer (vm, chain_bi0);
       chain_b->current_data = 0;
       data = vlib_buffer_get_current (chain_b);
+      if (j == ctx->n_bufs_per_seg - 1)
+	is_tail = 1;
       if (peek_data)
 	{
-	  n_bytes_read = svm_fifo_peek (ctx->s->tx_fifo,
-					ctx->sp.tx_offset, len_to_deq, data);
-	  ctx->sp.tx_offset += n_bytes_read;
+	  if (!wrk->dma_enabled)
+	    {
+	      n_bytes_read = svm_fifo_peek (ctx->s->tx_fifo, ctx->sp.tx_offset,
+					    len_to_deq, data);
+	      ctx->sp.tx_offset += n_bytes_read;
+	      // printf ("ctx->sp.tx_offset is %d after svm_fifo_peek\n",
+	      //		  ctx->sp.tx_offset);
+	    }
+	  else
+	    {
+	      n_bytes_read = session_tx_fill_dma_transfers_tail (
+		vm, ctx, bi, b, is_tail, len_to_deq, data);
+	      ctx->sp.tx_offset += n_bytes_read;
+	      //  if (n_bytes_read < 0)
+	      //    {
+	      // 	  ctx->sp.tx_offset += n_bytes_read;
+	      //    	  n_bytes_read = svm_fifo_peek (ctx->s->tx_fifo,
+	      //    ctx->sp.tx_offset, len_to_deq, data);
+	      //    }
+	    }
 	}
       else
 	{
@@ -920,7 +1026,6 @@ session_tx_fifo_chain_tail (vlib_main_t * vm, session_tx_context_t * ctx,
 
       /* update current buffer */
       chain_b->next_buffer = 0;
-
       to_deq -= n_bytes_read;
       if (to_deq == 0)
 	break;
@@ -930,32 +1035,169 @@ session_tx_fifo_chain_tail (vlib_main_t * vm, session_tx_context_t * ctx,
   ctx->left_to_snd -= left_from_seg;
 }
 
-always_inline void
-session_tx_fill_buffer (vlib_main_t * vm, session_tx_context_t * ctx,
-			vlib_buffer_t * b, u16 * n_bufs, u8 peek_data)
+always_inline int
+session_tx_fill_dma_transfers (vlib_main_t *vm, session_tx_context_t *ctx,
+			       u32 bi, vlib_buffer_t *b)
 {
+  session_main_t *smm = &session_main;
   u32 len_to_deq;
-  u8 *data0;
-  int n_bytes_read;
+  u8 *data0 = NULL;
+  int n_bytes_read, len_write;
+  svm_fifo_seg_t data_fs[2];
+  session_worker_t *wrk = &smm->wrk[vm->thread_index];
 
+  u32 n_segs = 2;
+  u16 n_transfers = 0;
   /*
    * Start with the first buffer in chain
    */
   b->error = 0;
   b->flags = VNET_BUFFER_F_LOCALLY_ORIGINATED;
   b->current_data = 0;
-
   data0 = vlib_buffer_make_headroom (b, TRANSPORT_MAX_HDRS_LEN);
   len_to_deq = clib_min (ctx->left_to_snd, ctx->deq_per_first_buf);
+  // printf ("len_to_deq is %d\n", ctx->left_to_snd);
+
+  n_bytes_read = svm_fifo_segments (ctx->s->tx_fifo, ctx->sp.tx_offset,
+				    data_fs, n_segs, len_to_deq);
+
+  //   if (n_bytes_read != len_to_deq)
+  //     return -1;
+
+  //   session_dma_ctx *dma_ctx = &wrk->dma_ctx[wrk->tail];
+  //   wrk->tail++;
+  //   if (wrk->tail == wrk->size)
+  //     wrk->tail = 0;
+
+//   session_dma_transfer *dma_transfer = &wrk->dma_trans[wrk->trans_tail];
+//   dma_transfer->is_tail = 1;
+//   dma_transfer->bi = bi;
+//   dma_transfer->s_index = ctx->s->session_index;
+//   dma_transfer->c_index = ctx->tc->c_index;
+//   dma_transfer->next_index = smm->session_type_to_next[ctx->s->session_type];
+//   dma_transfer->time1 = clib_cpu_time_now ();
+  // printf("session_tx_fill_dma_transfers: add tc %d\n",
+  // dma_transfer->c_index);
+
+  len_write = n_bytes_read;
+  // printf ("svm_fifo_segments return n_bytes_read %d\n", n_bytes_read);
+  // save into transfer
+  ASSERT (n_bytes_read == len_to_deq);
+  /* Keep track of progress locally, transport is also supposed to
+   * increment it independently when pushing the header */
+  // ctx->sp.tx_offset += n_bytes_read;
+  b->current_length = n_bytes_read;
+  ctx->left_to_snd -= n_bytes_read;
+  // printf("session_tx_fill_dma_transfers fill dma ctx from dma_buf %d\n",
+  // dma_ctx->dma_index);
+
+  // fprintf(stderr, "session_tx_fill_dma_transfers dma_ctx->dma_index %d\n",
+  // dma_ctx->dma_index);
+
+  while (n_bytes_read)
+    {
+//       wrk->iov[wrk->batch_num].dst = data0;
+//       wrk->iov[wrk->batch_num].src = data_fs[n_transfers].data;
+//       wrk->iov[wrk->batch_num].size = data_fs[n_transfers].len;
+      wrk->batch_num++;
+      vlib_dma_batch_add (vm, wrk->batch, data0, data_fs[n_transfers].data, data_fs[n_transfers].len);
+      //       vlib_dma_add_transfer (vm, wrk->config_index, data0,
+      // 			     data_fs[n_transfers].data,
+      // 			     data_fs[n_transfers].len);
+      // printf("session_tx_fill_dma_transfers: src %p dst %p size %d %d
+      // times\n",data_fs[n_transfers].data, data0, data_fs[n_transfers].len,
+      // n_transfers);
+      data0 += data_fs[n_transfers].len;
+      n_bytes_read -= data_fs[n_transfers].len;
+      //    printf ("\n\n\n\ndma request copy from %.*s to %p len %d\n",
+      //    data_fs[n_transfers].len, data_fs[n_transfers].data, data0,
+      //	       data_fs[n_transfers].len);
+      // printf ("n_bytes_read remain %d\n", n_bytes_read);
+      n_transfers++;
+    }
+//   dma_transfer->num += n_transfers;
+//   wrk->trans_num += n_transfers;
+  //  wrk->batch_num += n_transfers;
+  //  dma_buf->n_transfers = n_transfers;
+  // printf("session_tx_fill_dma_transfers fill dma ctx to dma_buf %d\n",
+  // wrk->dma_tail); printf("session_tx_fill_dma_transfers ctx tail %d\n",
+  // wrk->tail);
+  //  dma_buf->len = len_write;
+  // printf ("-n bytes read %d\n", len_write);
+  // printf("snd_dsa before dma %d\n",ctx->s->snd_dsa);
+  //  ctx->s->snd_dsa += len_write;
+  // printf("snd_dsa after dma %d \n",ctx->s->snd_dsa);
+//   if (PREDICT_FALSE (ctx->n_bufs_per_seg > 1 && ctx->left_to_snd))
+//     dma_transfer->is_tail = 0;
+
+//   vlib_dma_transfer (vm, wrk->config_index, wrk->iov, wrk->batch_num, 0);
+//   wrk->batch_num = 0;
+  // vlib_dma_transfer (wrk->config_index,
+  // 		   (vlib_dma_ctx_t *) &wrk->dma_ctx[wrk->head]);
+  //   wrk->head++;
+  //   if (wrk->head == wrk->size)
+  //     wrk->head = 0;
+
+//   wrk->trans_tail++;
+//   if (wrk->trans_tail == wrk->trans_size)
+//     wrk->trans_tail = 0;
+  /*
+   * Fill in the remaining buffers in the chain, if any
+   */
+  // if (PREDICT_FALSE (ctx->n_bufs_per_seg > 1 && ctx->left_to_snd))
+  //  session_tx_fifo_chain_tail (vm, ctx, b, n_bufs, peek_data);
+  return len_write;
+}
 
+always_inline void
+session_tx_fill_buffer (vlib_main_t *vm, session_tx_context_t *ctx, u32 bi,
+			vlib_buffer_t *b, u16 *n_bufs, u8 peek_data)
+{
+  u32 len_to_deq;
+  u8 *data0 = NULL;
+  int n_bytes_read;
+  session_main_t *smm = vnet_get_session_main ();
+  session_worker_t *wrk = &smm->wrk[vm->thread_index];
+  /*
+   * Start with the first buffer in chain
+   */
+  if (!wrk->dma_enabled)
+    {
+      b->error = 0;
+      b->flags = VNET_BUFFER_F_LOCALLY_ORIGINATED;
+      b->current_data = 0;
+
+      data0 = vlib_buffer_make_headroom (b, TRANSPORT_MAX_HDRS_LEN);
+      len_to_deq = clib_min (ctx->left_to_snd, ctx->deq_per_first_buf);
+    }
   if (peek_data)
     {
-      n_bytes_read = svm_fifo_peek (ctx->s->tx_fifo, ctx->sp.tx_offset,
-				    len_to_deq, data0);
-      ASSERT (n_bytes_read > 0);
-      /* Keep track of progress locally, transport is also supposed to
-       * increment it independently when pushing the header */
-      ctx->sp.tx_offset += n_bytes_read;
+      if (!wrk->dma_enabled)
+	{
+	  n_bytes_read = svm_fifo_peek (ctx->s->tx_fifo, ctx->sp.tx_offset,
+					len_to_deq, data0);
+	  ASSERT (n_bytes_read > 0);
+	  /* Keep track of progress locally, transport is also supposed to
+	   * increment it independently when pushing the header */
+	  ctx->sp.tx_offset += n_bytes_read;
+	}
+      else
+	{
+	  n_bytes_read = session_tx_fill_dma_transfers (vm, ctx, bi, b);
+	  ctx->sp.tx_offset += n_bytes_read;
+	  if (n_bytes_read < 0)
+	    {
+	      b->error = 0;
+	      b->flags = VNET_BUFFER_F_LOCALLY_ORIGINATED;
+	      b->current_data = 0;
+
+	      data0 = vlib_buffer_make_headroom (b, TRANSPORT_MAX_HDRS_LEN);
+	      len_to_deq = clib_min (ctx->left_to_snd, ctx->deq_per_first_buf);
+	      n_bytes_read = svm_fifo_peek (ctx->s->tx_fifo, ctx->sp.tx_offset,
+					    len_to_deq, data0);
+	      ctx->sp.tx_offset += n_bytes_read;
+	    }
+	}
     }
   else
     {
@@ -998,14 +1240,18 @@ session_tx_fill_buffer (vlib_main_t * vm, session_tx_context_t * ctx,
 	  ASSERT (n_bytes_read > 0);
 	}
     }
-  b->current_length = n_bytes_read;
-  ctx->left_to_snd -= n_bytes_read;
-
+  if (!wrk->dma_enabled)
+    {
+      b->current_length = n_bytes_read;
+      ctx->left_to_snd -= n_bytes_read;
+    }
   /*
    * Fill in the remaining buffers in the chain, if any
    */
   if (PREDICT_FALSE (ctx->n_bufs_per_seg > 1 && ctx->left_to_snd))
-    session_tx_fifo_chain_tail (vm, ctx, b, n_bufs, peek_data);
+    {
+      session_tx_fifo_chain_tail (vm, ctx, b, bi, n_bufs, peek_data);
+    }
 }
 
 always_inline u8
@@ -1236,6 +1482,8 @@ session_tx_fifo_read_and_snd_i (session_worker_t * wrk,
 
   if (ctx->s->flags & SESSION_F_CUSTOM_TX)
     {
+//       if (wrk->trans_head != wrk->trans_tail)
+//         return SESSION_TX_NO_BUFFERS;
       u32 n_custom_tx;
       ctx->s->flags &= ~SESSION_F_CUSTOM_TX;
       ctx->sp.max_burst_size = max_burst;
@@ -1258,6 +1506,7 @@ session_tx_fifo_read_and_snd_i (session_worker_t * wrk,
     transport_connection_clear_descheduled (ctx->tc);
 
   transport_connection_snd_params (ctx->tc, &ctx->sp);
+//   ctx->sp.tx_offset += ctx->s->snd_dsa;
 
   if (!ctx->sp.snd_space)
     {
@@ -1292,7 +1541,6 @@ session_tx_fifo_read_and_snd_i (session_worker_t * wrk,
 
   /* Check how much we can pull. */
   session_tx_set_dequeue_params (vm, ctx, max_burst, peek_data);
-
   if (PREDICT_FALSE (!ctx->max_len_to_snd))
     {
       transport_connection_tx_pacer_reset_bucket (ctx->tc, 0);
@@ -1321,6 +1569,18 @@ session_tx_fifo_read_and_snd_i (session_worker_t * wrk,
 
   vec_validate (ctx->transport_pending_bufs, n_left);
 
+  session_dma_transfer_v1 *dma_transfer = NULL;
+  if (wrk->dma_enabled)
+  {
+    dma_transfer = &wrk->dma_trans_v1[wrk->trans_tail];
+    dma_transfer->time1 = clib_cpu_time_now ();
+  }
+//   dma_transfer->is_tail = 1;
+//   dma_transfer->bi = bi;
+//   dma_transfer->s_index = ctx->s->session_index;
+//   dma_transfer->c_index = ctx->tc->c_index;
+//   dma_transfer->next_index = smm->session_type_to_next[ctx->s->session_type];
+
   while (n_left >= 4)
     {
       vlib_buffer_t *b0, *b1;
@@ -1339,17 +1599,29 @@ session_tx_fifo_read_and_snd_i (session_worker_t * wrk,
       b0 = vlib_get_buffer (vm, bi0);
       b1 = vlib_get_buffer (vm, bi1);
 
-      session_tx_fill_buffer (vm, ctx, b0, &n_bufs, peek_data);
-      session_tx_fill_buffer (vm, ctx, b1, &n_bufs, peek_data);
+      session_tx_fill_buffer (vm, ctx, bi0, b0, &n_bufs, peek_data);
+      session_tx_fill_buffer (vm, ctx, bi1, b1, &n_bufs, peek_data);
 
       ctx->transport_pending_bufs[ctx->n_segs_per_evt - n_left] = b0;
       ctx->transport_pending_bufs[ctx->n_segs_per_evt - n_left + 1] = b1;
       n_left -= 2;
 
-      vec_add1 (wrk->pending_tx_buffers, bi0);
-      vec_add1 (wrk->pending_tx_buffers, bi1);
-      vec_add1 (wrk->pending_tx_nexts, next_index);
-      vec_add1 (wrk->pending_tx_nexts, next_index);
+//       ctx->s->snd_dsa +=
+// 	session_tcp_buffer_len (b0) + session_tcp_buffer_len (b1);
+
+      if (!wrk->dma_enabled)
+	{
+	  vec_add1 (wrk->pending_tx_buffers, bi0);
+	  vec_add1 (wrk->pending_tx_buffers, bi1);
+	  vec_add1 (wrk->pending_tx_nexts, next_index);
+	  vec_add1 (wrk->pending_tx_nexts, next_index);
+	} else
+	{
+	  vec_add1 (dma_transfer->pending_tx_buffers, bi0);
+	  vec_add1 (dma_transfer->pending_tx_buffers, bi1);
+	  vec_add1 (dma_transfer->pending_tx_nexts, next_index);
+	  vec_add1 (dma_transfer->pending_tx_nexts, next_index);
+	}
     }
   while (n_left)
     {
@@ -1365,18 +1637,42 @@ session_tx_fifo_read_and_snd_i (session_worker_t * wrk,
 
       bi0 = ctx->tx_buffers[--n_bufs];
       b0 = vlib_get_buffer (vm, bi0);
-      session_tx_fill_buffer (vm, ctx, b0, &n_bufs, peek_data);
+      session_tx_fill_buffer (vm, ctx, bi0, b0, &n_bufs, peek_data);
 
       ctx->transport_pending_bufs[ctx->n_segs_per_evt - n_left] = b0;
       n_left -= 1;
 
-      vec_add1 (wrk->pending_tx_buffers, bi0);
-      vec_add1 (wrk->pending_tx_nexts, next_index);
+//       ctx->s->snd_dsa += session_tcp_buffer_len (b0);
+      if (!wrk->dma_enabled)
+	{
+	  vec_add1 (wrk->pending_tx_buffers, bi0);
+	  vec_add1 (wrk->pending_tx_nexts, next_index);
+	} else
+	{
+	  vec_add1 (dma_transfer->pending_tx_buffers, bi0);
+	  vec_add1 (dma_transfer->pending_tx_nexts, next_index);
+	}
     }
-
   /* Ask transport to push headers */
-  ctx->transport_vft->push_header (ctx->tc, ctx->transport_pending_bufs,
-				   ctx->n_segs_per_evt);
+//   if (wrk->config_index < 0)
+//     {
+      ctx->transport_vft->push_header (ctx->tc, ctx->transport_pending_bufs,
+				       ctx->n_segs_per_evt);
+//     }
+//     if (wrk->batch_num >= DMA_TRANS_SIZE)
+//     {
+//       printf("session_tx_fifo_read_and_snd_i: found iov overflow\n");
+//       u32 cookie = wrk->trans_tail;
+// //       vlib_dma_transfer (vm, wrk->config_index, wrk->iov, wrk->batch_num, cookie);
+//       wrk->batch_num = 0;
+//       wrk->trans_tail ++;
+//       if (wrk->trans_tail == wrk->trans_size)
+//         wrk->trans_tail = 0;
+//     }
+
+//   wrk->trans_tail ++;
+//   if (wrk->trans_tail == wrk->trans_size)
+//     wrk->trans_tail = 0;
 
   if (PREDICT_FALSE ((n_trace = vlib_get_trace_count (vm, node)) > 0))
     session_tx_trace_frame (vm, node, next_index, wrk->pending_tx_buffers,
@@ -1573,6 +1869,16 @@ session_event_dispatch_ctrl (session_worker_t * wrk, session_evt_elt_t * elt)
   SESSION_EVT (SESSION_EVT_COUNTS, CNT_CTRL_EVTS, 1, wrk);
 }
 
+// typedef struct {
+//   u32 thread_index;
+//   u32 session_index;
+//   u32 app_wrk_index;
+//   bool saved;
+// } session_record_t;
+
+// #define RECORD_SIZE 1024
+// static session_record_t records[RECORD_SIZE] = {};
+
 always_inline void
 session_event_dispatch_io (session_worker_t * wrk, vlib_node_runtime_t * node,
 			   session_evt_elt_t * elt, int *n_tx_packets)
@@ -1586,6 +1892,32 @@ session_event_dispatch_io (session_worker_t * wrk, vlib_node_runtime_t * node,
   ei = clib_llist_entry_index (wrk->event_elts, elt);
   e = &elt->evt;
 
+#ifdef DEBUG
+  if (e->event_type <= 4)
+  {
+    s = session_event_get_session (wrk, e);
+    for (int i = 0; i < RECORD_SIZE; i++)
+    {
+	session_record_t *session_record = &records[i];
+	if (session_record->saved == 1)
+	{
+		if ((session_record->thread_index == wrk->vm->thread_index) &&
+		    (session_record->session_index == s->session_index) && 
+		    (session_record->app_wrk_index == s->app_wrk_index))
+		    break;
+	}
+	else {
+	    session_record->thread_index = wrk->vm->thread_index;
+	    session_record->session_index = s->session_index;
+	    session_record->app_wrk_index = s->app_wrk_index;
+	    session_record->saved = true;
+	    printf("worker %d handle IO event from session %d app wrk %d event type %d\n", wrk->vm->thread_index, s->session_index, s->app_wrk_index, e->event_type);
+	    break;
+	}
+    }
+  }
+#endif
+
   switch (e->event_type)
     {
     case SESSION_IO_EVT_TX_FLUSH:
@@ -1747,7 +2079,7 @@ session_queue_node_fn (vlib_main_t * vm, vlib_node_runtime_t * node,
   session_worker_t *wrk = &smm->wrk[thread_index];
   clib_llist_index_t ei, next_ei, old_ti;
   int n_tx_packets;
-
+  //  printf("1");
   SESSION_EVT (SESSION_EVT_DISPATCH_START, wrk);
 
   session_wrk_update_time (wrk, vlib_time_now (vm));
@@ -1759,6 +2091,13 @@ session_queue_node_fn (vlib_main_t * vm, vlib_node_runtime_t * node,
   n_tx_packets = vec_len (wrk->pending_tx_buffers);
   SESSION_EVT (SESSION_EVT_DSP_CNTRS, UPDATE_TIME, wrk);
 
+  if (wrk->dma_enabled &&
+      (wrk->trans_head == ((wrk->trans_tail + 1) & (wrk->trans_size - 1))))
+    return 0;
+
+  if (wrk->dma_enabled)
+    wrk->batch = vlib_dma_batch_new (vm, wrk->config_index);
+
   /*
    *  Dequeue new internal mq events
    */
@@ -1828,6 +2167,22 @@ session_queue_node_fn (vlib_main_t * vm, vlib_node_runtime_t * node,
 	};
     }
 
+    if (wrk->batch_num)
+    {
+#ifdef DEBUG
+      printf("session_tx_fifo_read_and_snd_i: do flush %d ios at the end cookie %d\n", wrk->batch->n_enq, wrk->trans_tail);
+#endif
+      vlib_dma_batch_set_cookie (vm, wrk->batch, wrk->trans_tail);
+//      vlib_dma_transfer (vm, wrk->config_index, wrk->iov, wrk->batch_num, cookie);
+      wrk->batch_num = 0;
+      wrk->trans_tail ++;
+      if (wrk->trans_tail == wrk->trans_size)
+        wrk->trans_tail = 0;
+    }
+
+  if (wrk->dma_enabled)
+    vlib_dma_batch_submit (vm, wrk->batch);
+
   SESSION_EVT (SESSION_EVT_DSP_CNTRS, OLD_IO_EVTS, wrk);
 
   if (vec_len (wrk->pending_tx_buffers))
@@ -1835,12 +2190,13 @@ session_queue_node_fn (vlib_main_t * vm, vlib_node_runtime_t * node,
 
   vlib_node_increment_counter (vm, session_queue_node.index,
 			       SESSION_QUEUE_ERROR_TX, n_tx_packets);
-
   SESSION_EVT (SESSION_EVT_DISPATCH_END, wrk, n_tx_packets);
 
   if (wrk->flags & SESSION_WRK_F_ADAPTIVE)
     session_wrk_update_state (wrk);
 
+  //   vlib_dma_completed_cb(vm, wrk->config_index);
+  // wrk->trans_num = 0;
   return n_tx_packets;
 }
 
diff --git a/src/vnet/session/session_types.h b/src/vnet/session/session_types.h
index 8a8571bc9..c26ba116f 100644
--- a/src/vnet/session/session_types.h
+++ b/src/vnet/session/session_types.h
@@ -203,6 +203,7 @@ typedef struct session_
   /** Index of application that owns the listener. Set only if a listener */
   u32 app_index;
 
+  u32 snd_dsa;
   union
   {
     /** Parent listener session index if the result of an accept */
@@ -214,7 +215,6 @@ typedef struct session_
     /** Index in app worker's half-open table if a half-open */
     u32 ho_index;
   };
-
   /** Opaque, for general use */
   u32 opaque;
 
diff --git a/src/vnet/tcp/tcp_input.c b/src/vnet/tcp/tcp_input.c
index 64b9334cb..c185218cf 100644
--- a/src/vnet/tcp/tcp_input.c
+++ b/src/vnet/tcp/tcp_input.c
@@ -579,6 +579,7 @@ tcp_handle_postponed_dequeues (tcp_worker_ctx_t * wrk)
 	continue;
 
       /* Dequeue the newly ACKed bytes */
+      // printf("acked packet %d", tc->burst_acked);
       session_tx_fifo_dequeue_drop (&tc->connection, tc->burst_acked);
       tcp_validate_txf_size (tc, tc->snd_nxt - tc->snd_una);
 
diff --git a/src/vnet/tcp/tcp_output.c b/src/vnet/tcp/tcp_output.c
index 88cd91330..e31d9385e 100644
--- a/src/vnet/tcp/tcp_output.c
+++ b/src/vnet/tcp/tcp_output.c
@@ -944,6 +944,7 @@ tcp_push_hdr_i (tcp_connection_t * tc, vlib_buffer_t * b, u32 snd_nxt,
 
   if (update_snd_nxt)
     tc->snd_nxt += data_len;
+  // printf ("tcp_push_hdr_i: tc->snd_nxt updated to %u\n", tc->snd_nxt);
   tc->rcv_las = tc->rcv_nxt;
 
   tc->bytes_out += data_len;
@@ -968,10 +969,14 @@ tcp_push_one_header (tcp_connection_t *tc, vlib_buffer_t *b)
 {
   if (tc->cfg_flags & TCP_CFG_F_RATE_SAMPLE)
     tcp_bt_track_tx (tc, tcp_buffer_len (b));
-
+  // printf ("transport_max_tx_dequeue (&_tc->connection) %d offset
+  // %d\n",transport_max_tx_dequeue(&tc->connection), tc->snd_nxt -
+  // tc->snd_una);
   tcp_push_hdr_i (tc, b, tc->snd_nxt, /* compute opts */ 0, /* burst */ 1,
 		  /* update_snd_nxt */ 1);
-
+  // printf ("transport_max_tx_dequeue (&_tc->connection) %d offset
+  // %d\n",transport_max_tx_dequeue (&tc->connection), tc->snd_nxt -
+  // tc->snd_una);
   tcp_validate_txf_size (tc, tc->snd_nxt - tc->snd_una);
   return 0;
 }
diff --git a/src/vppinfra/CMakeLists.txt b/src/vppinfra/CMakeLists.txt
index b08ebb61e..d0df86fbd 100644
--- a/src/vppinfra/CMakeLists.txt
+++ b/src/vppinfra/CMakeLists.txt
@@ -253,7 +253,6 @@ if(VPP_BUILD_VPPINFRA_TESTS)
     random_isaac
     rwlock
     serialize
-    socket
     spinlock
     time
     time_range
diff --git a/src/vppinfra/pmalloc.c b/src/vppinfra/pmalloc.c
index a0b1d1f11..440698cc7 100644
--- a/src/vppinfra/pmalloc.c
+++ b/src/vppinfra/pmalloc.c
@@ -476,7 +476,7 @@ clib_pmalloc_alloc_aligned_on_numa (clib_pmalloc_main_t * pm, uword size,
   return clib_pmalloc_alloc_inline (pm, 0, size, align, numa_node);
 }
 
-void *
+__clib_export void *
 clib_pmalloc_alloc_aligned (clib_pmalloc_main_t * pm, uword size, uword align)
 {
   return clib_pmalloc_alloc_inline (pm, 0, size, align,
diff --git a/src/vppinfra/socket.c b/src/vppinfra/socket.c
index a09a390da..cc6d0bb81 100644
--- a/src/vppinfra/socket.c
+++ b/src/vppinfra/socket.c
@@ -93,11 +93,41 @@ find_free_port (word sock)
   return port < 1 << 16 ? port : -1;
 }
 
+/**
+ * Unformat the socket config (and potential netns). Syntax is as follows :
+ * config=@netns:ns0@memif
+ * > socket_name=memif ; netns=ns0
+ */
+static clib_error_t *
+clib_unformat_abstract_socket_name (const char *config, u8 **socket_name,
+				    u8 **namespace)
+{
+  unformat_input_t _input, *input = &_input;
+  clib_error_t *error = 0;
+
+  unformat_init_string (input, config, strlen (config));
+  /* namespace is a cstring, socket_name a vec */
+  if (unformat (input, "@netns:%s@%v", namespace, socket_name))
+    ;
+  else if (unformat (input, "@%v", socket_name))
+    *namespace = NULL;
+  else
+    {
+      error =
+	clib_error_return (0, "unknow abstract socket format `%s'", config);
+      goto done;
+    }
+
+done:
+  unformat_free (input);
+  return error;
+}
+
 /* Convert a config string to a struct sockaddr and length for use
    with bind or connect. */
 static clib_error_t *
-socket_config (char *config,
-	       void *addr, socklen_t * addr_len, u32 ip4_default_address)
+socket_config (const char *config, void *addr, socklen_t *addr_len,
+	       u32 ip4_default_address, u8 **namespace)
 {
   clib_error_t *error = 0;
 
@@ -115,17 +145,29 @@ socket_config (char *config,
     }
 
   /* Treat everything that starts with @ as an abstract socket. */
-  else if (config[0] == '@')
+  else if (clib_socket_name_is_abstract ((u8 *) config))
     {
       struct sockaddr_un *su = addr;
+      u8 *socket_name = NULL;
       su->sun_family = PF_LOCAL;
-      clib_memcpy (&su->sun_path, config,
-		   clib_min (sizeof (su->sun_path), 1 + strlen (config)));
 
-      *addr_len = sizeof (su->sun_family) + strlen (config);
+      if ((error = clib_unformat_abstract_socket_name (config, &socket_name,
+						       namespace)))
+	goto done;
+
+      /* socket_name should be smaller than dst (minus heading 0) */
+      if (sizeof (su->sun_path) - 1 < vec_len (socket_name))
+	{
+	  error = clib_error_return (0, "socket name too long `%s'", config);
+	  goto done;
+	}
+
+      clib_memcpy (&su->sun_path[1], socket_name, vec_len (socket_name));
       su->sun_path[0] = '\0';
-    }
+      *addr_len = sizeof (su->sun_family) + 1 + vec_len (socket_name);
 
+      vec_free (socket_name);
+    }
   /* Hostname or hostname:port or port. */
   else
     {
@@ -411,13 +453,38 @@ clib_socket_init (clib_socket_t * s)
   int socket_type, rv;
   clib_error_t *error = 0;
   word port;
+  int old_netns_fd = -1, nfd = -1;
+  u8 *namespace = NULL;
 
-  error = socket_config (s->config, &addr.sa, &addr_len,
-			 (s->flags & CLIB_SOCKET_F_IS_SERVER
-			  ? INADDR_LOOPBACK : INADDR_ANY));
+  error = socket_config (
+    s->config, &addr.sa, &addr_len,
+    (s->flags & CLIB_SOCKET_F_IS_SERVER ? INADDR_LOOPBACK : INADDR_ANY),
+    &namespace);
   if (error)
     goto done;
 
+  if (namespace != NULL)
+    {
+      if ((old_netns_fd = clib_netns_open (NULL /* self */)) < 0)
+	{
+	  error = clib_error_return_unix (0, "get current netns failed");
+	  goto done;
+	}
+
+      if ((nfd = clib_netns_open (namespace)) == -1)
+	{
+	  error =
+	    clib_error_return_unix (0, "clib_netns_open '%s'", namespace);
+	  goto done;
+	}
+
+      if (clib_setns (nfd) == -1)
+	{
+	  error = clib_error_return_unix (0, "setns '%s'", namespace);
+	  goto done;
+	}
+    }
+
   socket_init_funcs (s);
 
   socket_type = s->flags & CLIB_SOCKET_F_SEQPACKET ?
@@ -545,50 +612,22 @@ clib_socket_init (clib_socket_t * s)
 	}
     }
 
-  return error;
-
 done:
-  if (s->fd > 0)
+  if (error && s->fd > 0)
     close (s->fd);
-  return error;
-}
 
-__clib_export clib_error_t *
-clib_socket_init_netns (clib_socket_t *s, u8 *namespace)
-{
-  if (namespace == NULL || namespace[0] == 0)
-    return clib_socket_init (s);
-
-  clib_error_t *error;
-  int old_netns_fd, nfd = -1;
-
-  old_netns_fd = clib_netns_open (NULL /* self */);
-  if (old_netns_fd < 0)
-    return clib_error_return_unix (0, "get current netns failed");
-
-  if ((nfd = clib_netns_open (namespace)) == -1)
+  if (old_netns_fd != -1)
     {
-      error = clib_error_return_unix (0, "clib_netns_open '%s'", namespace);
-      goto done;
-    }
+      if (clib_setns (old_netns_fd))
+	clib_warning ("Cannot setns to original netns");
 
-  if (clib_setns (nfd) == -1)
-    {
-      error = clib_error_return_unix (0, "setns '%s'", namespace);
-      goto done;
+      close (old_netns_fd);
     }
 
-  error = clib_socket_init (s);
-
-done:
-  if (clib_setns (old_netns_fd) == -1)
-    clib_warning ("Cannot set old ns");
-
-  close (old_netns_fd);
-
-  if (-1 != nfd)
+  if (nfd != -1)
     close (nfd);
 
+  vec_free (namespace);
   return error;
 }
 
diff --git a/src/vppinfra/socket.h b/src/vppinfra/socket.h
index fa5ef1efc..80fc95f7d 100644
--- a/src/vppinfra/socket.h
+++ b/src/vppinfra/socket.h
@@ -93,8 +93,6 @@ typedef struct _socket_t
    from IPPORT_USERRESERVED (5000). */
 clib_error_t *clib_socket_init (clib_socket_t * socket);
 
-clib_error_t *clib_socket_init_netns (clib_socket_t *socket, u8 *namespace);
-
 clib_error_t *clib_socket_accept (clib_socket_t * server,
 				  clib_socket_t * client);
 
@@ -116,6 +114,12 @@ clib_socket_is_connected (clib_socket_t * sock)
   return sock->fd > 0;
 }
 
+always_inline int
+clib_socket_name_is_abstract (const u8 *name)
+{
+  /* Treat everything that starts with @ as an abstract socket. */
+  return (name[0] == '@');
+}
 
 always_inline int
 clib_socket_rx_end_of_file (clib_socket_t * s)
diff --git a/test/test_unittest.py b/test/test_unittest.py
new file mode 100644
index 000000000..564110a58
--- /dev/null
+++ b/test/test_unittest.py
@@ -0,0 +1,26 @@
+#!/usr/bin/env python3
+
+import unittest
+
+from framework import VppTestCase, VppTestRunner
+
+
+class TestUnittest(VppTestCase):
+    """ Unittest plugin Test Case """
+
+    @classmethod
+    def setUpClass(cls):
+        super(TestUnittest, cls).setUpClass()
+
+    @classmethod
+    def tearDownClass(cls):
+        super(TestUnittest, cls).tearDownClass()
+
+    def test_clib_socket(self):
+        """ FIB Unit Tests """
+        self.vapi.cli("test clib socket config /tmp/sometestsocket")
+        self.vapi.cli("test clib socket config @thisisabstract")
+
+
+if __name__ == '__main__':
+    unittest.main(testRunner=VppTestRunner)
